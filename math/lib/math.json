{
  "Affine_Space": {
    "define": "$$\n(\\mathcal{A}, V, \\phi)\n$$\n\nLet $V$ be a [vector space](./Linear_Space.md) over a field $K$. An affine space $\\mathcal{A}$ over $V$ is a non-empty set of elements called points together with a function\n\n$$\n\\phi: V \\times \\mathcal{A} \\rightarrow \\mathcal{A}\n$$\n\nthat associates to each point $p \\in \\mathcal{A}$ and each vector $v \\in V$ a point $q = \\phi(v, p)$, written as $q = p + v$, such that the following axioms hold:\n\n1. For every point $p \\in \\mathcal{A}$, $p + 0 = p$, where $0$ is the zero vector in $V$.\n2. For every point $p \\in \\mathcal{A}$ and all vectors $u, v \\in V$, $p + (u + v) = (p + u) + v$.\n3. For any two points $p, q \\in \\mathcal{A}$, there exists a unique vector $v \\in V$ such that $q = p + v$.\n\n\n\n> *Affine space is extended on the basis of vector space, removing the uniqueness of the origin. Its basic idea is to liberate geometric research from specific numerical values (i.e. vector coordinates) and instead focus on the relative positions and arrangements between points.*",
    "kids": {
      "Polyhedron": ""
    },
    "name": "Affine_Space",
    "parents": {
      "Linear_Space": ""
    },
    "properties": [
      "### Affine Set\n\n- Define\n  Affine Set is a set such that the lines drawn by any two points in the set are still in the set.  \n\n$$\n\\forall \\boldsymbol x_i \\in C, \u03b8_i \\in R, \\sum \u03b8_i = 1 \\quad \\text{, then}\\quad \\sum \u03b8_i x_i \\in C\n$$\n\n- Property\n\n  - Affine Hull\n\n    - Define  \n      $$\n      \\text{aff}(C) = \\left\\{\\sum \u03b8_i x_i\\ |\\ x_i\\in C,theta_i \\in R, \\sum \u03b8_i = 1  \\right\\}\n      $$\n      Affine Hull is a set such that affine combinations of all points in the set constitutes an affine hull.\n\n- Include\n\n  - Convex Set\n\n    - Define\n      $$\n      \\forall \\boldsymbol x_i \\in C \\subseteq \\mathbb R^n, a_i \\in [0,1], \\sum a_i = 1 \\quad \\text{, then}\\quad \\sum a_i x_i \\in C\n      $$\n\n      A convex set $C$ is a set such that the line segment between any two points in the set is still in the set. Convex sets are a special class of affine sets.\n\n    - Property\n\n      - Convex Set $C$\u7684\u4efb\u610f\u8fb9\u754c\u70b9, \u5747\u5b58\u5728\u652f\u6491\u8d85\u5e73\u9762.\n\n      - Convex Hull\n        $$\n          \\text{conv}(C) = \\left\\{\\sum \u03b8_i x_i\\ |\\ x_i\\in C, \u03b8_i \\in [0,1], \\sum \u03b8_i = 1 \\right\\}\n        $$\n\n          A convex hull is a set of points is the smallest convex polygon that contain all the input points.\n\n          The set of convex combinations of all points in the set constitutes a convex hull This convex hull is also the smallest Convex Set containing all points in a given set.\n\n        $$\n          \\mathcal X_{\\text{Convex\\ Hull}} \\subseteq \\mathcal X_{\\text{input}}\n        $$\n        $$\n        \\mathcal X_{\\text{input}} \\subseteq \\text{Polygon}(\\mathcal X_{\\text{Convex\\ Hull}})\n        $$\n\n\n\n### Cone\n- Define  \n$$\n\\forall \\boldsymbol x \\in C, \u03b8 > 0, \\quad \\text{, then}\\quad \u03b8 \\boldsymbol x \\in C\n$$\n\u4ee5\u96f6\u70b9\u4e3a\u8d77\u70b9\u7684\u5c04\u7ebf\u7684\u96c6\u5408.\n\n- Include\n  * Convex Cone\n    - Define  \n    $$\n    \\forall \\boldsymbol x_1, \\boldsymbol x_2 \\in C, \u03b8_1,\u03b8_2 \u2265 0 \\quad \\text{, then}\\quad \u03b8_1 \\boldsymbol x_1 + \u03b8_2 \\boldsymbol x_2 \\in C\n    $$\n\n### [Polyhedron](./Polyhedron.md)\n\n### Hyperplane & Half Space\n\n- Define\n  $$\n  \\begin{align*}\n    \\{\\boldsymbol x \\ |\\ \\boldsymbol a^T \\boldsymbol x = b\\}  \\tag{Hyperplane}\\\\\n    \\{\\boldsymbol x \\ |\\ \\boldsymbol a^T \\boldsymbol x \u2264 b\\}  \\tag{Half-Space}\n  \\end{align*}\n  $$\n\n- Property\n  - Hyperplane & Half-Space is Convex Set"
    ]
  },
  "Algebra_Structure": {
    "define": "An algebraic structure consists of a nonempty set $A$ (called the underlying set, carrier set or domain), a collection of operations on $A$ (typically binary operations such as addition and multiplication), and a finite set of identities, known as axioms, that these operations must satisfy.",
    "kids": {
      "Group": "",
      "Lattice": "",
      "Ring": ""
    },
    "name": "Algebra_Structure",
    "parents": {
      "Set": ""
    },
    "properties": [
      "### Automorphism \n\nAn automorphism is simply a bijective homomorphism of a mathematical object with itself."
    ]
  },
  "Bessel_Function": {
    "define": "[**Bessel functions**](./Function.md) are canonical solutions $y(x)$ of Bessel's differential equation\n$$\nx^{2}{\\frac {\\mathrm{d}^{2}y}{\\mathrm{d}x^{2}}}+x{\\frac {\\mathrm{d}y}{\\mathrm{d}x}}+\\left(x^{2}-\\alpha ^{2}\\right)y=0\\\\\ny(x)=c_{1}J_{\\alpha }(x)+c_{2}Y_{\\alpha }(x)\n$$\n**Bessel function of the first kind** $J_{\\alpha}(x)$, are solutions of Bessel's differential equation. For integer or positive $\u03b1$, Bessel functions of the first kind are finite at the origin $(x = 0)$; while for negative non-integer $\u03b1$, Bessel functions of the first kind diverge as x approaches zero. The Bessel function can be defined by its Taylor series expansion at $x = 0$.\n$$\nJ_{\\alpha }(x)=\\sum _{m=0}^{\\infty }{\\frac {(-1)^{m}}{m!\\Gamma (m+\\alpha +1)}}{\\left({\\frac {x}{2}}\\right)}^{2m+\\alpha}\n$$\n**Bessel functions of the second kind** $Y_{\\alpha}(x)$, \n$$\nY_{\\alpha }(x)={\\frac {J_{\\alpha }(x)\\cos(\\alpha \\pi )-J_{-\\alpha }(x)}{\\sin(\\alpha \\pi )}}\n$$",
    "kids": {},
    "name": "Bessel_Function",
    "parents": {
      "Function": ""
    },
    "properties": [
      ""
    ]
  },
  "Binary_Tree": {
    "define": "A tree in which each node has at most two children, which are referred to as the left child and the right child.\n\n<img src=\"./assets/Binary_tree_v2.svg\" alt=\"Binary_tree_v2\" style=\"zoom: 25%;\" />",
    "kids": {},
    "name": "Binary_Tree",
    "parents": {
      "Tree": ""
    },
    "properties": [
      "### Full Binary Tree\n\nFull Binary Tree refer to node has either 0 or 2 children, and all leaf nodes are at the same level.\n\n#### Property\n\nA binary tree in which all leaf nodes have the same height.\nNumber of nodes with depth $h$: $2^h$\nNumber of nodes in a complete binary tree with depth $h$: $2^{h+1} - 1$ \nNumber of non leaf nodes: $2^h - 1$\nNumber of leaf nodes: $2^h$  \n\nProof: \n$$\n\\sum\\limits_{i=0}^h 2^i = \\frac{1 - 2^h}{1 - 2} = 2^h - 1  \\tag{geometric sequence summation}\n$$\n\n\n\n### Complete Binary Tree\n\nComplete Binary Tree refer to all levels are completely filled except possibly the last level, and all nodes are as far left as possible.\n\n### Balanced Binary Tree\n\nBalanced Binary Tree refer to the heights of the left and right subtrees of every node differ by at most 1.\n\n### Traversal\nPre-order Traversal: The root node is visited first, then the left subtree, and finally the right subtree.\nIn-order Traversal: The left subtree is visited first, then the root node, and finally the right subtree. For a binary search tree, in-order traversal visits the nodes in ascending order.\nPost-order Traversal: The left subtree is visited first, then the right subtree, and finally the root node."
    ]
  },
  "Bipartite_Graph": {
    "define": "$$\n(X, Y, E)  \\tag{Bipartite Graph}\n$$\n$$\nX, Y \\subset V, X \\cup Y = V  \\tag{vertex sets}\n$$\n$$\nE = \\{(x_i, y_j) \\ |\\ x_i \\in X, y_j \\in Y\\}  \\tag{edge set}\n$$\n\nFor a Bipartite Graph, The vertex set $V$ of a graph is divided into two disjoint subsets $X, Y$. And, edges in Bipartite Graph only exist between point sets $X, Y$, not within them.\n\n<img src=\"./assets/Simple_bipartite_graph;_two_layers.svg\" alt=\"Simple_bipartite_graph;_two_layers\" style=\"zoom:20%;\" />",
    "kids": {},
    "name": "Bipartite_Graph",
    "parents": {
      "Graph": ""
    },
    "properties": [
      "- Representation, a bipartite graph can be represented by a matrix $M \\in \\mathbb R^{m \\times n}$ with each value $M_{ij}$ refer to the edge weight between $x_i$ and $y_j$, where $m$ is the element number of $X$ and $n$ is that of $Y$.\n  $$\n  f:(X \\times Y) \\to \\mathbb R \\quad\\Rightarrow\\quad \\mathbb R^{m \\times n}\n  $$\n\n### Maximum Matching\nThe maximum matching of bipartite graphs equivalents to a network flow model.\nConnect the source point to all points on the left and all points on the right to the sink, with a capacity of $1$. The original edge is connected from left to right, with a capacity of $1$. The maximum flow is the maximum match. \n\n\n#### Kuhn-Munkres Algorithm\n\n1. **\u521d\u59cb\u5316**\uff1a\u521b\u5efa\u4e00\u4e2a\u5339\u914d$M$\uff0c\u5f00\u59cb\u65f6$M$\u4e3a\u7a7a\u3002\n2. **\u8def\u5f84\u641c\u7d22**\uff1a\u5bf9\u4e8e$U$\u4e2d\u7684\u6bcf\u4e00\u4e2a\u672a\u5339\u914d\u8282\u70b9\uff0c\u5c1d\u8bd5\u627e\u5230\u4e00\u6761\u589e\u5e7f\u8def\u5f84\u3002\u589e\u5e7f\u8def\u5f84\u662f\u6307\u8d77\u59cb\u4e8e\u672a\u5339\u914d\u7684\u8282\u70b9\uff0c\u7ec8\u6b62\u4e8e\u672a\u5339\u914d\u7684\u8282\u70b9\uff0c\u4e14\u8def\u5f84\u4e0a\u7684\u8fb9\u4ea4\u66ff\u5730\u4e0d\u5728\u5339\u914d\u4e2d\u548c\u5728\u5339\u914d\u4e2d\u7684\u8def\u5f84\u3002\n3. **\u627e\u589e\u5e7f\u8def\u5f84**\uff1a\u4f7f\u7528\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u6216\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6765\u627e\u5230\u589e\u5e7f\u8def\u5f84\u3002\u8bbe$P$\u662f\u4e00\u6761\u4ece$u$\u5230$v$\u7684\u589e\u5e7f\u8def\u5f84\uff0c\u5176\u4e2d$u \\in U$\u4e14$v \\in V$\u3002\n4. **\u66f4\u65b0\u5339\u914d**\uff1a\u5982\u679c\u627e\u5230\u589e\u5e7f\u8def\u5f84\uff0c\u66f4\u65b0\u5f53\u524d\u5339\u914d$M$\u3002\u5bf9\u4e8e\u8def\u5f84$P$\u4e0a\u7684\u6bcf\u4e00\u6761\u8fb9\uff0c\u5982\u679c\u5b83\u4e0d\u5728$M$\u4e2d\uff0c\u5c31\u52a0\u5165$M$\uff1b\u5982\u679c\u5b83\u5728$M$\u4e2d\uff0c\u5c31\u4ece$M$\u4e2d\u79fb\u9664\u3002\u8fd9\u6837\u64cd\u4f5c\u540e\uff0c$M$\u4e2d\u5339\u914d\u7684\u6570\u91cf\u589e\u52a0\u4e861\u3002\n5. **\u91cd\u590d**\uff1a\u91cd\u590d\u6b65\u9aa42\u548c3\uff0c\u76f4\u5230\u65e0\u6cd5\u627e\u5230\u589e\u5e7f\u8def\u5f84\u4e3a\u6b62\u3002\n\n\u6570\u5b66\u4e0a\uff0c\u53ef\u4ee5\u7528\u4e00\u4e2a\u77e9\u9635$A$\u6765\u8868\u793a\u56fe$G$\uff0c\u5176\u4e2d$A_{ij} = 1$\u5982\u679c$(i, j) \\in E$\uff0c\u5426\u5219$A_{ij} = 0$\u3002\u5339\u914d\u53ef\u4ee5\u7528\u4e00\u4e2a\u4e0e$A$\u5927\u5c0f\u76f8\u540c\u7684\u77e9\u9635$M$\u6765\u8868\u793a\uff0c\u5176\u4e2d$M_{ij} = 1$\u5982\u679c\u8fb9$(i, j)$\u5728\u5339\u914d$M$\u4e2d\uff0c\u5426\u5219$M_{ij} = 0$\u3002\n\n\u7b97\u6cd5\u7684\u5173\u952e\u5728\u4e8e\u627e\u5230\u589e\u5e7f\u8def\u5f84\uff0c\u8fd9\u53ef\u4ee5\u901a\u8fc7\u6784\u9020\u4e00\u4e2a\u7b49\u4ef7\u7684\u7f51\u7edc\u6d41\u95ee\u9898\u6765\u5b9e\u73b0\u3002\u5728\u7f51\u7edc\u6d41\u7684\u8868\u8ff0\u4e2d\uff0c\u6bcf\u6b21\u589e\u5e7f\u8def\u5f84\u7684\u67e5\u627e\u76f8\u5f53\u4e8e\u5728\u6b8b\u4f59\u7f51\u7edc\u4e2d\u67e5\u627e\u4ece\u6e90\u70b9\u5230\u6c47\u70b9\u7684\u8def\u5f84\u3002\n\n\n\n#### Hopcroft-Karp Algorithm\n\n\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5308\u7259\u5229\u7b97\u6cd5\u8fd8\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e9b\u4f18\u5316\uff0c\u6bd4\u5982\u4f7f\u7528Hopcroft-Karp\u7b97\u6cd5\uff0c\u8fd9\u53ef\u4ee5\u5728\u66f4\u77ed\u7684\u65f6\u95f4\u5185\u627e\u5230\u6700\u5927\u5339\u914d\u3002Kuhn-Munkres\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u901a\u5e38\u4e3a$O(V^2E)$\uff0c\u4f46\u4f18\u5316\u540e\u7684\u7248\u672c\uff0c\u5982Hopcroft-Karp\u7b97\u6cd5\uff0c\u53ef\u4ee5\u8fbe\u5230$O(\\sqrt{V}E)$\u3002\n\n1. **\u521d\u59cb\u5316**\uff1a\n\n      - \u6700\u5927\u5339\u914d$M$\u5f00\u59cb\u65f6\u4e3a\u7a7a\u3002\n\n      - \u8ddd\u79bb\u51fd\u6570$dist$\u7528\u6765\u8bb0\u5f55\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u5c42\u7ea7\u4fe1\u606f\u3002\n\n\n2. **\u5c42\u6b21\u56fe\u6784\u5efa**\uff1a\n   - \u4f7f\u7528\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6784\u5efa\u5c42\u6b21\u56fe\u3002\u5c42\u6b21\u56fe\u662f\u539f\u56fe\u7684\u5b50\u56fe\uff0c\u5176\u4e2d\u5305\u542b\u4ece$U$\u4e2d\u672a\u5339\u914d\u9876\u70b9\u51fa\u53d1\u53ef\u4ee5\u901a\u8fc7\u589e\u5e7f\u8def\u5f84\u5230\u8fbe\u7684$V$\u4e2d\u9876\u70b9\u3002\n   - \u5bf9\u4e8e\u6bcf\u4e2a$u \\in U$\uff0c\u5982\u679c$u$\u672a\u5339\u914d\uff0c$dist(u) = 0$\uff0c\u5426\u5219$dist(u) = \\infty$\u3002\n   - \u4f7f\u7528\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u8ba1\u7b97\u5230\u6bcf\u4e2a\u9876\u70b9\u7684\u8ddd\u79bb\u3002\n\n3. **\u589e\u5e7f\u8def\u5f84\u641c\u7d22**\uff1a\n   - \u4f7f\u7528\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u5728\u5c42\u6b21\u56fe\u4e2d\u5bfb\u627e\u589e\u5e7f\u8def\u5f84\u3002\n   - \u5bf9\u4e8e\u6bcf\u4e2a$u \\in U$\uff0c\u5982\u679c$u$\u672a\u5339\u914d\uff0c\u5c1d\u8bd5\u627e\u5230\u4e00\u6761\u4ece$u$\u51fa\u53d1\u7684\u589e\u5e7f\u8def\u5f84\u3002\n\n4. **\u8def\u5f84\u589e\u5e7f**\uff1a\n   - \u5982\u679c\u627e\u5230\u4e86\u589e\u5e7f\u8def\u5f84\uff0c\u66f4\u65b0\u5339\u914d$M$\u3002\u5bf9\u4e8e\u8def\u5f84\u4e0a\u7684\u6bcf\u6761\u8fb9$(u, v)$\uff0c\u5982\u679c\u5b83\u4e0d\u5728$M$\u4e2d\uff0c\u5c31\u52a0\u5165$M$\uff1b\u5982\u679c\u5b83\u5728$M$\u4e2d\uff0c\u5c31\u4ece$M$\u4e2d\u79fb\u9664\u3002\n\n5. **\u91cd\u590d\u6784\u5efa\u548c\u641c\u7d22**\uff1a\n   - \u91cd\u590d\u6b65\u9aa42\u548c3\u76f4\u5230\u65e0\u6cd5\u627e\u5230\u66f4\u591a\u7684\u589e\u5e7f\u8def\u5f84\u4e3a\u6b62\u3002\n\n6. **\u7b97\u6cd5\u7ed3\u675f**\uff1a\n   - \u5f53\u5c42\u6b21\u56fe\u4e2d\u4e0d\u518d\u5b58\u5728\u589e\u5e7f\u8def\u5f84\u65f6\uff0c\u5f53\u524d\u5339\u914d$M$\u5c31\u662f\u6700\u5927\u5339\u914d\u3002\n\n\u5728\u6570\u5b66\u8868\u8ff0\u4e2d\uff0c\u5339\u914d$M$\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u96c6\u5408\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u8fb9\u7684\u96c6\u5408\u3002\u8ddd\u79bb\u51fd\u6570$dist$\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u4ece\u9876\u70b9\u5230\u975e\u8d1f\u6574\u6570\u7684\u6620\u5c04\uff0c\u5b83\u8bb0\u5f55\u4e86\u4ece$U$\u5230$V$\u7684\u6700\u77ed\u8def\u5f84\u957f\u5ea6\u3002Hopcroft-Karp\u7b97\u6cd5\u7684\u5173\u952e\u70b9\u5728\u4e8e\uff0c\u6bcf\u6b21\u901a\u8fc7\u5c42\u6b21\u56fe\u5bfb\u627e\u589e\u5e7f\u8def\u5f84\u65f6\uff0c\u81f3\u5c11\u53ef\u4ee5\u589e\u52a0\u4e00\u4e2a\u5339\u914d\u7684\u5927\u5c0f\u3002\u800c\u4e14\uff0c\u6bcf\u6b21\u627e\u5230\u7684\u589e\u5e7f\u8def\u5f84\u90fd\u662f\u6700\u77ed\u7684\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u7b97\u6cd5\u7684\u6548\u7387\u3002\u5728\u7b97\u6cd5\u7684\u5b9e\u73b0\u4e2d\uff0c\u901a\u5e38\u4f1a\u7ef4\u62a4\u4e24\u4e2a\u6570\u7ec4\u6765\u8bb0\u5f55\u5339\u914d\u5173\u7cfb\u548c\u8ddd\u79bb\uff0c\u8fd9\u4e9b\u6570\u636e\u7ed3\u6784\u4f1a\u5728\u7b97\u6cd5\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u66f4\u65b0\u3002\u6700\u7ec8\uff0c\u7b97\u6cd5\u80fd\u591f\u8fd4\u56de\u6700\u5927\u5339\u914d\u7684\u5927\u5c0f\u548c\u5339\u914d\u7684\u5177\u4f53\u5185\u5bb9\u3002"
    ]
  },
  "Boolean_Algebra": {
    "define": "Boolean Algebra is a [Lattice](./Lattice.md) including value and its operators,\n$$\n(\\{0, 1\\}, \\neg, \\wedge, \\vee)\n$$\n\nThe value of boolean algebra belongs to $\\{\\text{true}, \\text{false}\\}$, usually denoted $\\{1, 0\\}$. The basic operations of boolean algebra include $\\neg, \\wedge, \\vee$.\n\n- NOT $\\neg$\n  NOT is a unary operator.\n  \n  |$a$|$\\neg a$|\n  |---|---|\n  | 0 | 0 |\n  | 1 | 1 |\n  \n- AND $\\wedge$, OR $\\vee$\n  AND, OR are two binary operators.  \n  \n  |$a$|$b$|$a \\wedge b$|$a \\vee b$|\n  |:---:|:---:|:---:|:---:|\n  | 0 | 0 | 0 | 0 | \n  | 0 | 1 | 0 | 1 | \n  | 1 | 0 | 0 | 1 | \n  | 1 | 1 | 1 | 1 |",
    "kids": {},
    "name": "Boolean_Algebra",
    "parents": {
      "Lattice": ""
    },
    "properties": [
      "- \n\n  - $a \\wedge b = b \\wedge a$\n\n  - $a \\vee b = b \\vee a$\n\n  - $(a \\wedge b) \\wedge c = a \\wedge (b \\wedge c)$\n\n  - $(a \\vee b) \\vee c = a \\vee (b \\vee c)$\n\n  - $\\neg(a \\wedge b) = \\neg a \\vee \\neg b$\n\n  - $\\neg(a \\vee b) = \\neg a \\wedge \\neg b$\n\n  - $a \\wedge (a \\vee b) = a$\n\n  - $a \\vee (a \\wedge b) = a$\n\n  - $a \\wedge (b \\vee c) = (a \\wedge b) \\vee (a \\wedge c)$\n\n  - $a \\vee (b \\wedge c) = (a \\vee b) \\wedge (a \\vee c)$\n\n\n### XOR & XNOR\n\n- Define   \n  XOR $\\oplus$, XNOR $\\odot$ are two binary operators.  \n  \n  |$a$|$b$|$a \\oplus b$|$a \\odot b$|\n  |:---:|:---:|:---:|:---:|\n  | 0 | 0 | 0 | 1 | \n  | 0 | 1 | 1 | 0 | \n  | 1 | 0 | 1 | 0 | \n  | 1 | 1 | 0 | 1 | \n  |||\n  $$a \\oplus b = \\neg(a \\odot b)$$\n  $$a \\oplus b = (a \\wedge \\neg b) \\vee (\\neg a \\wedge b)$$\n  \n- Property\n  - $x \\oplus 0 = x$\n  - $x \\oplus 1 = \\neg x$\n  - $x \\oplus \\neg x = 1$\n  - $x \\oplus x = 0$\n  - $(a \\oplus b) \\oplus c = a \\oplus (b \\oplus c)$\n\n- |\n|$f(0, 0)$|$f(0, 1) = f(1, 0)$|$f(1, 1)$|operator|\n|:---:|:---:|:---:|:---:|\n| 0 | 0 | 0 | $a \\wedge 0$ |\n| 0 | 0 | 1 | $a \\wedge b$ |\n| 0 | 1 | 0 | $a \\oplus b = (a \\wedge \\neg b) \\vee (\\neg a \\wedge b)$ |\n| 0 | 1 | 1 | $a \\vee b$ |\n| 1 | 0 | 0 | $\\neg(a \\vee b)$ |\n| 1 | 0 | 1 | $a \\odot b = (a \\vee \\neg b) \\wedge (\\neg a \\vee b)$ |\n| 1 | 1 | 0 | $\\neg(a \\wedge b)$ |\n| 1 | 1 | 1 | $a \\vee 0$ |\n|||||"
    ]
  },
  "Complete_Graph": {
    "define": "Complete Graph is a undirected graph in which every pair of vertices is adjacent.\n\n<img src=\"./assets/11-simplex_graph.svg\" alt=\"11-simplex_graph\" style=\"zoom:30%;\" />",
    "kids": {},
    "name": "Complete_Graph",
    "parents": {
      "Graph": "full connected"
    },
    "properties": [
      "A complete graph containing $n$ vertices,\n\n- $number(E) = \\frac{n(n-1)}{2}$\n- The degree of each vertex is $n-1$"
    ]
  },
  "Complex_Field": {
    "define": "$$\n\\mathbb C\n$$\n\nThe set of complex numbers, denoted $\\mathbb{C}$, consists of all ordered pairs of [real numbers](./Real_Field.md) $(a, b)$. Each such number is usually written as $a + bi$, where $a$ is called the real part, $b$ is called the imaginary part, and $i$ is the imaginary unit with the property that $i^2 = -1$.\n$$\n\\mathbb C = \\{a + b i \\ |\\ a, b \\in \\mathbb R ,i^2  = 1\\}\n$$\nThe operations of addition and multiplication are defined as:\n- Addition: $(a + bi) + (c + di) = (a + c) + (b + d)i$.\n- Multiplication: $(a + bi)(c + di) = (ac - bd) + (ad + bc)i$.\n\nThe set $\\mathbb{C}$ with these operations forms a [field](./Field.md) that satisfies all the field axioms (A1-A4, M1-M4, D). It also has the property that every non-constant polynomial equation with coefficients in $\\mathbb{C}$ has a root in $\\mathbb{C}$ (this is the statement of the Fundamental Theorem of Algebra).",
    "kids": {
      "Complex_Value_Function": ""
    },
    "name": "Complex_Field",
    "parents": {
      "Field": "",
      "Real_Field": ""
    },
    "properties": [
      "- module and argument\n$$\n\\begin{align*}\nr &= |z| = \\sqrt{a^2 + b^2}  \\tag{module}\\\\\n\\theta &= \\arg(z) = \\arctan(b/a)  \\tag{argument}\n\\end{align*}\n$$\n$$\nz = a + b i = r (\\cos \\theta + i \\sin \\theta) = r e^{i \\theta}\n$$\n\n- Fundamental theorem of algebra\n\n  Every non-constant single-variable polynomial with complex coefficients has at least one complex root.\n\n- sub & div\n$$\n\\begin{align*}\nz_1 - z_2 &= (a - b i) + (c - d i) = (a - b) + (c - d) i  \\tag{sub}\\\\\n\\frac{z_1}{z_2} &= \\frac{a - b i}{c - d i} = \\frac{a c + b d}{c^2 + d^2} + \\frac{b c + a d}{c^2 + d^2} i  \\tag{div}\n\\end{align*}\n$$\n- conjugate: \n\n$$\n\\bar z = a - b i  \\tag{conjugate}\n$$\n- power: \n\n$$\nz^p = r^p (\\cos \u03b8 + i \\sin \u03b8)^p = r^p (\\cos (p \u03b8) + i \\sin(p \u03b8))  \\tag{De Moiver's theorem}\n$$"
    ]
  },
  "Complex_Value_Function": {
    "define": "$$\nf: \\mathbb C \\to \\mathbb C\n$$\n\nA complex function $f: \\mathbb C \\to \\mathbb C$ is a [function](./Function.md) from [complex numbers](./Complex_Field.md) to complex numbers.",
    "kids": {
      "Gamma_Function": "",
      "Holomorphic_Function": "",
      "Hypergeometric_Function": "",
      "Riemann_Zeta_Function": ""
    },
    "name": "Complex_Value_Function",
    "parents": {
      "Complex_Field": "",
      "Function": ""
    },
    "properties": [
      "- Differentiability: Holomorphic functions (or analytic functions) are differentiable everywhere within their domain of definition. For complex functions, holomorphism and analyticity are equivalent. \n\n  Let $U$ be an open set in the complex plane $\\mathbb C$ and let $f : U \\to \\mathbb C$ be a function. The function ,is said to be analytic (or holomorphic) on $U$ if for every $z_0 \\in U$, there exists an open disk $D$ centered at $z_0$ such that $f$ is differentiable at every point in $D$.\n\n### Residue & Residue Theorem\n$$\n\\operatorname{Res}(f,a)  \\tag{Residue}\n$$\n$$\n\\oint_C f(z)\\,\\mathrm{d}z=2\\pi i\\sum_{k=1}^n \\operatorname{Res}(f,a_k)  \\tag{Residue Theorem}\n$$\n\nFor an analytic function $f(z)$ on an open set $D$ and a simple closed curve $C$ that encircles counterclockwise all the isolated singularities $a_1,a_2,\\ldots,a_n$ of $f(z)$, then the integral of $f(z)$ along $C$ can be expressed as the sum of the residues of $f(z)$ at these singularities. And $\\operatorname{Res}(f,a_k)$ denotes the residue of $f(z)$ at the point $a_k$.\n\n### Laurent Series\n\nThe Laurent series for a complex function $f(z)$ about a point $c$ is given by\n$$\nf(z) = \\sum^{\\infty}_{n=-\\infty} a_n(z-c)^n\\\\\na_n = \\frac{1}{2\\pi i} \\oint_\\gamma \\frac{f(z)}{(z-c)^{n+1}}\\mathrm{d}z\n$$\nThe path of integration $\\gamma$ is counterclockwise around a Jordan curve enclosing $c$ and lying in an annulus $A$ in which $f(z)$ is holomorphic (analytic). The expansion for $f(z)$ will then be valid anywhere inside the annulus.\n\n### Analytic Function\n\n$$\nf(z) = \\sum_{n=0}^\\infty c_n (z - z_0)^n  \\tag{Analytic Function}\n$$\n\nAnalytic function $f$ is a complex function on an open set $D$ in the real line if for any $x_0 \\in D$, it can be expanded into a power series. Where the coefficients $a_i \\in \\mathbb R$.\n\n\n### Meromorphic Function\n\nA meromorphic function on an open subset $D$ of the complex plane is a function that is holomorphic on all of $D$ except for a set of isolated points, which are poles of the function."
    ]
  },
  "Convolution": {
    "define": "Cross Correlation and Convolution, are a measure of similarity (through [inner product](./Inner_Product_Space.md)) of two functions $f, g$ of the displacement $t \\in \\mathbb R$ of one relative to the other.\n$$\n\\begin{align*}\nCorr(f(t), g(t)) \n&= \\sum_{t = -\\infty}^{\\infty} f(\\tau) g(t + \\tau)  \\tag{Cross Correlation}  \\\\\n&= \\sum_{t = -\\infty}^{\\infty} f(-t+\\tau) g(\\tau)  \\\\\n&= \\int_{-\\infty}^{\\infty} f(\\tau) g(t + \\tau) \\mathrm d \\tau   \\\\\n&= \\int_{-\\infty}^{\\infty} f(-t+\\tau) g(\\tau) \\mathrm d \\tau  \\\\\nConv(f(t), g(t)) \n&= \\sum_{t = -\\infty}^{\\infty} f(\\tau) g(t - \\tau)  \\tag{Convolution}  \\\\\n&= \\sum_{t = -\\infty}^{\\infty} f(t-\\tau) g(\\tau)  \\\\\n&= \\int_{-\\infty}^{\\infty} f(\\tau) g(t - \\tau) \\mathrm d \\tau   \\\\\n&= \\int_{-\\infty}^{\\infty} f(t-\\tau) g(\\tau) \\mathrm d \\tau  \\\\\n\\end{align*}\n$$",
    "kids": {},
    "name": "Convolution",
    "parents": {
      "Inner_Product_Space": ""
    },
    "properties": [
      "- Commutativity & Associativity & Distributivity\n$$\n\\begin{align*}\nConv(f, g)  &= Conv(g, f)  \\tag{Commutativity}  \\\\\nConv(f, Conv(g, h))  &= Conv(Conv(f, g), h)  \\tag{Associativity}  \\\\\nConv(f, g+h)  &= Conv(f, g) + Conv(f, h)  \\tag{Distributivity}  \\\\\na\u00b7Conv(f, g)  &= Conv(a\u00b7f, g)  \\tag{Associativity with scalar multiplication}  \\\\\n\\end{align*}\n$$\n- Differential \n$$\n\\frac{\\mathrm{d}(f_1(t) * f_2(t))}{\\mathrm{d} t} = \\mathrm{d}(f_1(t) * \\frac{\\mathrm{d} f_2(t)}{\\mathrm{d} t} = \\mathrm{d}(f_2(t) * \\frac{\\mathrm{d} f_1(t)}{\\mathrm{d} t}\n$$\n- Integral \n$$\n\\int^t_{-\\infty} f_1(\u03bb) * f_2(\u03bb) \\mathrm{d} \u03bb = f_1(t) * \\int^t_{-\\infty} f_2(\u03bb) \\mathrm{d} \u03bb =  f_2(t) * \\int^t_{-\\infty} f_1(\u03bb) \\mathrm{d} \u03bb\n$$\n- Relation with impulse function\n$$\nf(t) * \u03b4^{(k)}(t - t_0) = f^{(k)}(t - t_0)\n$$\n$$\n\\begin{align*}\n\\mathrm{d}f(t) * \u03b4(t) &= f(t)\\\\\n\\mathrm{d}f(t) * \u03b4(t - t_0) &= f(t - t_0)\\\\\n\\mathrm{d}f(t) * \u03b4'(t - t_0) &= f'(t - t_0)\\\\\n\\mathrm{d}f(t) * u(t - t_0) &= f(t) * \\int^t_{-\\infty} \u03b4(\u03bb - t_0) \\mathrm{d} \u03bb = \\int^t_{-\\infty} f(\u03bb - t_0) \\mathrm{d} \u03bb\\\\\n\\end{align*}\n$$\n\n### Convolution Theorem\n$$\n\\mathcal F(f_1(t) * f_2(t)) = F_1(\u03c9) \u00b7 F_2(\u03c9)\n$$\n$$\n\\mathcal F(F_1(\u03c9) * F_2(\u03c9)) = \\frac{1}{2 \u03c0} f_1(t) \u00b7 f_2(t)\n$$"
    ]
  },
  "Cubic_Function": {
    "define": "$$\nf(x) = \\sum_{i=0}^{3} a_i x^i  \\tag{Univariate}\n$$",
    "kids": {
      "Elliptic_Curve": ""
    },
    "name": "Cubic_Function",
    "parents": {
      "Polynomial_Function": ""
    },
    "properties": [
      "### Zero Set of Cubic Function , Cubic Surface   \n\n- Define\n  $$\n  \\left\\{\\boldsymbol x \\ |\\  \\right\\}\n  $$\n- Property\n  - Solution of Univariate Cubic Equation  \n    For a Univariate Cubic Equation,\n    $$\n    x^3 + px + q = 0\n    $$\n\n    The solutions are,\n    $$\n    r = \\sqrt[3]{-\\frac{q}{2}+\\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}}}+\\sqrt[3]{-\\frac{q}{2}-\\sqrt{\\frac{q^2}{4}+\\frac{p^3}{27}}}\n    $$\n\n- Include\n  * Fermat Cubic\n    - Define\n      $$\n      \\left\\{ x \\ |\\ \\sum_{i = 1}^{\\dim} x_i^3 = 0 \\right\\}\n      $$"
    ]
  },
  "Differential_Manifold": {
    "define": "Differential manifold $M$ of dimension $n$ is a [manifold](./Manifold.md) and equipped with a differentiable structure. Differentiable structure refers to there exists a collection of charts $\\{(U_\\alpha, \\varphi_\\alpha)\\}$ such that $\\bigcup_{\\alpha}U_{\\alpha}=M$, for all overlapping charts $(U_{\\alpha},\\varphi_{\\alpha}), (U_{\\beta},\\varphi_{\\beta})$ in the atlas with $U_{\\alpha}\\cap U_{\\beta}\\neq\\varnothing$, then the transition maps $\\varphi_{\\beta}\\circ\\varphi_{\\alpha}^{-1}:\\varphi_{\\alpha}(U_{\\alpha}\\cap U_{\\beta})\\to\\varphi_{\\beta}(U_{\\alpha}\\cap U_{\\beta})$ are smooth (infinitely differentiable $C^\\infty$) map. This collection of charts is called an smooth atlas.\n\n<img src=\"./assets/Two_coordinate_charts_on_a_manifold.svg\" alt=\"Two_coordinate_charts_on_a_manifold\"  />",
    "kids": {
      "Euclidean_Space": ""
    },
    "name": "Differential_Manifold",
    "parents": {
      "Manifold": ""
    },
    "properties": [
      "### Continuity\n\n$f$ is a $C^r$ mapping $\\Leftrightarrow$ $\\forall p \\in M, \\psi_\\beta \\circ f \\circ \\psi_\\alpha^{-1}$ is $C^r$\n\n### Diffeomorphic\n\n### Christopher Symbol\n\nThe Christopher Symbol can compare tensors at different locations on the manifold instead of viewing them in isolation, so the K-Schmidt symbol is also called the connection coefficient.\n$$\n\\var A^i = -\\Gamma^i_{kl} A^k \\mathrm{d} x^l\n$$\nProperty\n$$\n\\Gamma^k_{ij} = \\frac{1}{2} g^{kl} \\left( \\frac{\\partial g_{il}}{\\partial x^j} + \\frac{\\partial g_{jl}}{\\partial x^i} - \\frac{\\partial g_{ij}}{\\partial x^l} \\right)\n$$\n\n### Geodesic equation\n\n$$\n\\frac{d^2 x^k}{d\\tau^2} + \\Gamma^k_{ij} \\frac{dx^i}{d\\tau} \\frac{dx^j}{d\\tau} = 0\n$$"
    ]
  },
  "Dirac_Delta_Function": {
    "define": "Dirac delta function $\\delta(x)$ is a type of [generalized function](./Function.md). \n$$\n\\delta(x) = \\left\\{\\begin{matrix}+\\infty,& x = 0\\\\0, & x \\neq 0\\end{matrix}\\right.\\\\\n\\int_{-\\infty}^{\\infty}\\delta(x) \\mathrm{d} x = 1\n$$\n<img src=\"assets/Dirac_distribution_PDF.svg\" alt=\"Dirac_distribution_PDF\" style=\"zoom:15%;\" />",
    "kids": {},
    "name": "Dirac_Delta_Function",
    "parents": {
      "Function": ""
    },
    "properties": [
      "### sampling property  \n\n$$\n\\int_{-\\infty}^{\\infty} f(t) \\delta(t-T) \\mathrm{d} t = f(T)\n$$"
    ]
  },
  "Directed_Acyclic_Graph": {
    "define": "Directed acyclic graph is directed graph without loops.",
    "kids": {},
    "name": "Directed_Acyclic_Graph",
    "parents": {
      "Graph": "directed, acyclic"
    },
    "properties": [
      "### Topological Sort  \n\nTopological Sort aims to linear ordering of point sets of directed acyclic graphs, and satisfying as follows. Topological Sort can help determine whether a graph is a directed acyclic graph.  \n- Each point appears only once\n- If there is an edge from point A to point B, point A appears before point B in the sequence.\n\n#### Solution\n\nIterate and delete points with 0 incoming edge on the Graph, put these points into the output sequence in turn, until all points are removed from the graph. If there are no more nodes in the graph that can be delete, but the number of remaining points is not 0, then the graph has loops and is not a directed acyclic graph."
    ]
  },
  "Division_with_Remainder": {
    "define": "([Integer_Ring](./Integer_Ring.md))\n\nFor $a,b \\in \\mathbb Z, b \\neq 0$, there are unique $q,r\\in \\mathbb Z, 0 \u2264 r < b$ satisfy\n$$\na = q \\times b + r\n$$\n\nwe called $q$ is Division, $r$ is Remainder.\n$$\n\\begin{align*}\n  a / b &= q  \\tag{Division}\\\\\n  a \\% b &= r  \\tag{Remainder}\\\\\n  a &\\equiv r \\mod b\n\\end{align*}\n$$\n\nIf $r = 0$, then we called the $q$ and $b$ is two Factors of $a$, and $b$ divides $a$, $b | a$. For any $a$, $1, a$ are always Factors of $a$.\n$$\nb | a \\quad\\Leftrightarrow\\quad (\\exists c \\in \\mathbb Z) a = b \\times c\n$$",
    "kids": {
      "Prime": ""
    },
    "name": "Division_with_Remainder",
    "parents": {
      "Integer_Ring": ""
    },
    "properties": [
      "- /\n  $$\n  \\begin{align*}\n    (a + b) \\% c &= (a \\% c + b \\% c) \\% c  \\\\\n    (a - b) \\% c &= (a \\% c - b \\% c + c) \\% c  \\\\\n    (a \u00b7 b) \\% c &= ((a \\% c) \u00b7 (b \\% c)) \\% c  \\\\\n    (a / b) \\% c &= (a \u00b7 b^{-1}) \\% c = ((a \\% c) \u00b7 (b^{-1} \\% c)) \\% c  \\tag{$b^{-1}$:$b$\u7684\u9006\u5143}\n  \\end{align*}\n  $$\n\n- Inverse element\n  $(a \u00b7 c) % b = 1$, \u5219$c$\u662f$a$\u5728$mod\\ b$\u4e0b\u7684\u9006\u5143$a^{-1}$\n\n### [Prime](./Prime.md)\n\n### Common Divisor & Common Multiple\n\nA Common Divisor $c$ of two number $a, b \\in \\mathbb Z$ is a number such that \n$$\na = k_a \\times c, \\quad b = k_b \\times c\n$$\n\nA Common Multiple $c$ of two number $a, b \\in \\mathbb Z$ is a number such that \n$$\nc = k_a \\times a, k_b \\times b\n$$\n\nProperty\n\n- Greatest Common Divisor & Least Common Multiple\n\n  Greatest Common Divisor is the maximum Common Divisor of two number $a, b \\in \\mathbb Z$ except $1$. \n\n  $$\n  gcd(a, b) = \\arg\\max_c\\ c \\quad s.t.\\ c | a, c | b\n  $$\n\n  Least Common Multiple is the minimum Common Multiple of two number $a, b \\in \\mathbb Z$.\n\n  $$\n  lcm(a, b) = \\arg\\min_c\\ c \\quad s.t.\\ a | c, b | c\n  $$\n  \n  - /\n    $$\n    \\begin{align*}\n      gcd(a, b) &= gcd(b, a)  \\\\\n      gcd(a, b) &= gcd(a - b, b) \\quad;(a \u2265 b)  \\\\\n      gcd(a, b) &= gcd(a \\% b, b)  \\\\\n      gcd(k a, k b) &= gcd(k a, b)  \\\\\n    \\end{align*}\n    $$\n\n  - $lcm(a, b) = \\frac{a \\times b}{gcd(a, b)}$\n\n  - $c | a, c | b \\Rightarrow c | (u a + v b)$ \n    - proof\n      $$\n      \\begin{align*}  \n        u a + v b \n        &= u \\times k_a \\times c + v \\times k_b \\times c \\\\\n        &= k \\times c\n      \\end{align*}\n      $$\n\n  - $gcd(a, b) = gcd(b, a \\% b)$\n    - proof  \n      For $a = q \\times b + r$,  \n      $$\n      \\begin{align*}  \n        gcd(a, b) = gcd(b, a \\% b) \\Leftrightarrow \\left\\{\\begin{matrix}\n        c | a, c | b &\\Rightarrow  c | r  &\\text{(1)}\\\\\n        c | b, c | r &\\Rightarrow  c | a  &\\text{(2)}\n        \\end{matrix}\\right.\n      \\end{align*}\n      $$\n      For (1), \n      $$\n      \\begin{align*}\n        \\Rightarrow\\quad k_a \\times c &= k_b \\times c \\times q + r  \\\\\n        \\Rightarrow\\quad r &= (k_b \\times q - k_a) \\times c  \n      \\end{align*}\n      $$\n\n      For (2), \n      $$\n      \\begin{align*}\n        \\Rightarrow\\quad a \n        &= k_b \\times c \\times q + k_r  \\times c  \\\\\n        &= (k_b \\times q + k_r)  \\times c\n      \\end{align*}\n      $$\n\n  - Algorithm: Euclid's Algorithm -- finding Greatest Common Divisor\n    $$\n    \\begin{align*}\n      a = q \\times b + r &\\Rightarrow gcd(a, b) = gcd(b, a \\% b)  \\\\\n      a = q \\times b &\\Rightarrow gcd(a, b) = b\n    \\end{align*}\n    $$\n\n    ```cpp\n    int gcd(int a, int b) { return b == 0 ? a : gcd(b, a %b); }\n    ```\n\n### Linear Diophantine Equation\n\n$$\na x + b y = c\n$$\nwhere, $a, b, c \\in \\mathbb Z$ is ciefficient, $x, y  \\in \\mathbb Z$ is unknown number.\n\n- Property\n  - $ax + by = c$ has a solution $\\quad\\Leftrightarrow\\quad$ $\\text{gcd}(a, b) \\% c = 0$\n\n- Algorithm\n  * Extended Euclidean Algorithm\n    - Purpose  \n      Solve the $x, y  \\in \\mathbb Z$ in equations:\n      $$a x + b y = \\text{gcd}(a, b)$$\n\n    - Process  \n      Start with two integers $a, b \\in \\mathbb Z$, where $a \\ge b$.\n\n      If $b \\% a = 0$, return $gcd(a, b) = b$, $(x, y) = (0, 1)$, because of $0 \\cdot a + 1 \\cdot b = b$.\n\n      If $b \\% a \\neq 0$, we solve $b x' + (a \\% b) y' = gcd(b, a \\% b)$, and\n      $$\n      \\begin{align*}\n        x &= y'\\\\\n        y &= x' - \\text{int}(a / b) \\cdot y'\n      \\end{align*}\n      $$\n\n- Include\n  * System of Linear Diophantine Equations\n    - Define  \n      $$A X = C$$ \n      where, $A \\in \\mathbb Z^{m \\times n}$ is a matrix of integers, $X \\in \\mathbb Z^n$ is a vector of unknowns and $C \\in \\mathbb Z^m$ is a vector of integers.\n\n    - Include\n      * Chinese Remainder Theorem\n        - Purpose   \n          Solve a class of linear Diophantine systems of equations: \n          $$\n          \\begin{align*}\n            x - n_1 x_1 &= a_1  \\\\\n            \\vdots &= \\vdots  \\\\\n            x - n_k x_k &= a_k\n          \\end{align*}\n          $$\n          \n          where, $(n_1, ..., n_k \\in \\mathbb Z)$ are pairwise coprime integers greater than one, $(x, x_1, ..., x_k \\in \\mathbb Z)$ are unknowns.\n\n### Congruence Equation\n\nSolve the unknown $0 \\le x < m, x \\in \\mathbb Z$ \n$$\nf(x) \\equiv b \\mod m\n$$\nInclude\n* Linear Congruence Equation\n  \n  A type of Congruence Equation with $f(x) = a x$.\n  $$\n  a x \\equiv b \\mod m\n  $$\n\n  - Include: System of Linear Congruence Equations\n    $$\n    \\begin{align*}\n      \\left\\{\\begin{matrix} x \\equiv a_1 \\mod m_1 \\\\ \\vdots \\\\ x \\equiv a_n \\mod m_n \\end{matrix}\\right.\n    \\end{align*}\n    $$\n  \n    $$\n    x = k \\prod_{i=1}^n m_i + \\sum_{i=1}^n a_i \\left(\\prod_{j=1, j\u2260i}^n m_j\\right) \\left(\\prod_{j=1, j\u2260i}^n m_j\\right)^{-1}\n    $$\n\n### Power Module\n\n$$\nb = (a^k) \\% m\n$$\n\nAlgorithm: \u9010\u6b21\u5e73\u65b9\u6cd5\n- \u5c06 k \u4e8c\u8fdb\u5236\u5c55\u5f00\n  $$k = \\sum_{i=0}^r u_i\u00b72^i$$\n\n  - Note\n    \u8ba1\u7b97\u673a\u91cc, k\u5185\u5b58\u5929\u7136\u662f\u4e8c\u8fdb\u5236\n\n- \u9010\u6b21\u5e73\u65b9\u5236\u4f5c\u6a21$m$\u7684$a$\u5e42\u6b21\u8868, $i\\in[0,r]$\n  $$\n  \\begin{align*}\n    a^{2^0} &= a = A_0 \\% m  \\\\\n    a^{2^i} &= (a^{2^{i-1}})^2 = A^{2(i-1)} = A_i % m\n  \\end{align*}\n  $$\n\n- \u4e58\u79ef\n  $$\n  \\prod_{i=0}^r A_i^{u_i} \\% m\n  $$\n\n- proof\n  $$\n  a^k = a^{\\sum\\limits_{i=0}^r u_i\u00b72^i}\n  $$"
    ]
  },
  "Elliptic_Curve": {
    "define": "$$\ny^2 = x^3 + a x + b\n$$\n\nAn elliptic curve over a field $K$ is defined by an equation of the form as above. where $a, b$ are elements in $K$, and the discriminant $ \\Delta = -16(4a^3 - 27b^2) \\neq 0$. The non-vanishing of the discriminant ensures that the curve has no singularities (i.e., no cusps or self-intersections). ([Cubic Function](./Cubic_Function.md))\n\n<img src=\"assets/EllipticCurveCatalog.svg\" alt=\"EllipticCurveCatalog\" style=\"zoom: 33%;\" />",
    "kids": {},
    "name": "Elliptic_Curve",
    "parents": {
      "Cubic_Function": ""
    },
    "properties": [
      "Groups formed by points on elliptic curves: The points on an elliptic curve form an Abelian group through a defined \"addition\" operation. This addition operation is related to the intersection of a line and a curve, while the unit element is represented by a point at infinity.\n\n- Addition Operation: Given two points $P = (x_1, y_1), Q = (x_2, y_2)$ on $E$, their sum $P+Q=(x3, y3)$ is defined as follows: (Draw a straight line passing through points $P, Q$. This straight line will align with the curve at the third point $Q'$. By reflecting perpendicular to the x-axis from point $Q'$, you will obtain new points $C$, which is defined as $P + Q$.)\n\n  If $P \\neq Q$, the slope of the line through $P$ and $Q$ is:\n  $$\n  m = \\frac{y_2 - y_1}{x_2 - x_1}\n  $$\n  If $P = Q$, the slope of the tangent to the curve at $P$ is:\n  $$\n  m = \\frac{3x_1^2 + a}{2y_1}\n  $$\n  The coordinates $x_3$ and $y_3$ of $P + Q$ are given by:\n  $$\n  (x_3, y_3) = (m^2 - x_1 - x_2, m(x_1 - x_3) - y_1)\n  $$\n\n  Special cases:\n\n  if $P = O$, then $P +Q= Q$\n  if $Q = O$,then $P +Q = P$\n  if $P = (x_1, y_1), Q = (x_1, -y_1)$  (i.e., $Q$ is the reflection of $P$ over the x-axis), then $P + Q= O$.\n\n- Unit element: The unit element of this group is a special point at infinity, usually denoted as $O$. Any point on an elliptical curve plus O is equal to itself."
    ]
  },
  "Euclidean_Space": {
    "define": "Euclidean space is a finite dimensional [Hilbert space](./Hilbert_Space.md) over a [real number field](./Real_Field.md), and has a standard dot product as its inner product. Let $n \\in \\mathbb{N}$ (the set of natural numbers). The $n$-dimensional Euclidean space, denoted as $\\mathbb{R}^n$, is the set of all ordered $n$-tuples of real numbers. That is,\n$$\n\\mathbb{R}^n = \\{(x_1, x_2, \\dots, x_n) : x_i \\in \\mathbb{R} \\text{ for } i = 1,2, \\dots, n\\}\n$$\n\nIn $\\mathbb{R}^n$, we define the following operations:\n\n1. **Vector Addition:** For any two vectors $\\mathbf{v} = (v_1, v_2, \\dots, v_n)$ and $\\mathbf{w} = (w_1, w_2, \\dots, w_n)$ in $\\mathbb{R}^n$, their sum is given by:\n$$\n\\mathbf{v} + \\mathbf{w} = (v_1 + w_1, v_2 + w_2, \\dots, v_n + w_n)\n$$\n\n2. **Scalar Multiplication:** For any scalar $c \\in \\mathbb{R}$ and vector $\\mathbf{v} = (v_1, v_2, \\dots, v_n)$ in $\\mathbb{R}^n$, the scalar product is:\n$$\nc \\cdot \\mathbf{v} = (c v_1, c v_2, \\dots, c v_n)\n$$\n\n3. **Inner Product (Dot Product):** The inner product of two vectors $\\mathbf{v} = (v_1, v_2, \\dots, v_n)$ and $\\mathbf{w} = (w_1, w_2, \\dots, w_n)$ in $\\mathbb{R}^n$ is defined as:\n$$\n\\mathbf{v} \\cdot \\mathbf{w} = v_1 w_1 + v_2 w_2 + \\dots + v_n w_n\n$$\n\nFrom this inner product, we can derive the **Euclidean norm** of a vector $\\mathbf{v}$ as:\n$$\n||\\mathbf{v}|| = \\sqrt{\\mathbf{v} \\cdot \\mathbf{v}}\n$$\n\nWith these operations, $\\mathbb{R}^n$ becomes a **real inner product space**. The geometry induced by the inner product is the familiar Euclidean geometry, and the distance between two vectors $\\mathbf{v}$ and $\\mathbf{w}$ is given by the norm of their difference:\n$$\nd(\\mathbf{v}, \\mathbf{w}) = ||\\mathbf{v} - \\mathbf{w}||\n$$",
    "kids": {
      "Knot": ""
    },
    "name": "Euclidean_Space",
    "parents": {
      "Differential_Manifold": "",
      "Hilbert_Space": "",
      "Real_Field": ""
    },
    "properties": [
      "### Tessellation\n\nA tessellation or tiling is the covering of a surface, often a plane, using one or more geometric shapes, called tiles, with no overlaps and no gaps.\n\n#### Convex regular polygon tiling\n\nThere are three methods for dense tiling of a monohedral regular polygon in a plane: equilateral triangle, square, and regular hexagon.\n\n<img src=\"assets/1-uniform_n11.svg\" alt=\"1-uniform_n11\" style=\"zoom:8%;\" /><img src=\"assets/1-uniform_n5.svg\" alt=\"1-uniform_n5\" style=\"zoom:20%;\" /><img src=\"assets/1-uniform_n1.svg\" alt=\"1-uniform_n1\" style=\"zoom:8%;\" />\n\nThere are 17 combinations of regular convex polygons that form 21 types of plane-vertex tilings.\n\n<img src=\"assets/image-20240209012125223.png\" alt=\"image-20240209012125223\" style=\"zoom: 33%;\" />\n\n#### Space-Filling Polyhedron\n\n<img src=\"assets/SpaceFillingPolyhedra_1000.svg\" alt=\"SpaceFillingPolyhedra\" style=\"zoom: 25%;\" />\n\n#### Monohedral Pentagonal tiling\n\n<img src=\"assets/image-20240209013213739.png\" alt=\"image-20240209013213739\" style=\"zoom:20%;\" />\n\n#### Penrose tiling\n\nA Penrose tiling is an example of an aperiodic tiling.\n\n<img src=\"assets/Penrose_Tiling_(Rhombi).svg\" alt=\"Penrose_Tiling_(Rhombi)\" style=\"zoom:25%;\" />"
    ]
  },
  "Exponential_Function": {
    "define": "Trigonometric functions $f: \\mathbb R \\to \\mathbb R$ are a set of mathematical [functions](./Function.md) that relate angles $\\theta$ to the ratios of the sides (opposite $a$, adjacent $b$, hypotenuse $c$) of a right-angled triangle. Where hypotenuse is the length of the side opposite the right angle, opposite represents the side opposite the given angle $\\theta$, adjacent represents the side between the angle $\\theta$ and the right angle.\n\n$$\n\\begin{align*}\n  \\sin(\\theta) &= \\frac{a}{c}  \\quad\\in (-1, 1)\\tag{sine}\\\\\n  \\cos(\\theta) &= \\frac{b}{c}  \\quad\\in (-1, 1)\\tag{cosine}\\\\\n  \\tan(\\theta) &= \\frac{a}{b}  \\quad\\in (-\\infty, +\\infty)\\tag{tangent}\n\\end{align*}\n$$\n\nHyperbolic Functions $f: \\mathbb R \\to \\mathbb R$ are defined by hyperbola $x^2 - y^2 = 1$, where the angles $\\theta$ refer to twice the included angle of the ray from zero point to the point in hyperbola and positive half of x-axis, $\\sinh(\\theta)$ is the coordinate value $x$ of the point, and $\\cosh(\\theta)$ is the coordinate value $y$ of the point.\n\nFor the complex field $z \\in \\mathbb C$,\n$$\ne^{iz} = \\cos(z) + i \\sin(z)\n$$\n\n$$\n\\begin{align*}\n\\sin(z)  &= \\frac{e^{iz} - e^{-iz}}{2i}  \\tag{sine}\\\\\n\\cos(z)  &= \\frac{e^{iz} + e^{-iz}}{2}  \\tag{cosine}\\\\\n\\tan(z)  &= \\frac{e^{iz} - e^{-iz}}{ie^{iz} + ie^{-iz}}  \\tag{tangent}\\\\\n\\sinh(z) &= \\frac{e^{z} - e^{-z}}{2}  \\tag{hyperbolic sine}\\\\\n\\cosh(z) &= \\frac{e^{z} + e^{-z}}{2}  \\tag{hyperbolic cosine}\\\\\n\\sinh(z) &= \\frac{e^{-z} - e^{z}}{e^{z} + e^{-z}}  \\tag{hyperbolic tangent}\\\\\n\\end{align*}\n$$",
    "kids": {},
    "name": "Exponential_Function",
    "parents": {
      "Function": ""
    },
    "properties": [
      "- Euler's formula\n  $$\n  e^{i \\pi} + 1 = 0\n  $$\n  \n- Trigonometric functions are periodic functions. The period of $\\sin(\\cdot), \\cos(\\cdot)$ is $2 k \\pi$, period of $\\tan(\\cdot)$ is $k \\pi$, $k \\in \\mathbb Z$,\n  $$\n  \\begin{align*}\n    \\sin(\\theta + 2 k \\pi) &= \\sin(\\theta)  \\\\\n    \\cos(\\theta + 2 k \\pi) &= \\cos(\\theta)  \\\\\n    \\tan(\\theta + k \\pi) &= \\tan(\\theta)  \\\\\n  \\end{align*}\n  $$\n  \n- 1\n  $$\n  \\begin{align*}\n    \\sin(a \\pm b) &= \\sin(a) \\cos(b) \\pm \\cos(a) \\sin(b)  \\\\\n    \\cos(a \\pm b) &= \\cos(a) \\cos(b) \\mp \\sin(a) \\sin(b)  \\\\\n    \\tan(a \\pm b) &= \\frac{\\tan(a) \\pm  \\tan(b)}{1 \\mp \\tan(a) \\tan(b)}\n  \\end{align*}\n  $$\n  \n- The relationship between the addition and multiplication of two trigonometric functions,\n  $$\n  \\begin{align*}\n    \\sin(a)\\cos(b) &= \\frac{\\sin(a + b) + \\sin(a - b)}{2}  \\\\\n    \\sin(a)\\sin(b) &= \\frac{\\cos(a + b) - \\cos(a - b)}{2}  \\\\\n    \\cos(a)\\cos(b) &= \\frac{\\cos(a + b) + \\cos(a - b)}{2}  \\\\\n  \\end{align*}\n  $$\n\n- 1\n  $$\n  a \\sin(\\theta) + b \\cos(\\theta) = \\sqrt{a^2 + b^2} \\sin \\left(\\theta + \\arctan\\left(\\frac{b}{a}\\right) \\right)\n  $$"
    ]
  },
  "Field": {
    "define": "Field is a [ring](./Ring.md) that satisfies the existence of multiplicative inverses for every nonzero element.",
    "kids": {
      "Complex_Field": "",
      "Rational_Number_Field": "",
      "Real_Field": ""
    },
    "name": "Field",
    "parents": {
      "Ring": ""
    },
    "properties": [
      "### Field extension\n\n- Define\n\n  A field extension is a pair of fields $E$ and $F$ such that the operations of $F$ are those of $E$ restricted to $F$. In other words, $F$ is a subset of $E$, and the addition and multiplication of elements of $F$ in $E$ coincide with their addition and multiplication in $F$. When $F$ is a subfield of $E$, we often say that $E$ is an extension of $F$ and write $E/F$."
    ]
  },
  "Forth-Order_Function": {
    "define": "$$\nf(x) = \\sum_{i=0}^{4} a_i x^i  \\tag{Univariate}\n$$\n\n$$\n\\begin{align*}\n  f(\\boldsymbol x) =& \\sum_{i_1=1}^{\\dim} \\sum_{i_2=i_1}^{\\dim} \\sum_{i_3=i_2}^{\\dim} \\sum_{i_4=i_3}^{\\dim} a_{i_1 i_2 i_3 i_4} \u00b7 x_{i_1} x_{i_2} x_{i_3} x_{i_4} +    \\\\\n  &\\sum_{i_1=1}^{\\dim} \\sum_{i_2=i_1}^{\\dim} \\sum_{i_3=i_2}^{\\dim} b_{i_1 i_2 i_3} \u00b7 x_{i_1} x_{i_2} x_{i_3} +    \\\\\n  &\\sum_{i_1=1}^{\\dim} \\sum_{i_2=i_1}^{\\dim} c_{i_1 i_2} \u00b7 x_{i_1} x_{i_2} +    \\\\\n  &\\sum_{i_1=0}^{\\dim} d_{i_1} x_{i_1} +    \\\\\n  &e  \\tag{Multivariate}  \\\\\n  =& \\sum_{i_0=0}^{\\dim} \\sum_{i_1=i_0}^{\\dim} \\sum_{i_2=i_1}^{\\dim} \\sum_{i_3=i_2}^{\\dim} \\sum_{i_4=i_3}^{\\dim} a_{i_0 i_1 i_2 i_3 i_4} \u00b7 x_{i_0} x_{i_1} x_{i_2} x_{i_3} x_{i_4}  \\quad, x_0 = 1\n\\end{align*}\n$$",
    "kids": {},
    "name": "Forth-Order_Function",
    "parents": {
      "Polynomial_Function": ""
    },
    "properties": [
      "### Zero Set of Quartic Function , Quartic Surface\n\n\n\n### Solution of Univariate Quartic Equation  \nFor an Univariate Quartic Equation,\n$$\na x^4 + b x^3 + c x^2 + d x + e = 0\n$$\n\nThe solutions are $r_1, r_2, r_3, r_4$,\n$$\n\\begin{align*}\n  r_{i} &= -\\frac{b}{4 a} - S \\pm \\frac{1}{2} \\sqrt{-4 S^2 -2 p \\pm \\frac{q}{S}}  \\\\\n  p & =\\frac{8 a c-3 b^2}{8 a^2} \\\\\n  q & =\\frac{b^3-4 a b c+8 a^2 d}{8 a^3} \\\\\n  S & =\\frac{1}{2} \\sqrt{-\\frac{2}{3} p+\\frac{1}{3 a}\\left(Q+\\frac{\\Delta_0}{Q}\\right)} \\\\\n  Q & =\\sqrt[3]{\\frac{\\Delta_1+\\sqrt{\\Delta_1^2-4 \\Delta_0^3}}{2}} \\\\\n  \\Delta_0 & =c^2-3 b d+12 a e \\\\\n  \\Delta_1 & =2 c^3-9 b c d+27 b^2 e+27 a d^2-72 a c e\n\\end{align*}\n$$\n\nOr representation by\n$$\n\\begin{align*}\n  Q_1 &= c^2 - 3bd + 12e  \\\\\n  Q_2 &= 2c^3 - 9bcd + 27d^2 + 27b^2e - 72ce  \\\\\n  Q_3 &= 8bc - 16d - 2b^3  \\\\\n  Q_4 &= 3b^2 - 8c  \\\\\n  Q_5 &= \\sqrt[3]{\\frac{Q_2}{2} + \\sqrt{\\left(\\frac{Q_2^2}{4} - Q_1^3\\right)}}   \\\\\n  Q_6 &= \\frac{Q_1}{Q_5} + Q_5  \\\\\n  Q_7 &= 2\\sqrt{\\frac{Q_4}{12} + Q_6}   \\\\\n  x_1 &= \\frac{-b - Q_7 - \\sqrt{4\\left(\\frac{Q_4}{6} - Q_6 - \\frac{Q_3}{Q_7}\\right)}}{4} \\\\\n  x_2 &= \\frac{-b - Q_7 + \\sqrt{4\\left(\\frac{Q_4}{6} - Q_6 - \\frac{Q_3}{Q_7}\\right)}}{4} \\\\\n  x_3 &= \\frac{-b + Q_7 - \\sqrt{4\\left(\\frac{Q_4}{6} - Q_6 + \\frac{Q_3}{Q_7}\\right)}}{4} \\\\\n  x_4 &= \\frac{-b + Q_7 + \\sqrt{4\\left(\\frac{Q_4}{6} - Q_6 + \\frac{Q_3}{Q_7}\\right)}}{4}\n\\end{align*}\n$$\n\n### Torus\n\n$$\n\\{\\boldsymbol x \\ |\\ (R^2 - r^2 + \\boldsymbol x^T \\boldsymbol x)^2 - 4 R^2 (\\boldsymbol x^T \\boldsymbol x - x_i^2) = 0\\}  \\tag{Torus}\n$$\n\n<img src=\"./assets/torus-84d2651b-f18b-462b-be8c-436c8ae4c54-resize-750.gif\" alt=\"torus-84d2651b-f18b-462b-be8c-436c8ae4c54-resize-750\" style=\"zoom:50%;\" />\n\n### Tanglecube\n\n$$\n\\left\\{\\boldsymbol x \\ |\\ \\sum_{i=1}^3 \\left(x_i^4 - 5 x_i^2 \\right) + 11.8 = 0 \\right\\}  \\tag{Tanglecube}\n$$\n\n<img src=\"./assets/Tanglecube1_700.svg\" alt=\"Tanglecube1_700\" style=\"zoom:67%;\" />"
    ]
  },
  "Fractal": {
    "define": "A mathematical [set](./Set.md) $F$ is considered self similar if it can be divided into several non empty disjoint subsets, each of which is a scaled, translated, rotated (and possibly also reflective) version of $F $. Specifically, if the set $F$ can be written as\n$$\nF = \\bigcup_{i=1}^{N} w_i(F)\n$$\nWhere $w_i$ is a similarity transformation with a scaling factor less than 1, then $F$ can be considered to have self similarity properties.",
    "kids": {},
    "name": "Fractal",
    "parents": {
      "Set": ""
    },
    "properties": [
      "### Mandelbrot Set & Julia Set\n\n- Define  \n  $$\n  Z_{n+1} = Z_n^2 + C\n  $$\n  \n  $$\n  \\begin{align*}\n    S_\\text{Mandelbrot} &= \\{ C \\ |\\ Z_{n+1} \\text{ non-divergent }, Z_0 = 0 \\}  \\tag{Mandelbrot Set}\\\\\n    S_\\text{Julia, C} &= \\{ Z_0 \\ |\\ Z_{n+1} \\text{ non-divergent } \\}  \\tag{Julia Set}\n  \\end{align*}\n  $$\n  \n  Mandelbrot set is the set of all complex numbers $C$ for which the Mandelbrot iteration remains bounded with $Z_0 = 0$. (non-divergent $\\neq$ convergent, may jump back and forth at several different points)\n\n  <img src=\"./assets/Mandel_zoom_00_mandelbrot_set.jpg\" alt=\"img\" style=\"zoom:10%;\" />\n\n  Julia set is the set of all complex numbers $Z_0$ for which the Mandelbrot iteration remains bounded with a given $C$.\n  \n  <img src=\"./assets/JSr07885.gif\" alt=\"img\" style=\"zoom: 40%;\" />\n  \n- Property\n  - $|Z_n|>2$ impossible to converge. Hence, Mandelbrot Set is in the circle with a radius of 2.\n\n### Newton Fractal    \n\n- Define  \n  $$\n  z_{n+1} = z_n - \\frac{p(z_n)}{p'(z_n)}\n  $$\n\n  Newton fractal is a boundary set in the complex plane which is characterized by Newton's method applied to a fixed polynomial $p(z)$ or transcendental function. \n  \n  <img src=\"./assets/Julia-set_N_z3-1.png\" alt=\"img\" style=\"zoom:12%;\" />"
    ]
  },
  "Function": {
    "define": "$$\nf: X \\to Y  \\tag{Function}\n$$\n$$\n\\forall x \\in X, \\exists_{= 1} y \\in Y, f(x) = y\n$$\nMapping, refer to a [binary relation](./Relation.md) from the element of set $X$ to that of set $Y$, and satisfy any element in $X$ has a unique element in $Y$ corresponding to it (One-to-many is not allowed).\n\n$X$: domain of Definition.\n\n\n### Injective\n\n$$\n\\forall x, x', f(x) = f(x') \\Rightarrow x = x'\n$$\nEach mapped element $y$ has a unique element $x$ corresponding to it.\n\n### Surjection\n\n$$\n\\forall y \\in Y, \\exists x \\in X, f(x) = y\n$$\nEach element $y$ in set $Y$ has a element $x$ in set $X$ corresponding to it.\n\n### Bijection, One-to-One Correspondence\n\n$$\n\\forall y \\in Y, \\exists_{= 1} x \\in X, f(x) = y\n$$\nA map that is both injective and surjective. Each element $y$ in set $Y$ has a unique element $x$ in set $X$ corresponding to it. Meanwhile, each element $x$ in set $X$ has a unique element $y$ in set $Y$ corresponding to it.\n\n<img src=\"assets/R-16983288702011.png\" alt=\"R\" style=\"zoom: 30%;\" />",
    "kids": {
      "Bessel_Function": "",
      "Complex_Value_Function": "",
      "Dirac_Delta_Function": "",
      "Exponential_Function": "",
      "Hilbert_Transform": "",
      "Laplace_Transform": "",
      "Linear_Transformation": "",
      "Polynomial_Function": "",
      "Radon_Translation": "",
      "Real_Value_Function": "",
      "Sequence": ""
    },
    "name": "Function",
    "parents": {
      "Relation": ""
    },
    "properties": [
      "* Inverse Function\n  if $f$ is a bijection, its inverse function is $f^{-1}(b) = a \\Leftrightarrow f(a) = b$"
    ]
  },
  "Gamma_Function": {
    "define": "The gamma function is defined for all complex numbers except the non-positive integers. ([Complex Value Function](./Complex_Value_Function.md)) For every positive integer $n$,\n$$\n\\Gamma(n) = (n-1)!\n$$\nFor complex numbers with a positive real part, the gamma function is defined via a convergent improper integral,\n$$\n\\Gamma(z) = \\int_{0}^\\infty t^{z-1} e^{-t} \\mathrm d t \\quad, \\Re(z) > 0\n$$\n<img src=\"assets/Plot_of_gamma_function_in_complex_plane_in_3D_with_color_and_legend_and_1000_plot_points_created_with_Mathematica.svg\" alt=\"Plot_of_gamma_function_in_complex_plane_in_3D_with_color_and_legend_and_1000_plot_points_created_with_Mathematica\" style=\"zoom:12%;\" />",
    "kids": {},
    "name": "Gamma_Function",
    "parents": {
      "Complex_Value_Function": ""
    },
    "properties": [
      "- Recursion\n  $$\n  \\Gamma(z+1) = z \\Gamma(z)\n  $$\n  \n- Euler's reflection formula\n  $$\n  \\Gamma(1-z)\\Gamma(z) = \\frac{\\pi}{\\sin \\pi z}\n  $$\n\n- $$\n  2^{2 z-1} \\Gamma(z) \\Gamma\\left(z+ \\frac{1}{2}\\right)=\\sqrt{\\pi} \\Gamma(2 z)\n  $$\n  \n  - $$\n    \\Gamma\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}\n    $$\n  \n- Stirling's formula\n  $$\n  \\Gamma(n+1) = n! \\sim \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n\n  $$\n  \n- $$\n  \\begin{align*}\n  \\Gamma(z) &=\\lim _{n \\rightarrow \\infty} \\frac{1 \\cdot 2 \\cdots n}{z(z+1) \\cdots(z+n)} n^{z}  \\\\\n  &= \\frac{e^{-\\gamma z}}{z} \\prod_{n=1}^{\\infty}\\left(1+\\frac{z}{n}\\right)^{-1} e^{\\frac{z}{n}}\n  \\end{align*}\n  $$"
    ]
  },
  "Graph": {
    "define": "$$\n\\begin{align*}\nG &= (V, E)  \\tag{Graph} \\\\\nE &= \\{(v_i, v_j)\\ |\\ v_i, v_j \\in V\\}  \\tag{Edge set}\n\\end{align*}\n$$\n\nGraph is a pair consist of vertex set $V$ and edge set $E$ with weights of edges $w: E \\to \\mathbb R$.\n\n- $V$: Vertex set\n- $E$: Edge set, a set of paired vertices\n- $w: E \\to \\mathbb R$: weight of edge\n\n### Undirected Graph & Directed Graph\n\n$$\n\\begin{align*}\nE &= \\{\\{v_i, v_j\\}\\ |\\ v_i, v_j \\in V\\}  \\tag{Undirected Graph}\\\\\nE &= \\{(v_i, v_j)\\ |\\ v_i, v_j \\in V\\}  \\tag{Directed Graph}\n\\end{align*}\n$$\n\nUndirected Graph, is a type of graph that does not distinguish the direction of edges.\n\nDirected Graph, is a type of graph that distinguish the direction of edges and its edge set is a set of ordered pairs.",
    "kids": {
      "Bipartite_Graph": "",
      "Complete_Graph": "full connected",
      "Directed_Acyclic_Graph": "directed, acyclic",
      "Tree": "undirected, connected, acyclic"
    },
    "name": "Graph",
    "parents": {
      "Set": ""
    },
    "properties": [
      "### Representation by Adjacency Matrix\nDue to the discreteness of vertices, we can represent the weight of edge $w: E \\to \\mathbb R$ by Matrix $\\boldsymbol G \\in \\mathbb R^{n \\times n}$.\n\n$$\n\\boldsymbol G = \\left(\\begin{matrix} w(v_1, v_1) & \\cdots & w(v_1, v_n) \\\\ \\vdots&\\ddots &\\vdots \\\\ w(v_n, v_1) & \\cdots & w(v_n, v_n) \\end{matrix}\\right)\n$$\n\n\n### Degree\nDegree of a node refers to the number of edges connecting this node. \n\n### Connectivity\n\nIn an undirected graph $G=(V, E)$, the graph is said to be connected if there is a path between every pair of vertices. A path is a sequence of vertices where consecutive vertices are adjacent (connected by an edge).\n\nIn a directed graph $G=(V, E)$, the graph is strongly connected if for every pair of vertices $u$ and $v$, there is a directed path from $u$ to $v$ and a directed path from $v$ to $u$.\n\n### Directivity\n\n### Acyclicity\n\n### Euler Path & Euler Graph\n\nEuler path is a path in a graph that passes through every edge exactly once. If the path starts and ends at the same vertex, it is called an Euler circuit. A graph that has an Euler circuit is called an Eulerian graph, while a graph that has an Euler path but not an Euler circuit is called a semi-Eulerian graph. \n\n<img src=\"./assets/48727417-28c3d500-ec58-11e8-9715-33b168a50b7c.png\" alt=\"theory1\" style=\"zoom:20%;\" />\n\n#### Property\nThe existence of an Euler path or circuit in a connected undirected graph depends on the degree of the vertices. For a graph to have an Euler circuit, every vertex must have an even degree. For a connected undirected graph to have an Euler path, exactly two vertices must have an odd degree (all other vertices must have even degree).\n\n\n### Matching of Graph\n\n$$\n\\forall e_i, e_j \\in M \\subseteq E, e_i \\neq e_j \\quad\\Rightarrow\\quad v(e_i, 1) \\neq v(e_i, 2) \\neq v(e_j, 1) \\neq v(e_j, 2)  \\tag{Matching}\n$$\nMatching of a graph is a set of edges $M \\subseteq E$ that have no common points between any two edges.\n\n#### Maximum Matching\n\n$$\nM^* = \\arg\\max_{M} \\quad \\text{number}(M) \\tag{Maximum Matching}\n$$\nMaximum Matching is a matching with the largest number of matching edges among all matches in a graph.\n\n#### Perfect Matching\n\n$$\nV^{(G)} = v(M^*)\n$$\nPerfect Matching is a matching that all vertices of the graph are in it."
    ]
  },
  "Group": {
    "define": "$$\n(G, \\cdot)\n$$\n\nGroup is an algebraic structure, where $G$ is a set, $\\cdot$ is a binary operation, and satisfy:\n\n- closure: $a, b \\in G \\Rightarrow a \\cdot b \\in G$\n- associative law $(a \\cdot b) \\cdot c = a \\cdot (b \\cdot c)$\n- exists identity element, $\\exists 1: x \\cdot 1 = 1 \\cdot x = x$\n- exists inverse element, $\\exists x^{-1}: x \\cdot x^{-1} = x^{-1} \\cdot x = 1$",
    "kids": {
      "Lie_Group": "",
      "Symmetric_Group": ""
    },
    "name": "Group",
    "parents": {
      "Algebra_Structure": ""
    },
    "properties": [
      "- $1$ is unique\n  - Proof  \n    $$\n    1_1 = 1_1 \\cdot 1_2 = 1_2\n    $$\n- The inverse of each element is unique.\n- Absorbing Element\n  $$\n  x \\cdot 0 = 0 \\cdot x = 0  \\quad; \\forall x \\in G  \\tag{absorbing element}\n  $$\n- 1 \n  - $\\forall a \\in G, (a^{-1})^{-1} = a$\n  - $\\forall a,b \\in G, (a \\cdot b)^{-1} = b^{-1} \\cdot a^{-1}$\n  - $\\forall a,b,c \\in G, a\\cdot b = a \\cdot c  \\quad\\Rightarrow\\quad b = c$\n  - $\\forall a,b,c \\in G, b\\cdot a = c \\cdot a  \\quad\\Rightarrow\\quad b = c$ \n\n### Subgroup\n\n- Define  \n  $$\n  H \\subseteq G, H \\neq \\emptyset, (H, \\cdot) \\text{ is group } \\quad\\Rightarrow\\quad H \\le G  \\tag{Subgroup}\n  $$\n\n  For a group $(G, \\cdot)$ and a nonempty subset $H$ of $G$, if $(H, \\cdot)$ is also group, then $(H, \\cdot)$ is a subgroup of $(G, \\cdot)$.\n\n- Property  \n  - $1 \\le G, G \\le G$\n\n  * Coset\n    - Define\n      For a subgroup $H$ of the group $G$ and an element $g \\in G$, the left cosets of $H$ in $G$ are the sets obtained by multiplying each element of $H$ by a fixed element $g$ (where $g$ is the left factor).\n      $$\n      gH = \\{gh \\ |\\ h \\in H\\} \\quad, \\text{for } g \\in G  \\tag{left cosets}\n      $$\n\n      The right cosets are defined similarly, except that the element g is now a right factor.\n      $$\n      Hg = \\{hg \\ |\\ h \\in H\\} \\quad, \\text{for } g \\in G  \\tag{right cosets}\n      $$\n\n    - Property\n\n      - Cosets form a partition of group $G$, that is, they divide $G$ into several disjoint sets. \n\n        Each coset of subgroup $H$ have the same number of elements as the subgroup $H$. Two cosets are either identical or completely disjoint. \n\n  * The size of any subgroup $H$ of a finite group $G$ can be divided by the size of $G$.\n    $$\n    |H|\\ |\\ |G|\n    $$\n\n#### Normal Subgroup\n\n- Define\n  $$\n  H \\lhd G \\quad\\Leftrightarrow\\quad  g^{-1}hg \\in H, \\forall h \\in H \\le G, g \\in  G \\tag{Normal Subgroup}\n  $$\n  Normal Subgroup is a subgroup $H \\le G$ if it is invariant under conjugation, that is, $\\forall h \\in H, g \\in G$, we have $g^{-1}hg \\in H$.\n\n- Property\n  * Quotient Group\n  \n    * Define\n  \n      Given a group $G$ and a normal subgroup $H \\lhd G$, the Quotient Group $G/H$ is a group composed of all left cosets of $H$ in $G$ as elements $\\{aH \\ |\\ a \\in G\\}$ and multiplication operations $(g_1 H) \\cdot (g_2 H) = g_1 g_2 H, \\forall g_1, g_2 \\in G$.\n      $$\n      (\\{aH \\ |\\ a \\in G\\}, \\cdot)  \\\\\n      $$\n  \n    - Property\n  \n      - The unit element of the quotient group $G/N$ is $N$ itself\n  \n      $$\n      gN \\cdot N = gN\n      $$\n  \n      - $|G/H| = \\frac{|G|}{|H|}$\n\n### Group Homomorphism\n\n- Define\n  $$\n  f: G \\to H\n  $$\n  Group Homomorphism is a function $f$ from a group $(G, \\cdot)$ to another group $(H, *)$ such that for all $u, v \\in G$ it hold that,\n  $$\n  f(u \\cdot v) = f(u) * f(v) \\quad, \\forall u, v \\in G\n  $$\n\n- Property\n  * Isomorphism of Groups  \n    If Group Homomorphism of $G, H$ is a Bijection, the groups $G, H$ are called isomorphic.\n\n### Simple Group\n\n- Define\n\n  A simple group is a group $G$ whose only normal subgroups are the trivial group $\\{e\\}$ (a trivial group or zero group is a group consisting of a single element $e$) and the group itself.\n\n- Property\n\n  - Classification of finite simple groups\n\n    Every finite simple group is isomorphic to one of the following groups\n\n    - a member of one of three infinite classes of such, namely:\n      - the cyclic groups of prime order,\n      - the alternating groups of degree at least 5,\n      - the groups of Lie type,\n      - the derivative of the groups of Lie Type, such as the Tits group\n    - one of 26 groups called the \"sporadic groups\"\n  \n    <img src=\"./assets/gn5cimd92mh11.jpg\" alt=\"gn5cimd92mh11\"  />\n\n### Commutative Group , Abelian Group\n\n- Define\n  Commutative Group is a Group satisfied commutative law,\n  $$\n  a \\cdot b = b \\cdot a\n  $$\n\n### Cyclic Group\n\n- Define\n\n  A group $G$ is called cyclic if there exists an element $a \\in G$ such that every element of $G$ can be expressed as a power of $a$. ln other words, every element in $G$ is of the form $a$ for some integer $k$. The element a is called a generator of the group.\n  $$\n  \u27e8g\u27e9 = \\{g^k \\ |\\ k \\in \\mathbb Z\\}\n  $$\n\n\n### Alternating Group\n\n- Define\n\n  An alternating group $A_n$ on a set of $n$ symbols is defined to be the group of all even permutations of the $n$ symbols. (The even arrangement here refers to an arrangement that can be obtained from an identical arrangement through even number of exchanges.)\n\n- Property\n  - $A_n$ is a normal group of $S_n$. $|A_n| = \\frac{1}{2} |S_n|$.\n  - For $n>5$, $A_n$ is a simple group."
    ]
  },
  "Hausdorff_Space": {
    "define": "Hausdorff Space $X$ is a topology space where, for any distinct points $x, y \\in X$, there exist a neighborhood $U$ of $x$ and a neighborhood $V$ of $y$ such that $U$ and $V$ are disjoint.\n\n$$\nU \\cap V = \\emptyset\n$$",
    "kids": {
      "Manifold": ""
    },
    "name": "Hausdorff_Space",
    "parents": {
      "Topological_Space": ""
    },
    "properties": [
      ""
    ]
  },
  "Hilbert_Space": {
    "define": "Hilbert Space, is the Intersection of [Complete Metric Space](./Metric_Space.md) and [Inner Product Space](./Inner_Product_Space.md).",
    "kids": {
      "Euclidean_Space": ""
    },
    "name": "Hilbert_Space",
    "parents": {
      "Inner_Product_Space": "",
      "Metric_Space": ""
    },
    "properties": [
      ""
    ]
  },
  "Hilbert_Transform": {
    "define": "[**Hilbert transform**](./Function.md) of $u(t)$ can be thought of as the convolution of $u(t)$ with the function $h(t) = \\frac{1}{\\pi t}$, known as the Cauchy kernel. Because $1/t$ is not integrable across $t = 0$, the integral defining the convolution does not always converge. Instead, the Hilbert transform is defined using the Cauchy principal value (denoted here by $p.v.$).\n$$\nH(u)(t) = p.v.\\frac{1}{\\pi}\\int_{-\\infty}^{+\\infty} \\frac{u(\\tau)}{t-\\tau}\\mathrm{d}\\tau\n$$",
    "kids": {},
    "name": "Hilbert_Transform",
    "parents": {
      "Function": ""
    },
    "properties": [
      "- $H(H(u))(t) = u(-t)$\n- $H(\\omega) = (-i \\cdot \\text{sgn}(\\omega))\\cdot \\mathcal F_h(\\omega)$"
    ]
  },
  "Holomorphic_Function": {
    "define": "A holomorphic function is a complex-valued function on an open set $U$ if it is complex differentiable at every point of $U$.",
    "kids": {},
    "name": "Holomorphic_Function",
    "parents": {
      "Complex_Value_Function": ""
    },
    "properties": [
      "Holomorphic functions are differentiable everywhere within their domain of definition.\n\n$$\n\\frac{\\partial f}{\\partial \\bar z} = 0\n$$\n\n* Cauchy-Riemann Equations\n  \n\nFor a complex function $f(z) = u(x,y) + i v(x,y)$ to be differentiable (and hence analytic) at a point, where $u(x,y)$ and $v(x,y)$ are real and imaginary part respectively, the partial derivatives of $u, v$ must satisfy the Cauchy-Riemann equations at that point:\n$$\n\\frac{\\partial u}{\\partial x} = \\frac{\\partial v}{\\partial y}  \\\\ \\quad \\frac{\\partial u}{\\partial y} = -\\frac{\\partial v}{\\partial x} \\tag{Cauchy-Riemann Equations}\n$$"
    ]
  },
  "Hypergeometric_Function": {
    "define": "$$\n{}_pF_q(a_1, \\cdots, a_p;b_1, \\cdots, b_q;z) = \\sum_{n=0}^\\infty \\frac{(a_1)_n (a_2)_n  \\cdots (a_p)_n}{(b_1)_n (b_2)_n \\cdots (b_q)_n} \\frac{z^n}{n!}\n$$\n\nThe hypergeometric function is defined for $|z| < 1$ by the power series. ([Complex Value Function](./Complex_Value_Function.md)) It is undefined (or infinite) if c equals a non-positive integer. Here (q)n is the (rising) Pochhammer symbol, which is defined by:\n$$\n(q)_{n}={\\begin{cases}1&n=0\\\\q(q+1)\\cdots (q+n-1)&n>0\\end{cases}}\n$$\n<img src=\"assets/Plot_of_the_hypergeometric_function_2F1(a,b;_c;_z)_with_a=2_and_b=3_and_c=4_in_the_complex_plane_from_-2-2i_to_2+2i_with_colors_created_with_Mathematica_13.1_function_ComplexPlot3D.svg\" alt=\"Plot_of_the_hypergeometric_function_2F1(a,b;_c;_z)_with_a=2_and_b=3_and_c=4_in_the_complex_plane_from_-2-2i_to_2+2i_with_colors_created_with_Mathematica_13.1_function_ComplexPlot3D\" style=\"zoom:25%;\" />",
    "kids": {},
    "name": "Hypergeometric_Function",
    "parents": {
      "Complex_Value_Function": ""
    },
    "properties": [
      "- Differentiation formulas\n  $$\n  \\begin{align*}\n  \\frac {\\mathrm d}{\\mathrm dz} F(a,b;c;z) &= \\frac {ab}{c} F(a+1,b+1;c+1;z)  \\\\\n  \\frac {\\mathrm d^{n}}{\\mathrm dz^{n}} F(a,b;c;z) &= \\frac {(a)_{n}(b)_{n}}{(c)_{n}} F(a+n,b+n;c+n;z)\n  \\end{align*}\n  $$\n\n- Special cases\n  $$\n  \\begin{align*}\n  e^z &= F(;;-z)  \\\\\n  \\ln(1+z) &= z F(1, 1;2;-z)\\\\\n  (1+z)^\\alpha &= F(-\\alpha;;-z)  \\\\\n  \\sin z &= z F(;\\frac{3}{2};-{z^2}{4})  \\\\\n  \\cos z &= F(;\\frac{1}{2};-{z^2}{4})  \\\\\n  \\arcsin z &= z F(\\frac{1}{2}, \\frac{1}{2};\\frac{3}{2};z^2)  \\\\\n  \\arccos z &= z F(\\frac{1}{2}, 1;\\frac{3}{2};-z^2)  \\\\\n  \\end{align*}\n  $$"
    ]
  },
  "Inner_Product_Space": {
    "define": "The [Normed Linear Space](./Normed_Linear_Space.md) of inner product is defined.\n\n### Inner Product\n\nOperations that meet the following conditions:\n- Commutative:$\\left<x, y\\right> = \\overline{\\left<y, x\\right>}$\n- Distributive:$\\left<x, y+z\\right> = \\left<x , y\\right> + \\left<x, z\\right>$\n- Homogeneity:$\\left<k x, y\\right> = k \\left<x, y\\right>$\n- Nonnegativity:$\\left<x,x\\right> \u2265 0$, if and only if $x = 0, \\left<x,x\\right> = 0$",
    "kids": {
      "Convolution": "",
      "Hilbert_Space": ""
    },
    "name": "Inner_Product_Space",
    "parents": {
      "Normed_Linear_Space": ""
    },
    "properties": [
      "- $x, y \\text{orthogonal} \\Leftrightarrow \\left<x,y\\right> = 0$\n- $|\\left<x, y\\right>| \u2264 |x| |y|$\n- $\\left<x, y \\right> = x^T y = |x| |y| cos(\\theta_{x,y})$\n- Geometric Interpretation:  \n$\\left<x, y \\right>$ means the length of $x$ projection toward $y$ multiply length of $y$; or the length of $y$ projection toward $x$ multiply length of $x$.\n- Example\n  * Laplace Transform\n  * Wavelet Transform\n  * Cross Correlation & Convolution"
    ]
  },
  "Integer_Ring": {
    "define": "Ring of Integers is a kind of Integral Domain (\u6574\u73af).\n$$\n\\mathbb Z\n$$\n\nAn **integer** can be defined as an equivalence class of ordered pairs of natural numbers $(a, b)$, where $a$ and $b$ are [natural numbers](./Natural_Number.md), under the following equivalence relation:\n\n- Two ordered pairs $(a, b)$ and $(c, d)$ are considered equivalent if and only if $a + d = b + c$. (the difference between two natural numbers)\n\n$$\n(\\mathbb Z, +, \\cdot)\n$$\n$$\n\\forall a, b \\in \\mathbb Z, a \\cdot b = 0 \\quad\\Rightarrow\\quad  (a = 0 \\vee b = 0)  \\tag{no zero divisor}\n$$\nIntegral ring is a nonzero commutative [ring](./Ring.md) in which the product of any two nonzero elements is nonzero.\n\n- **Addition:** To add two integers represented by $[a, b]$ and $[c, d]$, define their sum as $[a + c, b + d]$. This is equivalent to adding the two 'positive' parts and the two 'negative' parts separately.\n  \n- **Negation:** The negation of an integer represented by $[a, b]$ is $[b, a]$, reflecting the idea of $ -(a - b) = b - a $.\n  \n- **Multiplication:** To multiply two integers represented by $[a, b]$ and $[c, d]$, define their product as $[ac + bd, ad + bc]$. This captures the distributive property over the components of the ordered pairs.",
    "kids": {
      "Division_with_Remainder": "",
      "Mobius_Function": "",
      "Rational_Number_Field": ""
    },
    "name": "Integer_Ring",
    "parents": {
      "Natural_Number": "",
      "Ring": ""
    },
    "properties": [
      "### Division with Remainder & Factor\n\n### Multiplicative Function\n\n- Define  \n  A mapping $f: \\mathbb Z \\to \\mathbb R$, such that\n  $$\n  f(a \\times b) = f(a) f(b) \\quad \\text{when}\\ a, b \\in \\mathbb Z, gcd(a, b) = 1\n  $$\n\n- Property\n  - $f(1) = 1$\n\n- Example\n  * Eular Function\n    - Define  \n      The number of coprimes with $n$ in positive integers less than $n$.\n      $$\n      \\phi(n) = \\text{number}(\\{i\\ |\\ i \\in 1:n, \\text{GCD}(i, n) = 1\\})\n      $$\n\n    - Property\n      $$\n      \\begin{align*}\n        n &= \\prod_i p_i^{k_i}  \\\\\n        \\phi(n) &= n \\prod_{p|n} (1 - 1/p)  \n      \\end{align*}\n      $$\n\n  * [M\u00f6bius Function](./Mobius_Function.md)\n\n### Fermat's Last Theorem\n\nNo three positive integers $a, b, c$ satisfy the equation $a^n + b^n = c^n$ for any integer value of $n$ greater than $2$. The cases $n = 1$ and $n = 2$ have been known since antiquity to have infinitely many solutions."
    ]
  },
  "Knot": {
    "define": "A knot is an embedding of the circle into [three-dimensional Euclidean space](./Euclidean_Space.md) $S^1 \\to \\mathbb R^3$, or the 3-sphere $S^3$, since the 3-sphere is compact. Two knots are defined to be equivalent if there is an ambient isotopy between them.\n\n<img src=\"./assets/78a8406c7fac2177fb53bb8c5099e4d3.jpg\" alt=\"img\" style=\"zoom: 35%;\" />",
    "kids": {},
    "name": "Knot",
    "parents": {
      "Euclidean_Space": ""
    },
    "properties": [
      "### Knot Diagram\n\nA knot diagram is a visual representation of a knot, which is a projection of Knot on a plane, where each crossing point is marked as \"over\" or \"under\" to indicate which part is above and which part is below.\n\n<img src=\"./assets/2048px-TrefoilKnot_01.svg.png\" alt=\"img\" style=\"zoom:4%;\" />\n\n### Knot isotopy (Ambient isotopy)\n\nTwo knots are considered equivalent if one can be deformed into the other without cutting or gluing.\n\n### Reidemeister move\n\nReidemeister move are a set of three local transformations that can be applied to a knot diagram without changing the underlying knot's equivalence class. Each move operates on a small region of the diagram and is one of three types:\n\n1. Twist and untwist in either direction.\n2. Move one loop completely over another.\n3. Move a string completely over or under a crossing.\n\n<img src=\"./assets/Reidemeister-moves-Top-Row-Reidemeister-Moves-I-and-II-Bottom-Row-Reidemeister-Move.png\" alt=\"Reidemeister moves. Top Row: Reidemeister Moves I and II. Bottom Row ...\" style=\"zoom:25%;\" />\n\n- **Unknotting Theorem**: Any knot can be transformed into its simplified form through a series of Reidemeister movements.\n\n### Knot Invariants\n\nKnot invariants are used to determine whether two knots are equivalent or not.\n\n- **Jones Polynomial**\n\n  Given an oriented link diagram $D$, the Jones polynomial $V(D)$ can be defined recursively using the following relations:\n  1. $V(\\text{Unknot}) = 1$\n  2. $t^{-1} V(L_+) - t V(L_-) = (t^{1/2} - t^{-1/2}) V(L_0)$\n\n  Where $L_+, L_-, L_0$ are link diagrams that are identical outside a small region, and within that region look like:\n\n  - $L_+$: A positive crossing.\n  - $L_-$: A negative crossing.\n  - $L_0$: The two segments are resolved without a crossing.\n\n  The above recursive relations allow for the calculation of the Jones polynomial of a given link diagram by expanding it in terms of simpler diagrams until reaching the unknot.\n\n- **HOMFLY Polynomial**"
    ]
  },
  "Laplace_Transform": {
    "define": "Laplace Transform $f: (f: \\mathbb C \\to \\mathbb C) \\times \\mathbb C \\to \\mathbb C$\n$$\n\\mathcal L_{f(t)}(s) = \\int_0^{\\infty} f(t) e^{-st} \\mathrm d t\n$$\n\n$$\n\\mathcal L^{-1}_{F(s)}(t) = \\frac{1}{2 \\pi \\mathrm i} \\int_{\\real(s) - \\mathrm i \\infty}^{\\real(s) + \\mathrm i \\infty} F(s) e^{st} \\mathrm d s  \\tag{inverse Laplace transform}\n$$\n\nA type of [function](./Function.md)",
    "kids": {},
    "name": "Laplace_Transform",
    "parents": {
      "Function": ""
    },
    "properties": [
      ""
    ]
  },
  "Lattice": {
    "define": "$$\n(L, \\wedge, \\vee)\n$$\n\nLattice is a concept of partially ordered sets, which is a special type of [algebraic structure](./Algebra_Structure.md) that can define minimum upper and maximum lower bounds on certain sets.\u4e00\u4e2a\u683c $L$ \u662f\u4e00\u4e2a\u96c6\u5408\uff0c\u914d\u5408\u4e24\u4e2a\u4e8c\u5143\u8fd0\u7b97meet $\\wedge$\u548c join $\\vee$\uff0c\u6ee1\u8db3\u4ee5\u4e0b\u516c\u7406\uff1a\n\n1. **\u4ea4\u6362\u5f8b**\uff1a$\\forall a, b \\in L$\uff0c\u6709 $a \\wedge b = b \\wedge a$ \u548c $a \\vee b = b \\vee a$\n2. **\u7ed3\u5408\u5f8b**\uff1a$\\forall a, b, c \\in L$\uff0c\u6709 $a \\wedge (b \\wedge c) = (a \\wedge b) \\wedge c$ \u548c $a \\vee (b \\vee c) = (a \\vee b) \\vee c$\n3. **\u5438\u6536\u5f8b**\uff1a$\\forall a, b \\in L$\uff0c\u6709 $a \\wedge (a \\vee b) = a$ \u548c $a \\vee (a \\wedge b) = a$\n4. **\u5e42\u7b49\u5f8b**\uff1a$\\forall a \\in L$\uff0c\u6709 $a \\wedge a = a$ \u548c $a \\vee a = a$\n\n\u5728\u683c\u4e2d\uff0c\u4efb\u610f\u4e24\u4e2a\u5143\u7d20 $a$ \u548c $b$ \u7684\u201cmeet\u201d $a \\wedge b$ \u662f\u5b83\u4eec\u6240\u6709\u4e0b\u754c\u7684\u6700\u5927\u8005\uff0c\u800c\u5b83\u4eec\u7684\u201cjoin\u201d $a \\vee b$ \u662f\u5b83\u4eec\u6240\u6709\u4e0a\u754c\u7684\u6700\u5c0f\u8005\u3002",
    "kids": {
      "Boolean_Algebra": ""
    },
    "name": "Lattice",
    "parents": {
      "Algebra_Structure": ""
    },
    "properties": [
      ""
    ]
  },
  "Lie_Group": {
    "define": "A real Lie group is a [group](./Group.md) that is also a finite-dimensional real smooth [manifold](./Manifold.md), in which the group operations of multiplication and inversion are smooth maps. Smoothness of the group multiplication means that \u03bc is a smooth mapping of the product manifold G \u00d7 G into G.\n$$\n\\mu: G \\times G \\to G, \\mu(x,y) = xy\n$$",
    "kids": {},
    "name": "Lie_Group",
    "parents": {
      "Group": "",
      "Manifold": ""
    },
    "properties": [
      "### Lie Algebra"
    ]
  },
  "Linear_Function": {
    "define": "$$\n\\begin{align*}\n  f(x) &= a x + b \\tag{Univariate}  \\\\\n  f(\\boldsymbol x) &= \\boldsymbol A \\boldsymbol x + \\boldsymbol b  \\tag{Multivariate}\n\\end{align*}\n$$",
    "kids": {},
    "name": "Linear_Function",
    "parents": {
      "Polynomial_Function": ""
    },
    "properties": [
      "### Zero Set of Linear Function & Plane & Linear Surface \n\n$$\n\\{\\boldsymbol x \\ |\\ \\boldsymbol A \\boldsymbol x = \\boldsymbol b \\}\n$$\n\n### Problem: Solving Linear Equations \n\n$$\n\\boldsymbol A \\boldsymbol x = \\boldsymbol b\n$$\n\nKnow $\\boldsymbol A, \\boldsymbol b$ and Solve $\\boldsymbol x$. Where, $\\boldsymbol A \\in \\mathbb R^{m \\times n}$, $\\boldsymbol x \\in \\mathbb R^{n}$, $\\boldsymbol b \\in \\mathbb R^m$, $n$ is the number of unknown number, $m$ is the number of linear equations.\n\n#### Property: Existence of Solutions  \n\n$$\n\\begin{align*}\n  \\left\\{\\begin{matrix}\n    rank((\\boldsymbol A\\ \\boldsymbol b)) = rank(\\boldsymbol A) &= n& \\quad \\text{Unique Solution}  \\\\\n    rank((\\boldsymbol A\\ \\boldsymbol b)) = rank(\\boldsymbol A) &< n& \\quad \\text{Infinite Solutions}  \\\\\n    rank((\\boldsymbol A\\ \\boldsymbol b)) > rank(\\boldsymbol A) &&\\quad \\text{Unsolvable}\n  \\end{matrix}\\right.\n\\end{align*}\n$$\n\n- Proof \n  if $rank((\\boldsymbol A\\ \\boldsymbol b)) > rank(\\boldsymbol A)$ \n  $\\Rightarrow$ $(\\boldsymbol a_1,...,\\boldsymbol a_n)$ and $b$ is linearly independent \n  $\\Rightarrow$ $\\nexists \\boldsymbol x \\in \\mathbb R^{n}$ let $x_1 \\boldsymbol a_1 + ... + x_n \\boldsymbol a_n = b$. \n  $\\Rightarrow$ Unsolvable\n\n  if $rank((\\boldsymbol A\\ \\boldsymbol b)) = rank(\\boldsymbol A) < n$ \n  $\\Rightarrow$ $\\exists u \\in \\mathbb R^{n-1}, k \\in [1, n]$ let $\\boldsymbol a_k = \\sum\\limits_{i=1,i\\neq k}^n u_i \\boldsymbol a_i$ \n  $\\Rightarrow$ $\\exists c_1, c_2 \\in \\mathbb R, c_1 + c_2 = 1$ and $\\exists x^*$ is a special solution, let $b = \\left(c_1 x_k^* a_k + c_2 x_k^* \\sum\\limits_{i=1,i\\neq k}^n u_i \\boldsymbol a_i \\right) + \\sum\\limits_{i=1,i\\neq k}^n x_i^* \\boldsymbol a_i$ \n  $\\Rightarrow$ Infinite Solutions\n\n  for the same reason, if $rank((\\boldsymbol A\\ \\boldsymbol b)) = rank(\\boldsymbol A) = n$ \n  $\\Rightarrow$ Unique Solution\n\n#### Solving  \n\n- **Unique Solution**\n  if $rank(\\boldsymbol A) = n$ , then $\\boldsymbol A^{-1}$ exists and\n  $$\n  \\boldsymbol x = \\boldsymbol A^{-1} \\boldsymbol b\n  $$\n  \n- **Infinite Solutions**\n  General Solution $\\boldsymbol x = \\boldsymbol A^{-^{\\{1\\}}} \\boldsymbol b + (\\boldsymbol I - \\boldsymbol A^{-^{\\{1\\}}} \\boldsymbol A) \\boldsymbol c$ \n  Special Solution $\\boldsymbol x = \\boldsymbol A^{-^{\\{1\\}}} \\boldsymbol b$  \n\n  Minimal Norm Solution. The minimum norm solution is unique.\n  $$\n  \\begin{align*}\n    \\min_{\\boldsymbol x} \\quad& ||\\boldsymbol x||_2  \\\\\n    s.t. \\quad& \\boldsymbol A \\boldsymbol x = \\boldsymbol b\n  \\end{align*}\n  $$\n  $$\n  \\boldsymbol x = \\boldsymbol A^{-^{\\{1,3\\}}} \\boldsymbol b\n  $$\n  \n- **Unsolvable**\n  Approximate solution $\\tilde{\\boldsymbol x}$ by giving the evaluation function, such as least square,\n  $$\n  \\min_{\\tilde{\\boldsymbol x}} \\quad ||\\boldsymbol A \\tilde{\\boldsymbol x} - \\boldsymbol b||_2\n  $$\n  $$\n  \\tilde{\\boldsymbol x} = \\boldsymbol A^{-^{\\{1,4\\}}} \\boldsymbol b\n  $$\n\n  Minimal norm Approximate solution $\\tilde{\\boldsymbol x}$ by least square,\n  $$\n  \\begin{align*}\n    \\min_{\\tilde{\\boldsymbol x}} \\quad& ||\\boldsymbol A \\tilde{\\boldsymbol x} - \\boldsymbol b||_2  \\\\\n    \\min_{\\tilde{\\boldsymbol x}} \\quad& ||\\tilde{\\boldsymbol x}||_2\n  \\end{align*}\n  $$\n  \n  $$\n  \\tilde{\\boldsymbol x} = \\boldsymbol A^+ \\boldsymbol b\n  $$"
    ]
  },
  "Linear_Space": {
    "define": "$$\n(\\mathbb R, V, +, \\cdot)  \\tag{Linear Space}\n$$\nLinear Space is a special [module](./Module.md) including non empty set $V$ with addition and scalar multiplication, and satisfying:\n\n- Additive Closure: $x+y \\in V$\n- Scalar Multiplication Closure: $k x \\in V$\n- Identity element of vector addition: $x+0=x$\n- Inverse elements of vector addition: $x+(-x) = 0$\n- Identity element of scalar multiplication: $1x = x$\n- Commutativity of vector addition: $x+y = y+x$\n- Associativity of vector addition: $x+(y+z) = (x+y) +z$\n- Compatibility of scalar multiplication with field multiplication: $a(bx) = (a b)x$\n- Distributivity of scalar multiplication with respect to vector addition: $a(x+y) = a x + a y$\n- Distributivity of scalar multiplication with respect to field addition: $(a+b)x = ax+bx$",
    "kids": {
      "Affine_Space": "",
      "Linear_Transformation": "",
      "Normed_Linear_Space": "",
      "Projective_Space": "",
      "Tensor": ""
    },
    "name": "Linear_Space",
    "parents": {
      "Module": ""
    },
    "properties": [
      "### Representation: Base \n\n$$\n\\begin{align*}\n  \\boldsymbol v \n  &= \\sum_{i=1}^n a_i \\boldsymbol x_i \\quad, \\forall \\boldsymbol v \\in V  \\\\\n  &= \\boldsymbol X \\boldsymbol a\n\\end{align*}\n$$\nBase is a linearly independent vector group $\\boldsymbol X = (\\boldsymbol x_1, ... , \\boldsymbol x_n)$, All vectors in the linear space are linear combinations of the vector group.\n\n- $\\boldsymbol x_i$: Base vector\n- $a_i$: coordinate\n\n#### Base Transformation & Coordinate Transformation\n\nBase transformation, is a transformation between new bases $\\boldsymbol Y$ and old bases $\\boldsymbol X$, where $\\boldsymbol C$ is the Transformation Matrix.\n$$\n\\boldsymbol Y = \\boldsymbol X \\boldsymbol C\n$$\n\nCoordinate Transformation, is solving a new coordinate $\\boldsymbol a_y$ in new base $\\boldsymbol Y$ from old coordinate $\\boldsymbol a_x$ in old base $\\boldsymbol X$.\n$$\n\\boldsymbol a_x = \\boldsymbol C \\boldsymbol a_y\n$$\n\n> Proof\n> \n> $$\n> \\begin{align*}\n>   \\boldsymbol v \n>   &= \\boldsymbol X \\boldsymbol a_x  \\\\\n>   &= \\boldsymbol Y \\boldsymbol a_y  \\\\ \n>   &= \\boldsymbol X \\boldsymbol C \\boldsymbol a_y  \\\\ \n>   \\Rightarrow \\boldsymbol a_x &= \\boldsymbol C \\boldsymbol a_y\n> \\end{align*}\n> $$\n\n\n- Property\n  The base transformation matrix $\\boldsymbol C$ is nonsingular.\n\n\n#### Dimension  \nIn linear space, the maximum number of vectors contained in a linearly independent vector group.\n\n#### Span\n$$\nSpan(\\boldsymbol x_1,...,\\boldsymbol x_n) = \\left\\{\\boldsymbol v | \\boldsymbol v = \\sum_{i=1}^n a_i \\boldsymbol x_i \\right\\}\n$$\nA representation of a linear space given by a basis vector.\n\n\n### Representation\n\n#### Vector\n\n$$\n\\mathbb R^{n}, n \\in \\mathbb Z\n$$\nA vector is a one-dimensional array of numbers. It can be represented as a row or a column.\n\n#### Matrix \n\n$$\n\\mathbb R^{m \\times n}, m, n \\in \\mathbb Z\n$$\n\n$$\n\\boldsymbol A = \\left(\\begin{matrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{matrix}\\right)\n$$\n\n\n\nA matrix is a two-dimensional array of numbers, symbols, or expressions, arranged in rows and columns.\n\n##### Operations\n\n- Addition:\n\n$$\n\\boldsymbol A_{m \\times n} + \\boldsymbol B_{m \\times n} = \\boldsymbol C_{m \\times n}  \\tag{addition}\n$$\n$$\nc_{ij} = a_{ij} + b_{ij}\n$$\n\n- Scalar multiplication,\n\n$$\nk \\boldsymbol A_{m \\times n} = (k a_{ij})_{m \\times n}  \\tag{scalar multiplication}\n$$\n\n\n  - multiplication\n    $$\n    \\boldsymbol A_{m \\times n} \\times \\boldsymbol B_{n \\times p} = \\boldsymbol C_{m \\times p}\n    $$\n    $$\n    c_{ij} = \\sum_{k \\in 1:n} a_{ik} b_{kj}\n    $$\n\n  - multiplication of elements, Hadamard product\n    $$\n    \\boldsymbol A_{m \\times n} \\odot \\boldsymbol B_{m \\times n} = \\boldsymbol C_{m \\times n}\n    $$\n    $$\n    c_{ij} = a_{ij} b_{ij}\n    $$\n\n### Linear Independence & Linear Dependence\n\nFor a vector group $(\\boldsymbol x_1, ... , \\boldsymbol x_n)$, we said  \n\nLinear Independence,\n$$\n\\nexists\\ \\boldsymbol a \u2260 \\boldsymbol 0 \\Rightarrow \\sum_{i=1}^n a_i \\boldsymbol x_i = \\boldsymbol 0\n$$\n\nLinear Dependence,\n$$\n\\exists\\ \\boldsymbol a \u2260 \\boldsymbol 0 \\Rightarrow \\sum_{i=1}^n a_i \\boldsymbol x_i = \\boldsymbol 0\n$$\n\n### Linear Subspace\n\nA nonempty set in a linear space that is closed to linear operations.\n\n- Additive Closure: $x,y\\in V_1 ,\\quad x+y \\in V_1$\n- Scalar Multiplication Closure: $x \\in V_1, k x \\in V_1$\n\n### Dual Space\n\n$$\nV^*=\\left\\{f:V\\rightarrow \\mathbb R \\mid f \\text{ is a linear map}\\right\\}\n$$\n\nLet $V$ be a vector space over a field $\\mathbb R $, the dual space $V^*$ of $V$ is the vector space of all linear functionals from $f: V \\to \\mathbb R$ called dual vector. For a finite-dimensional column vector, its dual vector is in the form of a row vector.\n$$\n\\left(\\begin{matrix}v^*_1  & \\cdots & v^*_n\\end{matrix} \\right) \\left(\\begin{matrix}v_1 \\\\ \\vdots \\\\ v_n\\end{matrix} \\right) = a \\in \\mathbb R\n$$\n\n### Matrix Decomposition\n\n#### LU decomposition\n\n$$\nA = L R\n$$\n\nThe matrix $A$ is decomposed into the product of upper triangular matrix $R$ and lower triangular matrix $L$.\n\n#### Upper and lower triangular diagonal decomposition\n\n\u5c06\u77e9\u9635A\u5316\u6210\u4e0a\u4e09\u89d2\u77e9\u9635R, \u5bf9\u89d2\u77e9\u9635D, \u4e0b\u4e09\u89d2\u77e9\u9635L\u7684\u4e58\u79ef.$A = L D R$\n\n#### Symmetric triangular decomposition\n\n$$\nA = G G^T\n$$\n\n\u5c06\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u5316\u6210\u5bf9\u79f0\u7684\u4e24\u4e2a\u4e0a\u4e0b\u4e09\u89d2\u77e9\u9635.\n\n- Algorithm\n  - first LU decomposition\n    Because symmetric positive definite matrix\n    $$A = L D U = L D L^T$$\n    $$\n    \\begin{align*}\n      A &= L (\\sqrt{D})^2 L^T  \\\\\n        &= (L \\sqrt{D}) (\\sqrt{D} L^T)  \\\\\n        &= (L \\sqrt{D}) (L \\sqrt{D})^T  \\\\\n        &= G G^T\n    \\end{align*}\n    $$\n\n#### QR decomposition\n\n$$\nA = Q R\n$$\n\nThe nonsingular matrix A is decomposed into the product of orthogonal matrix Q and nonsingular upper triangular matrix R\n\n##### Algorithm\n\n- Schmidt Orthogonalization method\n  - $A = (a_1, ..., a_n)$\n  - Schmidt Orthogonalization\n    $$\n    b_i = a_i - \\sum_{k=1}^{i-1} \\frac{<a_i,b_j>}{<b_j,b_j>}b_j\n    $$\n    \n    $$\n    \\begin{align*}\n      Q &= ( \\frac{b_1}{|b_1|}, ... , \\frac{b_n}{|b_n|} )  \\\\\n      R &= \\left(\\begin{matrix} |b_1|\\\\ & \\ddots\\\\ && |b_n| \\end{matrix}\\right) \\left(\\begin{matrix} 1 & k_{21} & ... & k_{n1} \\\\ & 1 & ... & k_{n2} \\\\& & \\ddots & \\vdots \\\\& & & 1 \\end{matrix}\\right) \\quad; k_{ij} = \\frac{<a_i,b_j>}{<b_j,b_j>}  \\\\\n      A &= Q R\n    \\end{align*}\n    $$\n\n- \u521d\u7b49\u65cb\u8f6c\u53d8\u6362\u65b9\u6cd5\n  - \u5bf9\u7b2c1\u5217, \u521d\u7b49\u65cb\u8f6c\u53d8\u6362\u4f7f\u5176\u53d8\u4e3a $T_i a_1 = (b_{11}, 0,...,0)$\n  - $T_i = \\prod_{i=0}^{n-1} T_{i(n-1-j)}$\n  - \u91cd\u590d\u4e0a\u9762\u6b65\u9aa4, \u76f4\u81f3\u5c06 $A_i$ \u5316\u4e3a\u4e0a\u4e09\u89d2\u77e9\u9635\n    $$\n    \\begin{align*}\n      R &= A_{n-1}\n      Q &= \\left(\\prod_{i=0}^{n-1} T_{n-1-i} \\right)^T\n      A &= Q R\n    \\end{align*}\n    $$\n\n- \u521d\u7b49\u53cd\u5c04\u53d8\u6362\u65b9\u6cd5\n  - \u5bf9\u7b2c1\u5217, \u521d\u7b49\u65cb\u8f6c\u53d8\u6362\u4f7f\u5176\u53d8\u4e3a $H_i a_1 = (b_{11}, 0,...,0)$\n    $$\n    \\begin{align*}\n      u_i &= \\frac{b_i - |b_i|}{| b_i - |b_i| |}\n      H_i &= I - 2 u u^T\n      A_{i+1} &= H_i A_i\n    \\end{align*}\n    $$\n\n  - Repeat the above steps, until $A_i$ into upper triangular matrix\n    $$\n    \\begin{align*}\n      R &= A_{n-1}\n      Q &= \\left(\\prod_{i=0}^{n-1} H_{n-1-i} \\right)^T\n      A &= Q R\n    \\end{align*}\n    $$\n\n#### Full Rank decomposition\n\n$$\nA = F G\n$$\n\n##### Proof  \n$$\nA =P^{-1} B = \\left(\\begin{matrix} F & S \\end{matrix}\\right) \\left(\\begin{matrix} G\\\\ 0 \\end{matrix}\\right) = F G\n$$\n\n##### Algorithm  \n$$\nA = F G\n$$\n\u521d\u7b49\u884c\u53d8\u6362, \u53d6A\u5de6\u4fa7rank(A)\u5217\u4f5c\u4e3aF, \u5219\n$$\nA \\to \\left(\\begin{matrix} G \\\\ 0 \\end{matrix}\\right)\n$$\n\n#### Eigenvalue Decomposition\n\nEigenvalue Decomposition, for a square matrix $\\boldsymbol A \\in \\mathbb R^{n \\times n}$, \n\n$$\n\\begin{align*}\n  \\boldsymbol A \n  &= \\boldsymbol Q \\boldsymbol \\Lambda \\boldsymbol Q^{-1}  \\\\\n  &= \\boldsymbol Q \\boldsymbol \\Lambda \\boldsymbol Q^{\\mathrm T}  \\\\\n\\end{align*}\n$$\n\n- $\\boldsymbol Q$ is an orthogonal matrix $\\boldsymbol Q^{\\mathrm T} \\boldsymbol Q = \\boldsymbol I$ composed of eigenvectors $\\boldsymbol v$\n- $\\Lambda$ is composed of eigenvalues $\\lambda$, \n\n$$\n\\begin{align*}\n  \\boldsymbol Q &= (\\boldsymbol v_1, ..., \\boldsymbol v_n)  \\\\\n  \\boldsymbol \\Lambda &= \\left(\\begin{matrix} \\lambda_1 && 0 \\\\ &\\ddots \\\\ 0 && \\lambda_n \\end{matrix}\\right)\n\\end{align*}\n$$\n\n##### Proof\n$$\n\\boldsymbol A \\boldsymbol v_i = \\lambda_i \\boldsymbol v_i\n$$\n\n$$\n\\begin{align*}\n\\Rightarrow \\boldsymbol A (\\boldsymbol v_1, ..., \\boldsymbol v_n) &= (\\boldsymbol v_1, ..., \\boldsymbol v_n) \\left(\\begin{matrix} \\lambda_1 && 0 \\\\ &\\ddots \\\\ 0 && \\lambda_n \\end{matrix}\\right)  \\\\\n\\boldsymbol A &= (\\boldsymbol v_1, ..., \\boldsymbol v_n) \\left(\\begin{matrix} \\lambda_1 && 0 \\\\ &\\ddots \\\\ 0 && \\lambda_n \\end{matrix}\\right) (\\boldsymbol v_1, ..., \\boldsymbol v_n)^{-1}  \\\\\n\\boldsymbol A &= \\boldsymbol Q \\Lambda \\boldsymbol Q^{-1}\n\\end{align*}\n$$\n\n##### Note  \nThe geometric significance of Eigenvalue Decomposition is that a linear transformation $\\boldsymbol A \\boldsymbol x$ is equivalent to (1) $\\boldsymbol Q^{-1} \\boldsymbol x$, convert to a new coordinate system with eigenvectors of $\\boldsymbol A$ as unit bases; (2)$\\boldsymbol \\Lambda (\\boldsymbol Q^{-1} \\boldsymbol x)$, a scale transform; (3)$\\boldsymbol Q (\\boldsymbol \\Lambda \\boldsymbol Q^{-1} \\boldsymbol x)$, convert to original coordinate system.\n\n#### Singular Value Decomposition\n\nfor a matrix $\\boldsymbol A \\in \\mathbb R^{m \\times n}$,  \n$$\n\\boldsymbol A = \\boldsymbol U \\left(\\begin{matrix} \\boldsymbol \\Sigma & \\boldsymbol 0 \\\\ \\boldsymbol 0 & \\boldsymbol 0 \\end{matrix}\\right) \\boldsymbol V^{\\mathrm H}\n$$\n\n- $\\boldsymbol U \\in \\mathbb R^{m \\times m}, \\boldsymbol V \\in \\mathbb R^{n \\times n}$ are unitary matrixs $\\boldsymbol U^{\\mathrm H} \\boldsymbol U = \\boldsymbol I, \\boldsymbol V^{\\mathrm H} \\boldsymbol V = \\boldsymbol I$\n- $\\boldsymbol \\Sigma$ is composed of nonzero singular values.\n\n##### Note\n$$\n\\exists \\text{Unitary Matrix} U, V \\Rightarrow U^H A V = \\left(\\begin{matrix} \u03a3 & 0 \\\\ 0 & 0 \\end{matrix}\\right)\n$$\n\n##### Algorithm  \n$A^{\\mathrm T} A$ \u8ba1\u7b97\u7279\u5f81\u503c $\u03bb$, \u7279\u5f81\u5411\u91cf$v'$, \u5e76\u5f52\u4e00\u5316\u6c42\u5f97 $\\boldsymbol V, \\boldsymbol \u03a3, \\boldsymbol U$,\n\n$$\n(\\boldsymbol A^{\\mathrm T} \\boldsymbol A) \\boldsymbol v'_i = \\lambda_i \\boldsymbol v'_i\n$$\n\n$$\n\\begin{align*}\n  \\boldsymbol V &= \\left(\\frac{\\boldsymbol v'_1}{\\|\\boldsymbol v'_1\\|_2}, ... ,\\frac{\\boldsymbol v'_n}{\\|\\boldsymbol v'_n\\|_2} \\right)  \\\\\n  \\boldsymbol \u03a3 &= \\text{diag}\\left(\\sqrt{\u03bb_1}, ... ,\\sqrt{\u03bb_n}\\right)  \\\\\n  \\boldsymbol U' &= \\boldsymbol A \\boldsymbol V \\boldsymbol \u03a3^{-1}  \\\\\n  \\boldsymbol U &= \\left(\\frac{\\boldsymbol u'_1}{\\|\\boldsymbol u'_1\\|_2}, ... ,\\frac{\\boldsymbol u'_n}{\\|\\boldsymbol u'_n\\|_2} \\right)  \n\\end{align*}\n$$\n\n##### Property\n$$\n\\begin{align*}\n  Range(A) &= Span(u_1, ..., u_r)  \\\\\n  Null (A) &= Span(v_{r+1}, ... , v_n)  \\\\\n  Range(A^{\\mathrm T}) &= Span(v_1, ..., v_r)  \\\\\n  Null (A^{\\mathrm T}) &= Span(u_{r+1}, ... , u_m)  \\\\\n  A &= \\sum_{i=1}^{r} \u03c3_i u_i v_i^H\n\\end{align*}\n$$\n\n##### Proof\n$$\n\\begin{align*}\nA &= \\left(\\begin{matrix} U_{1:r} & U_{r+1:m} \\end{matrix}\\right) \\left(\\begin{matrix} \u03a3 & 0 \\\\ 0 & 0 \\end{matrix}\\right) \\left(\\begin{matrix} V_{1:r}^H \\\\ V_{r+1:n}^H \\end{matrix}\\right)  \\tag{\u5b9a\u4e49\u5f0f\u53d8\u5f62}  \\\\\n&= U_{1:r} \u03a3 V_{1:r}^H\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\nRange(A) &= \\{y\\ |\\ A x = y\\}  \\\\\n&= \\{y\\ |\\ U_{1:r} (\u03a3 V_{1:r}^H x) = y\\}  \\tag{\u4ee3\u5165}  \\\\\n&\\subseteq Range(U_{1:r})  \\\\\nRange(U_{1:r}) &= \\{y\\ |\\ U_{1:r} x = y\\}  \\\\\n&= \\{y\\ |\\ A (V_{1:r} \u03a3^{-1} x) = y\\}  \\tag{$U_{1:r} = A V_{1:r} \u03a3^{-1}$}  \\\\\n&\\subseteq Range(A)\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n\\Rightarrow Range(A) = Range(U_{1:r}) = Span(u_1, ..., u_r)\n\\end{align*}\n$$"
    ]
  },
  "Linear_Transformation": {
    "define": "$$\nT(k \\boldsymbol x + l \\boldsymbol y) = k(T \\boldsymbol x) + l(T \\boldsymbol y)\n$$\nLinear Transformation is a [mapping](./Function.md) $T: V \\to V$ for a [linear space](./Linear_Space.md) $V$, $\\forall \\boldsymbol x \\in V$ there is a unique $\\boldsymbol y \\in V$ corresponding to it, and the linear condition is satisfied. Meanwhile, linear Transformation can represent by matrix $\\boldsymbol A$ and matrix multiply, where the matrix $\\boldsymbol A$ can be obtained by the unit base vectors $(\\boldsymbol e_1, ..., \\boldsymbol e_n)$ after transformation, \n\n$$\nT(\\boldsymbol x) = \\boldsymbol A \\boldsymbol x \\\\\n\\boldsymbol A = (T(\\boldsymbol e_1), ..., T(\\boldsymbol e_n))\n$$\n\n> **Proof**: $T(\\boldsymbol x) = \\boldsymbol A \\boldsymbol x$,   \n> $$\n>\\begin{align*}\n> T(\\boldsymbol x)\n> &= T \\left(\\sum_{i=1}^{\\dim} x_i \\boldsymbol e_i \\right) \\tag{$\\boldsymbol x \n> = \\sum_{i=1}^{\\dim} x_i \\boldsymbol e_i$} \\\\\n>   &= \\sum_{i=1}^{\\dim} x_i T(\\boldsymbol e_i)  \\tag{Linear Transformation}\\\\\n>   &= \\sum_{i=1}^{\\dim} x_i \\boldsymbol a_i  \\tag{$T(\\boldsymbol e_i) = \\boldsymbol a_i$}\\\\\n>   &= \\boldsymbol A \\boldsymbol x\n> \\end{align*}\n> $$\n\n<img src=\"./assets/transformations-1694683776868-3.svg\" alt=\"transformations-1694683776868-3\" style=\"zoom: 13%;\" />",
    "kids": {},
    "name": "Linear_Transformation",
    "parents": {
      "Function": "",
      "Linear_Space": ""
    },
    "properties": [
      "### Range \n$$\nRange(T)=\\{T x | x \\in V\\}\n$$\nIn linear space,\nthe set of results of all vectors after linear transformation; \nthe linear space after linear transformation.\n\n- Rank\n$$\n  rank(A) = \\dim Range(A) = \\dim Range(A^T)\n$$\n  The dimension of space after transformation.\n  The dimension of the range.\n\n### Null Space\n$$\nNull(T) = \\{x | T x = 0\\}\n$$\nIn linear space, the set of all original vectors that are linearly transformed into zero vectors.\n\n- $\\dim V = \\dim Range(A) + \\dim Null(A)$ \n\n\n### Invariant Subspace\n$$\n\\forall x \\in V_1, V_1 \\subseteq V, T x \\in V_1\n$$\n### Eigenvalues & Eigenvectors\n\n$$\n  \\boldsymbol A \\boldsymbol x = \u03bb \\boldsymbol x\n$$\n\n  - $x$: Eigenvectors, a vector whose direction does not change before and after linear transformation;  \n  - $\u03bb$: Eigenvalues, proportion of length change of eigenvector after linear transformation.\n\n- Property\n  * Eigenvalue Decomposition & Singular Value Decomposition\n  \n  - Characteristic polynomial\n$$\n    \\varphi(\u03bb) = |\u03bb I - A| = \u03bb^n + a_1 \u03bb^{n-1} + ... + a_{n-1} \u03bb + a_n\n$$\n\n  - Hamilton-Cayley Theorem\n    $$\n    \\varphi(A) = A^n + a_1 A^{n-1}+ ... +a_{n-1} A + a_n I = 0\n    $$\n    Matrix is the root of its characteristic polynomial.\n\n### Moore-Penrose Inverse\n\nThe solution satisfying the following equation,\n$$\n  \\left\\{\\begin{matrix}\n    A X A = A\\\\\n    X A X = X\\\\\n    (A X)^H = A X\\\\\n    (X A)^H = A X\\\\\n  \\end{matrix}\\right.\n$$\nWhen the rank of cols is full, $A^+ = (A^H A)^{-1} A^H$   \nWhen the rank of rows is full,  $A^+ = A^H (A A^H)^{-1}$\n\n- Property\n  - $rank(A) = rank(A^H A) = rank(A A^H)$\n  - \u6ee1\u79e9\u5206\u89e3\u7b97\u5e7f\u4e49\u9006 $A^+ = G^H (F^H A G^H)^{-1} F^H$\n\n### Similarity\n\n$A$ is similar to $B$, $A ~ B$:\n$$\n\\exists \\text{Nonsingular Matrix}P \\Rightarrow B = P^{-1} A P\n$$\n\n- Property \n  - $A ~ A$ \n  - $A ~ B \\Leftrightarrow B ~ A$ \n  - $A ~ B, B ~ C \\Leftrightarrow A ~ C$\n  - The eigenvalues and eigenvectors of similar matrices are the same.\n  - The trace of similar matrix is the same.\n\n### Transformation of linear transformation matrix under different bases\n\n$$\nA_Y = C^{-1} A_X C \\quad ; Y = C X\n$$\n\n- Proof\n  $$\n  \\begin{align*}\n    T Y &= Y A_Y     \\tag{Define}\\\\ \n    T X C &= X C A_Y   \\tag{$ Y = X C $}\\\\\n    X A_X C &= X C A_Y   \\tag{$ T X = X A_X $}\\\\\n    A_X C &= C A_Y  \\\\\n    A_Y &= C^{-1} A_X C\n  \\end{align*}\n  $$\n\n### Special linear transformation\n\n#### Identity transformation\n\n$$\nT x = x \\quad (\\forall x \\in V) \\\\\n$$\n\n#### Zero transformation\n\n$$\nT x = 0 \\quad (\\forall x \\in V)\n$$\n\n#### Orthogonal Transformation\n\n$$\n\\langle x, x \\rangle = \\langle T x, T x \\rangle\n$$\nOrthogonal Transformation is a linear transformation in the inner product space that keeps the length of any vector unchanged.\nOrthogonal matrix:\n$$\n\\boldsymbol A \\boldsymbol A^T = \\boldsymbol I  \\\\\n\\boldsymbol A \\boldsymbol A^H = \\boldsymbol I\n$$\n\n##### Rotation Transformation\n\nRotation Transformation Matrix:  \n\n$$\n\\boldsymbol A = \\left(\\begin{matrix}\n\\boldsymbol I \\\\ & cos \\theta |_{(i,i)}&  & \\sin \\theta |_{(i,j)} \\\\ & & \\boldsymbol  I \\\\ & -\\sin \\theta |_{(j,i)} & & \\cos \\theta |_{(j,j)} \\\\ & & & & \\boldsymbol  I\n\\end{matrix}\\right)\n$$\n\n- $\\theta$ is the angle of clockwise rotation between dimension $i$ and $j$.\n\n##### Reflection Transformation\n\n$$\ny = H x = (I - 2 e_2 e_2^T) x\n$$\n- Proof  \n$$\n\\begin{align*}\nx - y &= e_2 \u00b7 (e_2^T x)  \\\\\n\\Rightarrow y &= (I-2 e_2 e_2^T) x\n\\end{align*}\n$$\n\n#### Symmetry Transformation\n\n$$\n\\langle T x, y \\rangle = \\langle x, T y \\rangle\n$$\nSymmetry Matrix:\n$$\n\\boldsymbol A^T = \\boldsymbol A  \\\\\n\\boldsymbol A^H = \\boldsymbol A\n$$\n\n#### Projection transformation & Orthogonal Projection transformation\n\nProjection transformation: Suppose the subspace $L$ of the linear space and its complement $M$, the projection transformation is the transformation of the projection of the linear space along $M$ to $L$.\n\nProjection matrix:  \n$$\nP_{L|M} = \\left(\\begin{matrix} X & 0 \\end{matrix}\\right) \\left(\\begin{matrix} X & Y \\end{matrix}\\right)^{-1}\n$$\n\nOrthogonal Projection transformation: Assume the subspace $L$ of the linear space and its orthogonal complement $L_\\bot$. The transformation of the projection of the linear space along $L_\\bot$ to $L$ is called orthogonal projection transformation.\n\nOrthogonal Projection matrix:  \n$$\nP_L = X(X^H X)^{-1}X^H\n$$\n- $X = (x_1, ... , x_r)$: basis of the projected subspace.\n\n- Property  \n  - $P_{L|M}^2 = P_{L|M}$ \n  - $P_L (a \\boldsymbol x + b \\boldsymbol y) = a (P_L \\boldsymbol x) + b (P_L \\boldsymbol y)$\n  - $x \\in L \\Leftrightarrow P_L x = x$\n  - $x \\in L_\\bot \\Leftrightarrow P_L x = 0$\n  - if $H$ is a inner product space, and $L$ is a subspace of $H$ with Orthonormal Basis $\\{u_1, ...u_n\\}$, then the projection of $x \\in H$ is\n    $$\n    \\hat x = \\sum_{i=1}^n \\frac{u_i^T x}{u_i^T u_i} u_i\n    $$\n\n#### Sheer transformation\n\nSheer transformation Matrix:  The $(i,j)-$th element of the identity matrix is changed to the shear ratio $a_{ij}$\n\n##### Scale Transformation\n\nScale Transformation Matrix:\n$$\nT = \\left(\\begin{matrix} \u0394x_1 \\\\ & \u0394x_2 \\\\ & & \\ddots \\\\ & & & \u0394x_n \\end{matrix}\\right)\n$$"
    ]
  },
  "Logic": {
    "define": "### Proposition\n\nA proposition is a declarative sentence that can be judged true or false, but cannot be both true and false.\n\n#### Axioms\n\nAn axiom is a statement that is taken to be true, to serve as a premise or starting point for further reasoning and arguments. \n\n#### Theorems\n\nTheorems are propositions obtained using axioms and inference rules. Once a proposition is proven as a theorem, it can also be used as a basis for further reasoning.\n\n### Logical syntax\n#### Logical connective\n\nLogical connective can be used to connect logical formulas. \n\n- Negation (not) $\\neg$\n- Conjunction (and) $\\wedge$\n- Disjunction (or) $\\vee$\n- Implication (if...then) $\\rightarrow$\n- Equivalence (if and only if, iff) $\\leftrightarrow$\n\n<img src=\"assets/Logical_connectives_Hasse_diagram.svg\" alt=\"Logical_connectives_Hasse_diagram\" style=\"zoom: 33%;\" />\n\n#### Constants\n\n- true $\\top$\n- false $\\bot$\n\n#### Relative words\n\n- equal to $=$\n- belong to $\\in$\n\n#### Predicate\n\nPredicates are symbols or expressions used to describe object attributes or relationships between objects.\n\n- **Predicate** $P (x), Q (x), R (x), \\cdots$: usually representing an object with a certain property, where $x$ is a variable\n\n- **Constants** $a, b, c, \\cdots$: representing specific individuals or objects\n\n- Variable $x, y, z, \\cdots$: used to represent any individual or object\n\n#### Quantifier\n\nQuantifier specify the quantity of specimens in the domain of discourse that satisfy a certain property. \n\n- **Universal quantifier** (for all) $\\forall$\n- **Existential quantifier** (there exists) $\\exists$ \n  - **Uniqueness quantifier** (there is only one) $\\exists_{=1}$\n\n\n### Axiomatic system\n\nAxiom system is composed of a set of axioms (basic, unproven true statements) and a set of inference rules. It provides a framework that enables us to derive new true statements (theorems) from axioms and inference rules.",
    "kids": {},
    "name": "Logic",
    "parents": {
      "root": ""
    },
    "properties": [
      "- Consistency: A system of axioms is consistent, and both if and only if there is no proposition and its negation can be proven from the axioms of that system.\n\n- Completeness: A system of axioms is complete if and only if every true proposition of the system can be proven from its axioms.\n\n\n### G\u00f6del's incompleteness theorems\n\n- First Incompleteness Theorem: Any consistent formal system F within which a certain amount of elementary arithmetic can be carried out is incomplete; i.e., there are statements of the language of F which can neither be proved nor disproved in F.\n- Second Incompleteness Theorem: For any consistent system F within which a certain amount of elementary arithmetic can be carried out, the consistency of F cannot be proved in F itself."
    ]
  },
  "Manifold": {
    "define": "Manifold $M$ is a second countable [Hausdorff space](./Hausdorff_Space.md) that is locally homeomorphic to a [Euclidean space](./Euclidean_Space.md).\n\n- Hausdorff, $\\forall x, y \\in M$, there exists open neighborhoods $U_x, U_y \\subseteq M$ with $x \\in U_x, y \\in U_y$ and $U_x \\cap U_y = \\emptyset$.   \n- Second countable, there exits a countable collection $(U_n)_{n \\in \\mathbb N}$ of open set in $M$ such that for all $V \\subseteq M$ open, and $p \\in V$, there is some $n$ such that $p \\in U_n \\subseteq V$\n- Locally homeomorphic to a Euclidean space, every point has a neighborhood $U$ homeomorphic $\\phi: U \\to V$ to an open subset $V$ of the Euclidean space $\\mathbb R^n$ for some nonnegative integer $n$.",
    "kids": {
      "Differential_Manifold": "",
      "Lie_Group": ""
    },
    "name": "Manifold",
    "parents": {
      "Hausdorff_Space": ""
    },
    "properties": [
      "### Manifold $\\leftrightarrow \\mathbb R^n$ \n\n#### Chart & Atlas\n\n**Chart** $(U, \\phi)$ on a set is a bijection $\\phi: U \\subseteq M \\to \\phi(U) \\subseteq \\mathbb R^n$, where $U, \\phi(U)$ is open. A chart $(U, \\phi)$ is centered at $p$ for $p \\in U$ if $\\phi(p) = 0$.\n\n**Atlas** is a set of charts $\\{(U_i, \\phi_i)\\}$, that collectively cover a manifold $M$.\n$$\n\\{(U_i, \\phi_i)\\}\n$$\n\n### Geodesic\n\nA geodesic is a curve representing in some sense the shortest path between two points in a Riemannian manifold."
    ]
  },
  "Markov_Process": {
    "define": "A [stochastic process](./Stochastic_Process.md) where the future state depends only on the current state and not on any past states.",
    "kids": {},
    "name": "Markov_Process",
    "parents": {
      "Stochastic_Process": ""
    },
    "properties": [
      "### Brownian Process, Wiener Process \n\nThe Wiener process $\\{W(t) \\ |\\ t \\ge 0\\}$ is a stochastic process such that,\n- $W(0) = 0$\n- $W$ has independent increments, $\\forall t > s \\ge 0$, i.e. the future increments $W(t+\\Delta t) - W(t), \\Delta t \\ge 0$ are independent of the past values $W_s$.\n- $W(t) - W(s) \\sim \\mathcal N(0, \\sigma^2(t-s)) \\quad; \\forall t > s \\ge 0, \\sigma > 0$\n- $W$ has continuous paths, $W(t)$ is continuous in $t$ \n\nNote:\nRandom walk is a discrete version of Wiener Process, and Wiener process is a limit of random walk.\n\nProperty:\n$$\n\\mathbb E(W(t)) = 0\n$$\n$$\nVar_{W}(t) = \\sigma^2 t\n$$\n$$\nCorr_{W}(t_1, t_2) = Cov_W(t_1, t_2) = \\sigma^2 \\min \\{t_1, t_2\\} \\quad; t_1, t_2 \\ge 0\n$$\n\n### Poisson Process\n\n$$\nN(t) = \\sum_{n=1}^\\infty u(t - T(n)) \\quad; f_T(t;n) = \\frac{(\u03bb t)^{n-1}}{(n-1)!} \u03bb e^{-\u03bb t} u(t)\n$$\n\n### Markov Chain\n\nMarkov Chain is a discrete-time and discrete-state stochastic process that consists of a sequence of Random Variables $(X_0, X_1, ..., X_n)$, taking values in a discrete state space $\\{1, ..., M\\}$, where the transition of states $X_{n-1} \\to X_{n}$ only depend on the value of the last state $X_{n-1}$.\n\n$$\n\\mathbb P(X_n = x_n \\ |\\ X_{n-1} = x_{n-1}, ..., X_{0} = x_{0}) = \\mathbb P(X_n = x_n \\ |\\ X_{n-1} = x_{n-1})  \\tag{Tansition Probability}\n$$\n\nThe probability of the Tansition from state $X_{n-1} \\to X_{n}$ is called Tansition Probability.\n\n#### Property\n\n##### Transition Matrix\n\n$$\nT_{i,j} = \\mathbb P(X_n = j\\ |\\ X_{n-1} = i)  \\tag{$i \\to j$}\n$$\n$$\n\\begin{align*}\n  \\boldsymbol T_{M \\times M} &= \\left(\\begin{matrix}\n    \\mathbb P(X_n = 1\\ |\\ X_{n-1} = 1) & \\mathbb P(X_n = 2\\ |\\ X_{n-1} = 1) & ... & \\mathbb P(X_n = M\\ |\\ X_{n-1} = 1)  \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    \\mathbb P(X_n = 1\\ |\\ X_{n-1} = M) & \\mathbb P(X_n = 2\\ |\\ X_{n-1} = M) & ... & \\mathbb P(X_n = M\\ |\\ X_{n-1} = M)  \\\\\n  \\end{matrix}\\right) \\tag{Tansition Matrix} \\\\\n  \\boldsymbol p_{n} &= \\boldsymbol T_{M \\times M} \\boldsymbol p_{n-1}  \\\\\n  &= \\left(\\begin{matrix} \\mathbb P(X_n = 1) \\\\ \\mathbb P(X_n = 2) \\\\ \\vdots \\\\ \\mathbb P(X_n = M) \\end{matrix}\\right)  \\\\\n  &= \\left(\\begin{matrix}\n  \\mathbb P(X_n = 1\\ |\\ X_{n-1} = 1) & ... & \\mathbb P(X_n = M\\ |\\ X_{n-1} = 1)  \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  \\mathbb P(X_n = 1\\ |\\ X_{n-1} = M) & ... & \\mathbb P(X_n = M\\ |\\ X_{n-1} = M)  \\\\\n  \\end{matrix}\\right)\n  \\left(\\begin{matrix} \\mathbb P(X_{n-1} = 1) \\\\ \\mathbb P(X_{n-1} = 2) \\\\ \\vdots \\\\ \\mathbb P(X_{n-1} = M) \\end{matrix}\\right)  \\tag{Tansition of Probability Distribution}\n\\end{align*}\n$$\n\n$k$-step Tansition Matrix\n$$\n\\begin{align*}\nT^{(k)}_{ij} &= \\mathbb P(X_n = j\\ |\\ X_{n-k} = i)  \\tag{element of $k$-step Tansition Matrix}\\\\\n  \\boldsymbol p_{n} &= \\boldsymbol T^{(k)} \\boldsymbol p_{n-k}  \\\\\n\\end{align*}\n$$\n$$\nT^{(k)} = T^k\n$$\n\n- Property\n  - simple\n    $$\n    \\begin{align*}\n      T_{i,j} &\\ge 0\\\\\n      \\sum_{j=1}^M T_{i,j} &= 1  \\\\\n    \\end{align*}\n    $$\n\n  * Stationary Distribution\n    $$\n    \\boldsymbol p_{\\pi} = \\boldsymbol T \\boldsymbol p_{\\pi}  \\tag{$p_{\\pi}$: Stationary Distribution}\n    $$\n\n#### Example\n\n##### Random Walk\nFor a squence $\\{Y_i\\}$ of iid. random variable with value $\\{-1, +1\\}$ and probability $\\{1-p, p\\}$, then the 1-dimensional random walk is the squence $\\{X_0, X_1, ...\\}, X_0 = 0$ of random variable such that\n$$\nX_t = \\sum_{i=1}^t Y_i\n$$\n##### Branching Process \nBranching Process are used to medel population growth by reproduction. At the beginning, there is only one individual $Z_0 = 1$. In the next generation $n+1$, each offspring will reproduce randomly according to iid. random variable $X_{n,i}$. In branching process, the expected number of individuals in a particular $\\mathbb E(Z_n)$ and the probability of ultimate extinction $\\mathbb P(Z_n = 0)$ are central questions. The recurrence equation of branching process is \n$$\nZ_{n+1} = \\sum_{i=1}^{Z_n} X_{n, i}\n$$\n$Z_{n+1}$: the size of generation $n$ with $Z_0 = 1$.  \n$X_{n, i}$: a random variable denoting the number of direct successors of member $i$ in generation $n$. And $X_{n,i}$ are iid. over all $n$ and $i$."
    ]
  },
  "Martingale": {
    "define": "Martingale is a discrete-time [stochastic process](./Stochastic_Process.md) that satisfies for any time $n$,\n$$\n\\mathbb E(|X_n|) < \\infty\n$$\n$$\n\\mathbb E(X_{n+1} \\ |\\ X_1, ..., X_n) = X_n\n$$\n\nThe second condition means that the conditional expected value of the next observation, given all the past observations, is equal to the most recent observation.",
    "kids": {},
    "name": "Martingale",
    "parents": {
      "Stochastic_Process": ""
    },
    "properties": [
      "- Doob-Meyer decomposition\n\n\n### Stopping Time\n\n- Define\n  Stopping Time $\\tau: \\Sigma \\to \\bar T, \\bar T = T \\cup \\{\\infty\\}$ is a random variable defined on the filtered probability space $(\\Omega, \\mathcal F, (\\mathcal F_n)_{n \\in \\mathbb N}, P)$ with value in $T = [0, +\\infty)$, such that \n  $$\n  \\{\\tau \\le t\\} \\in \\mathcal F_t \\quad, \\forall t \\in T\n  $$\n\n- Property\n\n  - Optional stopping theorem\n\n    Consider a stochastic process $\\{X_t\\}$ and a stopping time $\\tau$ (a random variable that represents the time at which some event of interest occurs). The optional stopping theorem provides conditions under which\n    $$\n    \\mathbb E(X_\\tau) = \\mathbb E(X_0)\n    $$"
    ]
  },
  "Measurable_Space": {
    "define": "A Measurable Space is a pair $(E, \\mathcal E)$, where $E$ is a set and $\\mathcal E$ is its [$\\sigma$-algebra](./Power_Set.md).\n\nA Measure Space is a pair $(E, \\mathcal E, \\mu)$, where $E$ is a set and $\\mathcal E$ is its $\\sigma$-algebra, $\\mu$ is a Measure on $(E, \\mathcal E)$\n\n### Measurex\n\nA Measure on a measurable space $(E, \\mathcal E)$ is a function $\\mu: \\mathcal E \\to [0, \\infty)$ such that \n\n- $\\mu (\\emptyset) = 0$\n- Countable additivity: For any disjoint sequence $(A_1, ..., A_n), A_i \\in \\mathcal E$, then\n$$\n\\mu \\left(\\bigcup_i A_i\\right) = \\sum_i \\mu(A_i)\n$$",
    "kids": {
      "Probability_Space": ""
    },
    "name": "Measurable_Space",
    "parents": {
      "Power_Set": ""
    },
    "properties": [
      "- Lebesgue Measure \n  For a measurable subset $E \\subseteq \\mathbb{R}^n$, $E$ is Lebesgue measurable, if for any $\\epsilon > 0$, there exist a finite number of open boxes $Q_1, Q_2, \\ldots, Q_m$ and their volumes $\\text{vol}(Q_i)$, such that\n  $$\n  E \\subset \\bigcup_{i=1}^m Q_i\n  $$\n  $$\n  \\sum_{i=1}^m \\text{vol}(Q_i) < \\text{vol}(E) + \\epsilon  \\tag{Lebesgue measurable}\n  $$\n\n  And Lebesgue measure $\\text{m}(E)$ of a measurable subset $E$ is defined as,\n  $$\n  \\text{m}(E) = \\inf\\left\\{\\sum_{i=1}^\\infty \\text{vol}(Q_i) \\ \\middle|\\ E \\subset \\bigcup_{i=1}^\\infty Q_i \\right\\}  \\tag{Lebesgue Measure}\n  $$\n\n- Probability"
    ]
  },
  "Metric_Space": {
    "define": "A metric space is a pair $(X, d)$ where $X$ is a set and $d: X \\times X \\to \\mathbb R$  is a metric on $X$ satisfying the following axioms $\\forall x, y, z \\in X$:\n\n- Non-negativity, with equality if and only if $x = y$\n  $$\n  d(x, y) \\ge 0\n  $$\n- Symmetry\n  $$\n  d(x, y) = d(y, x)\n  $$\n- Triangle Inequality\n  $$\n  d(x, y) \\le d(x, z) + d(z, y)\n  $$\n\nMetric Space is a type of [Topological Space](./Topological_Space.md).",
    "kids": {
      "Hilbert_Space": ""
    },
    "name": "Metric_Space",
    "parents": {
      "Topological_Space": ""
    },
    "properties": [
      "- Lipschitz Equivalent  \n  Metrics $d, d'$ on $X$ are said to be Lipschitz Equivalent if there are positive constants $A, B$ and $\\forall x, y \\in X$ such that\n  $$\n  A d(x, y) \\le d'(x, y) \\le B d(x, y)\n  $$\n\n- Convergence of Sequence  \n  A sequence $x_n \\in X$ is said to be converge to $x$ if\n  $$\n  (\\forall \\epsilon > 0)(\\exists K)(\\forall k > K) d(x_k, x) < \\epsilon\n  $$\n\n- Complete Metric Space  \n  A metric space $(X, d)$ is complete if all Cauchy sequences converge to a point in $X$. Cauchy sequence is a sequence satisfying \n  $$\n  (\\forall \\epsilon > 0)(\\exists N)(\\forall n, m \\ge N) d(x_n, x_m) < \\epsilon\n  $$\n\n- Continuity  \n  For metric spaces $(X, d), (X', d')$, a function $f: X \\to X'$ is continuous at $y \\in X$ if\n  $$\n  (\\forall \\epsilon > 0)(\\exists \\delta > 0)(\\forall x) d(X, Y) < \\delta \\Rightarrow d'(f(x),f(y)) < \\epsilon\n  $$\n\n- Uniform Continuity\n  $$\n  (\\forall \\epsilon > 0)(\\exists \\delta > 0)(\\forall x) d(X, Y) < \\delta \\Rightarrow d(f(x),f(y)) < \\epsilon\n  $$\n\n- Lipschitz Continuity  \n  $$\n  d'(f(x), f(y)) \\le K d(x, y)\n  $$\n\n- Lipschitz Continuity $\\Rightarrow$ Uniform Continuity $\\Rightarrow$ Continuity\n\n- Contraction Mapping  \n  A mapping $f: X \\to X$ is contraction if there exists $\\lambda \\in [0, 1)$ such that\n  $$\n  d(f(x), f(y)) \\le \\lambda d(x, y)\n  $$\n\n- Contraction Mapping Theorem , Banach Fixed-point Theorem  \n  For a complete matric space, if $f: X \\to X$ is a contraction, then $f$ has a unique fixed point $x^* \\in X$,\n  $$\n  f(x^*) = x^*,\\quad \\lim\\limits_{n \\to \\infty} f^n(x_0) = x^* ,\\forall x_0 \\in X\n  $$"
    ]
  },
  "Mobius_Function": {
    "define": "$$\n\\mu(n) = \\left\\{\\begin{matrix}\n  1 & n = 1\\\\\n  (-1)^k & n = \\prod\\limits_{i=1}^k p_i\\ (p_i \\text{ is prime})\\\\\n  0 & other.\n\\end{matrix}\\right.  \\tag{M\u00f6bius Function}\n$$\n\nM\u00f6bius Function $f: \\mathbb Z^+ \\to \\{-1, 0, 1\\}$ is defined above. For positive integers without square factors, if $n$ has an odd number of different prime factors, then $\\mu(n) = -1$; if there are even numbers of of different prime factors, then $\\mu(n)=1$.",
    "kids": {},
    "name": "Mobius_Function",
    "parents": {
      "Integer_Ring": ""
    },
    "properties": [
      "- M\u00f6bius Function is a multiplicative function.\n\n\n\n$$\n\\sum\\limits_{d|n} \\mu(d) = \\epsilon(n) = \\left\\{\\begin{matrix}\n1 & n=1 \\\\\n0 & n \\neq 1\\\\\n\\end{matrix}\\right.\n$$\n\n### M\u00f6bius Inversion \n\n$$\ng(n) = \\sum_{d|n} f(d) \\quad\\Leftrightarrow\\quad f(n) = \\sum_{d|n} \\mu(d) g\\left(\\frac{n}{d}\\right)  \\tag{M\u00f6bius Inversion}\n$$\n$$\nf * \\boldsymbol 1 = g  \\quad\\Leftrightarrow\\quad f = g * \\mu\n$$\n\nWhere, $*$ is dirichlet convolution."
    ]
  },
  "Module": {
    "define": "$$\n(R, M, +, \\cdot)\n$$\n\nSuppose that $R$ is a [ring](./Ring.md), and $1$ is its multiplicative identity. A left $R$-module $M$ consists of an abelian group $(M, +)$ and an operation $\\cdot$: $R \u00d7 M \\to M$ such that $\\forall r, s \\in R$ and $x, y \\in M$, we have\n1. $\\forall r, s \\in R$ \u548c $x, y \\in M$ \u6709 $(r + s) \\cdot x = r \\cdot x + s \\cdot x$\n2. $\\forall r \\in R$ \u548c $x, y \\in M$ \u6709 $r \\cdot (x + y) = r \\cdot x + r \\cdot y$\n3. $\\forall r, s \\in R$ \u548c $x \\in M$ \u6709 $(rs) \\cdot x = r \\cdot (s \\cdot x)$\n4. If ring $R$ \u6709\u4e00\u4e2a\u5355\u4f4d\u5143 $1_R$\uff0c\u90a3\u4e48\u5bf9\u6240\u6709 $x \\in M$ \u6709 $1_R \\cdot x = x$",
    "kids": {
      "Linear_Space": ""
    },
    "name": "Module",
    "parents": {
      "Ring": ""
    },
    "properties": [
      ""
    ]
  },
  "Moment": {
    "define": "K-order Moment & K-order Central Moment:\n$$\n\\begin{align*}\n  \\mathbb E(X^k) &= \\sum_i x_i^k \\mathbb P_X(x_i)  \\tag{Moment (Discrete)}  \\\\\n    &= \\int_{-\\infty}^\\infty x^k f_X(x) \\mathrm d x  \\tag{Moment (Continuous)}  \\\\\n  \\mathbb E((X-\\mu_x)^k) &= \\sum_i (x_i-\\mu_x)^k \\mathbb P_X(x_i)  \\tag{Central Moment (Discrete)}  \\\\\n    &= \\int_{-\\infty}^\\infty (x-\\mu_x)^k f_X(x) \\mathrm d x  \\tag{Central Moment (Continuous)}\n\\end{align*}\n$$\n\nSymbol: $\\mu_x = \\mathbb E(X)$",
    "kids": {},
    "name": "Moment",
    "parents": {
      "Random_Variable": ""
    },
    "properties": [
      "### Expectation\n\n$$\n\\begin{align*}\n  \\mathbb E(X) = \\mu_x &= \\sum x_i \\mathbb P_X(x_i)  \\tag{Discrete}  \\\\\n    &= \\int_{-\\infty}^\\infty x f_X(x) \\mathrm d x  \\tag{Continuous}  \\\\\n  \\mathbb E(\\boldsymbol X) &= \\left(\\begin{matrix} \\bar X_i \\\\ \\vdots \\end{matrix}\\right) \n\\end{align*}\n$$\n\n- Property\n  $$\n  \\begin{align*}\n    \\mathbb E(Y) &= \\int_{-\\infty}^\\infty g(x) f_X(x) \\mathrm d x  \\\\\n    Y &= g(X)  \\tag{$g$ is a measurable function}\n  \\end{align*}\n  $$\n\n### Variance & Standard Deviation\n\n$$\n\\begin{align*}\n  Var(X) = \\sigma_x^2 &= \\mathbb E((X - \\mu_x)^2)  \\tag{Variance}\\\\\n  \\sigma_x &= \\sqrt{\\mathbb E((X - \\mu_x)^2)}  \\tag{Standard Deviation}\n\\end{align*}\n$$\n\n- Property\n  - $Var(X) = \\mathbb E((X - \\mu_x)^2) = \\mathbb E(X^2) - \\mathbb E(X)^2$\n\n### Skewness  \n\n$$\n\\mathbb E\\left(\\frac{(X - \\mu_x)^3}{\\sigma_x^3}\\right)  \\tag{3-order Central Moment}\n$$\n\n### Kurtosis  \n\n$$\n\\mathbb E\\left(\\frac{(X - \\mu_x)^4}{\\sigma_x^4}\\right)  \\tag{4-order Central Moment}\n$$\n\n### Mixed Moment  \n\n$$\n\\begin{align*}\n  &\\mathbb E(X^i Y^j) \\tag{$ij$-order Joint Moment}  \\\\\n  &\\mathbb E((X-\\bar X)^i (Y-\\bar Y)^j) \\tag{$ij$-order Joint Central Moment}\n\\end{align*}\n$$\n\n#### Include\n\n* Correlation & Covariance  \n  $$\n  \\begin{align*}\n    Corr(X,Y) &= \\mathbb E(X Y)  &\\tag{Correlation}  \\\\\n  \n    Cov(X,Y) \n    &= \\mathbb E((X-\\bar X) (Y-\\bar Y))   \\tag{Covariance}  \\\\\n    &= \\mathbb E(X Y) - \\mathbb E(X) \\mathbb E(Y)  \\\\\n    &= Corr(X,Y) - \\mathbb E(X) \\mathbb E(Y)  \\\\\n  \n    R_{\\boldsymbol X\\boldsymbol X} &= \\mathbb E(\\boldsymbol X \\boldsymbol X^T)  \\\\\n    &= \\left(\\begin{matrix} E(X_i X_j) & ... \\\\ \\vdots & \\ddots \\end{matrix}\\right)  \\tag{AutoCorrelation matrix}  \\\\\n    \\boldsymbol \\Sigma_{\\boldsymbol X\\boldsymbol X} &= \\mathbb E((\\boldsymbol X - \\bar{\\boldsymbol X}) (X - \\bar{\\boldsymbol X})^T)  \\tag{AutoCovariance matrix}\\\\\n    &= \\left(\\begin{matrix} E((X_i - \\bar X_i) (X_j - \\bar X_j)) & ... \\\\ \\vdots & \\ddots \\end{matrix}\\right)  \n  \\end{align*}\n  $$\n  \n  - Include\n    * Correlation Coefficient\n      $$\n      \\begin{align*}\n        \\rho \n        &= \\frac{Cov(X,Y)}{Cov(X,X) Cov(Y,Y)}  \\\\\n        &= \\frac{\\mathbb E(XY) - \\mathbb E(X) \\mathbb E(Y)}{\\sqrt{\\mathbb E(X^2) - \\mathbb E(X)^2} \\sqrt{\\mathbb E(Y^2) - \\mathbb E(Y)^2}}\n      \\end{align*}\n      $$\n      \n      - Property\n        - $\\rho_{XY} \\in [-1, 1]$, Correlations equal to $+1$ or $-1$ correspond to data points lying exactly on a line.\n        - $\\rho_{XY} = \\rho_{YX}$\n        - $\\rho_{XY} = \\rho_{(a + b X)\\ (c + d Y)} \\quad; b, d > 0$  \n          it is invariant under separate changes in location and scale in the two variables.\n  \n  - Property\n    - $Cov(X,Y) = Cov(Y,X)$\n    - $Cov(X,X) = Var(X,X)$\n    - relation between AutoCorrelation & AutoCovariance matrix\n      $$\n      \\boldsymbol \\Sigma_{\\boldsymbol X\\boldsymbol X} = \\boldsymbol R_{\\boldsymbol X\\boldsymbol X} - \\bar{\\boldsymbol X} \\bar{\\boldsymbol X}^T\n      $$\n    - Autocovariance matrix $\\Sigma_{\\boldsymbol X\\boldsymbol X}$ is a positive semi-definite matrix.\n    - $\\boldsymbol Y = \\boldsymbol A \\boldsymbol X \\Rightarrow \\boldsymbol \\Sigma_{\\boldsymbol Y\\boldsymbol Y} = \\boldsymbol A \\boldsymbol \\Sigma_{\\boldsymbol X\\boldsymbol X} \\boldsymbol A^T$\n\n### Moment Generating Function\n\nLet $X$ be a random variable with CDF $F_X$, the moment generating function $M_X(t)$ of $X$ (or $F_X$) is \n$$\nM_X(t) = \\mathbb E(e^{tX})\n$$\n\n#### Property\n\n- $M_X(t)$ always exists and is equal to 1.\n\n- The moment-generating function is so named because it can be used to find the moments of the distribution. By using the moment generating function, we can calculate the various moments of the random variable $X$. Specifically, the $n$-th moment of $X$ can be obtained by the nth derivative of the moment generating function at $t=0$.\n  $$\n  E(X^n) = M_X^{(n)}(0)\n  $$\n\n- Differentiating $M_X(i)$ $i$ times with respect to $t$ and setting $t=0$, we obtain the i-th moment.\n  $$\n  \\begin{align*}\n  M_X(t) &= \\mathbb E(e^{tX}) \\\\\n   &= 1 + t E(X) + \\frac{t^2 E(X^2)}{2!} + \\cdots + \\frac{t^n E(X^n)}{n!} + \\cdots  \\\\\n   &= 1 + t m_1 + \\frac{t^2 m_2}{2!} + \\cdots + \\frac{t^n m_n}{n!} + \\cdots  \\\\\n  \\end{align*}\n  $$\n\n- If $X$ is a continuous random variable, the following relation between its moment-generating function $M_X(t)$ and the two-sided Laplace transform of its probability density function $f_X(x)$ holds:\n  $$\n  M_X(t) = \\mathcal L\\{f_X\\}(-t)\n  $$\n  since the PDF's two-sided Laplace transform is given as\n  $$\n  \\mathcal L\\{f_X\\}(s) = \\int_{-\\infty}^{+\\infty} e^{-sx} f_X(x) dx\n  $$\n  and the moment-generating function's definition expands (by the law of the unconscious statistician) to\n  $$\n  M_X(t) =  \\mathbb E(e^{tX}) = \\int_{-\\infty}^{+\\infty} e^{-tx} f_X(x) dx\n  $$"
    ]
  },
  "Natural_Number": {
    "define": "$$\n\\mathbb N\n$$\n\nNatural numbers are formally defined by the Peano axioms, which are a set of axioms that describe the properties of natural numbers. ([Set](./Set.md))\n\n- $0$ is a natural number.\n- Every natural number has a successor in the natural numbers.\n- $0$ is not the successor of any natural number.\n- If the successor of two natural numbers is the same, then the two original numbers are the same.\n- If a set contains $0$ and the successor of every number is in the set, then the set contains the natural numbers. (Mathematical Induction)",
    "kids": {
      "Integer_Ring": ""
    },
    "name": "Natural_Number",
    "parents": {
      "Set": ""
    },
    "properties": [
      ""
    ]
  },
  "Normed_Linear_Space": {
    "define": "$$\n(X, ||\u00b7||)\n$$\nThe [Linear Space](./Linear_Space.md) of Norm is defined.\n\nSymbol:\n- $X$: linear space\n- $||\u00b7||$:  Norm",
    "kids": {
      "Inner_Product_Space": ""
    },
    "name": "Normed_Linear_Space",
    "parents": {
      "Linear_Space": ""
    },
    "properties": [
      "### Norm\n\n#### Include\n\n##### Vector Norm \n\n- Define   \n  A class of functions$f: X \\to \\mathbb R$ that satisfy:\n  \n  - Nonnegativity, $||A|| \u2265 0 ; ||A|| = 0 <=> A = 0$\n  - Homogeneity, $||k A|| = |k| ||A||$\n  - Trigonometric Inequality, $||A + B|| \u2264 ||A|| + ||B||$\n  \n- Example \n  - $p$-Norm\n    $$\n    \\begin{align*}\n      ||x||_{p} &= \\left(\\sum_{i=1}^n |x_i|^p \\right)^{1 / p}  \\tag{p-Norm}\\\\\n      ||x||_0 &= number(x_i \u2260 0 |_{i=1:n})  \\tag{0-Norm}\\\\\n      ||x||_1 &= \\sum_{i=1}^n |x_i|  \\tag{1-Norm}\\\\\n      ||x||_2 &= \\sqrt{\\sum_{i=1}^n x_i^2}  \\tag{2-Norm}\\\\\n      ||x||_\u221e &= \\max |x_i|  \\tag{$\u221e$-Norm}\\\\\n    \\end{align*}\n    $$\n\n  - Ellipse Norm \n    $$||x||_A = (x^T A x)^{1/2}$$\n\n##### Matrix Norm \n\n- Define   \n  A class of functions that satisfy:\n  - Nonnegativity, $||A|| \u2265 0$, if and only if $A = 0, ||A|| = 0$\n  - Homogeneity, $||k A|| = |k| ||A||$\n  - Trigonometric Inequality, $||A + B|| \u2264 ||A|| + ||B||$\n  - Consistency, $||A B|| \u2264 ||A||\\ ||B||$\n\n- Example \n  - simple\n    $$\n    \\begin{align*}\n      ||A||_{m_1} &= \\sum_{i,j} |a_{ij}|  \\\\\n      ||A||_{m_2} &= \\left(\\sum_{i,j} a_{ij}^2 \\right)^{1/2}  \\\\\n      ||A||_{m_\u221e} &= n\u00b7\\max_{i,j}|a_{ij}|  \\\\\n      ||A||_1    &= \\max_j \\sum_i |a_{ij}|  \\tag{\u5217\u548c Norm}\\\\\n      ||A||_\u221e &= \\max_i \\sum_j |a_{ij}|  \\tag{\u884c\u548c Norm}\\\\\n    \\end{align*}\n    $$\n  - Spectral Norm   \n    $$\n    ||A||_2 = \\sqrt{\\max\\ \u03bb_i}\n    $$\n    $(\u03bb_i)$ is eigenvalue of $A^H A$ .\n\n  - Frobenius Norm \n    $$\n    ||\\.A||_F = \\sqrt{\\sum_i \\sum_j |a_{ij}|^2}\n    $$\n\n#### Property\n\n- Matrix & Vector Norm Consistency\n  $$\n  ||A x||_V \u2264 ||A||_M ||x||_V\n  $$"
    ]
  },
  "Ordered_Set": {
    "define": "An ordered set, or more formally, a partially ordered set (poset), is a pair $(S, \\le)$ consisting of a set $S$ and  a binary relation $\\le$ that satisfies the following properties for all $a, b, c \\in S$:\n\n1. Reflexivity: $a \\le a$.\n2. Antisymmetry: If $a \\le b$ and $b \\le a$, then $a = b$.\n3. Transitivity: If $a \\le b$ and $b \\le c$, then $a \\le c$.\n\n\n### Partial Order\n\nPartial Order is a homogeneous relation $\\le$ on a set $S$ that is reflexive, antisymmetric, transitive.\n\n- Reflexivity. Every element is related to itself.\n  $$\n  \\forall x \\in S, x \\le x\n  $$\n- Antisymmetry. \n  $$\n  \\forall x, y \\in S, x \\le y, y \\le x \\quad\\Rightarrow\\quad x = y\n  $$\n- Transitivity. \n  $$\n  \\forall x, y, z \\in S, x \\le y, y \\le z \\quad\\Rightarrow\\quad x \\le z\n  $$\n\nStrict Partial Order is a homogeneous relation $<$ on a set $S$ that is irreflexivity, antisymmetric, transitive. Where the irreflexivity is not $a < a$ (no element is related to itself).",
    "kids": {},
    "name": "Ordered_Set",
    "parents": {
      "Set": ""
    },
    "properties": [
      "* Least Element & Greatest Element\n    $$\n    m \\le a \\quad, m \\in S, \\forall a \\in S  \\tag{Least element}\n    $$\n    $$\n    a \\le g \\quad, g \\in S, \\forall a \\in S  \\tag{Greatest element}\n    $$\n    \n  * Minimal Element & Maximal Element  \n    $$\n    \\nexists a \\in S, \\text{ let } a < m \\quad, m \\in S \\tag{Minimal element}\n    $$\n    $$\n    \\nexists a \\in S, \\text{ let } g < a \\quad, g \\in S \\tag{Maximal element}\n    $$\n    \n  * Infimum & Supremum\n    Infimum (greatest lower bound) of a subset $S$ of a partially ordered set $(P, \\le)$ is an element $a^*\\in P$ such that,\n    $$\n    a \\le x \\quad, \\forall x \\in S  \\tag{lower bounds}\n    $$\n    $$\n    a \\le a^*, \\forall a \\tag{Infimum}\n    $$\n    \n    Supremum (least upper bound) of a subset $S$ of a partially ordered set $(P, \\le)$ is an element $b^* \\in P$ such that,\n    $$\n    x \\le b \\quad, \\forall x \\in S  \\tag{upper bounds}\n    $$\n    $$\n    b^* \\le b, \\forall b \\tag{Supremum}\n    $$\n\nInclude\n* Total Order \n  Total Order is a partial order in which any two elements are comparable, such that, \n  - strongly connected, formerly called total: $a \\le b$ or $b \\le a$.\n\n\n### Permutation\n\n- Define  \n  Permutation, is the arrangement of $k$ elements from a set of $n$ elements in a particular order. \n\n  The number of Conbination and Permutation Subsets\n  $$A(n, k) = \\frac{n!}{(n - k)!}  \\tag{Permutation}$$\n\n- Property\n  * Full Permutation\n    - Define  \n      Full Permutation refers to all possible permutations of all elements in a sequence.  \n\n    - Problem: Generate Full Permutation\n      $$\\begin{align*}\n        f(\\{a_i | i\\in 1:n\\}) \n        &= \\{(a_1, a_2, ..., a_n), (a_2, a_1, ..., a_n), (a_n, a_{n-1}, ..., a_1)\\}  \\\\\n        &= \\cup_{i=1}^n (\\{(a_i)\\} \u00d7 f(\\{a_j\\ |\\ j \u2260 i, j\\in 1:n\\}))  \\tag{$\u00d7$: \u5e8f\u5217\u5408\u5e76}  \\\\\n        f(\\{a_1\\}) &= \\{(a_1)\\}  \\tag{initial}  \\\\\n      \\end{align*}$$\n      \n    - Property\n      * Cantor Expansion  \n        - Define  \n          Cantor expansion is a bijection from a permutation sequence $a$ to a natural number $y$ that refer to the index of sequence in full permutation ordered by dictionary order. Where $f(a_i)$ is the number of elements smaller than $a_i$ and not appearing in $a_n:a_i$.\n          $$y = \\sum\\limits_{i=1}^n f(a_i) (i-1)!$$"
    ]
  },
  "Polyhedron": {
    "define": "$$\n\\{\\boldsymbol x \\ |\\ \\boldsymbol a_j^T \\boldsymbol x \u2264 b_j, j = 1,...,m,\\ \\boldsymbol c_j^T \\boldsymbol x = d_j, j = 1,...,p\\}\n$$\n\nPolyhedron is the intersection of a finite hyperplane and a half space.",
    "kids": {
      "Simplex": ""
    },
    "name": "Polyhedron",
    "parents": {
      "Affine_Space": ""
    },
    "properties": [
      "- Polyhedron is a convex set."
    ]
  },
  "Polynomial_Function": {
    "define": "$$\\begin{align*}\n  f(x) &= \\sum_{i=0}^{n} a_i x^i  \\tag{one variable}  \\\\\n  f(\\boldsymbol x) &= \\sum_{\\boldsymbol i=(0,...,0)_n, i_j \\le i_k, \\forall j \\le k}^{(\\dim,...,\\dim)_n} \\left(a_{\\boldsymbol i} \u00b7 \\prod_{i_j \\in \\boldsymbol i, x_0 = 1}x_{i_j} \\right)  \\tag{multi-variate}  \n\\end{align*}$$\n\nPolynomial function is a kind of [function](./Function.md).",
    "kids": {
      "Cubic_Function": "",
      "Forth-Order_Function": "",
      "Linear_Function": "",
      "Quadratic_Function": ""
    },
    "name": "Polynomial_Function",
    "parents": {
      "Function": ""
    },
    "properties": [
      "- For a univariate $N$-th degree equation, there is no root-finding formula composed of finite addition, subtraction, multiplication, division, and square root operations $(+, -, \\times, /, \\sqrt{\\ })$ from the fifth degree onwards.\n\n* Fundamental Theorem of Algebra\n  Every non-constant single-variable polynomial with complex coefficients has at least one complex root. \n  \n  Theorem states the field of complex numbers is algebraically closed."
    ]
  },
  "Power_Set": {
    "define": "$$\nP(S) = \\{X \\ |\\ X \\subseteq S\\}  \\tag{Power Set}\n$$\nThe Power Set of a set $S$ is the set of all subset of $S$, including $\\emptyset$ and $S$ itself.\n\n<img src=\"./assets/Hasse_diagram_of_powerset_of_3.svg\" alt=\"Hasse_diagram_of_powerset_of_3\" style=\"zoom: 40%;\" />",
    "kids": {
      "Measurable_Space": "",
      "Sigma_Algebra": "",
      "Topological_Space": ""
    },
    "name": "Power_Set",
    "parents": {
      "Set": ""
    },
    "properties": [
      "- The number of elements in the power set of a set $S$ is $2^n$, where $n$ is the number of elements in the set $S$.\n  $$\n  |P(S)| = 2^{|S|}\n  $$\n\n\n### Combination\n\n- Define\n  $$\n  f_\\text{Conbination}(S, k) = \\{ X \\ |\\ X \\subseteq S , |X| = k\\}  \\tag{Conbination}\n  $$\n  Combination, is the selection of $k$ elements from a set of $n$ elements without any regard to the order in which they are chosen.\n\n  The number of Combination $C(n, r)$,\n  $$\n  C(n, r) = |f_\\text{Conbination}(S, k)| = \\frac{n!}{(n - m)! m!}  \\tag{number of Conbination}\n  $$\n\n- Property    \n  - $C(n,r) = C(n-1,r-1) + C(n-1,r)$\n  - $C(n,r) = C(n,n-r)$\n  - The union of all Combination of a set $S$ is the power set $P(S)$ of the set $S$.\n    $$\n    \\bigcup_{k=0}^n f_\\text{Conbination}(S, k) = P(S)\n    $$\n    $$\n    \\begin{align*}\n      \\sum_{i=0}^n C(n,i) &= 2^n  \\\\\n      \\sum_{i=0}^n C(n,i)^2 &= C(2n, n)  \\\\\n      \\sum_{i=0}^n C(k+i,k)^2 &= C(n+k+1, k+1) \n    \\end{align*}\n    $$"
    ]
  },
  "Prime": {
    "define": "$$\n\\nexists a \\in (\\mathbb N - \\{1, p\\}), \\text{ let } a | p  \\tag{Prime}\n$$\nPrime is a number $p$ that can only be divided by $1$ and itself.",
    "kids": {},
    "name": "Prime",
    "parents": {
      "Division_with_Remainder": ""
    },
    "properties": [
      "### Fundamental Theorem of Arithmetic\nAny integer $n$ greater than $1$ can be uniquely expressed in the form of prime $p_i$ product.   \n$$\nn = \\prod_i p_i^{\\alpha_i} \\quad n \\in \\mathbb Z, n > 1\n$$\n\n### Fermat's Little Theorem\n\n$$\na^{p-1} \\equiv 1 \\mod p\n$$\nWhere $p$ is a prime and $a$ is an any integer that is not a multiple of $p$.\n\n- Property\n  $$\n  \\frac{a}{b} \\mod p \\equiv a \\times b^{p-2} \\mod p\n  $$\n\n  - Proof\n\n      $$\n      \\frac{a}{b} \\mod p = a \\times b^{-1} \\mod p  \\\\\n      b^{p-1} \\equiv 1 \\mod p \\\\\n      b \\times b^{p-1} \\equiv 1 \\mod p  \\\\\n      \\Rightarrow \\quad b^{-1} \\equiv b^{p-2}  \\mod p \\\\\n      \\Rightarrow \\quad \\frac{a}{b} \\mod p \\equiv a \\times b^{p-2} \\mod p\n      $$\n\n  ### Goldbach's Conjecture\n  \n  every even natural number greater than 2 is the sum of two prime numbers.\n  $$\n  \\forall n \\in \\mathbb{Z}^+ \\, (\\, n > 2 \\, \\land \\, \\text{even}(n) \\, ) \\, \\exists \\, p, q \\in \\text{Primes} \\, (\\, n = p + q \\, )\n  $$\n\n### Mersenne Prime\n\n$$\nM_n = 2^n - 1  \\tag{Mersenne number}\n$$\nMersenne Prime is a prime number that is one less than a power of two.\n\n- Property\n  - example of mersenne primes\n    |  n   |                                   value |\n    | :--: | --------------------------------------: |\n    |  2   |                                       3 |\n    |  3   |                                       7 |\n    |  5   |                                      31 |\n    |  7   |                                     127 |\n    |  13  |                                    8191 |\n    |  17  |                                  131071 |\n    |  19  |                                  524287 |\n    |  31  |                              2147483647 |\n    |  61  |                     2305843009213693951 |\n    |  89  |             618970019642690137449562111 |\n    | 107  |       162259276829213363391578010288127 |\n    | 127  | 170141183460469231731687303715884105727 |\n\n### Resolving prime factor\n\n- Pollard Rho algorithm\n\n\n### Filter Prime Number from a range of numbers\n\nEuler's Sieve\nFor a numbers range from $2$ to $n$, we aim to sift out all primes from them, through let each composite number be screened by its minimum prime factor.\n\n- Process\n  First, We traverse the numbers $x$ range from $2$ to $n$, we join $x$ into prime set $S_p$ if $x$ is not marked as non-prime.\n\n  Meanwhile, we traversing the current prime table $p \\in S_p$, and mark $p x$ as non-prime. When $p | x$, we should stop traversing the prime table, because that the primes $p' \\in S_p$ large than $p$ are no longer the minimum prime factor of $p' x$ ($p' x = p' p r$)."
    ]
  },
  "Probability_Space": {
    "define": "$$\n<\u03a9, \\mathcal F, \\mathbb P>  \\tag{Probability Space}\n$$\nProbability Space is a [measure space](./Measurable_Space.md) including, \n\n- $\u03a9$: sample space\n- $\\mathbb P$: Probability, a measure of the sample space $\u03a9$.\n- $\\mathcal F$: a $\\sigma$-algebra of the sample space $\u03a9$.\n\n### Probability\n\n$$\n\\mathbb P: \\mathcal F \\to [0, 1]  \\tag{Probability}\n$$\n\nProbability is a set function, a measure of a set, and satisfies (Kolmogorov axiomatization):\n\n- Nonnegativity $\\mathbb P(A) \\in [0, 1] \\quad ; \\forall A \\in F$\n- Normative $\\mathbb P(\u03a9) = 1$\n- Countable Additivity \n$$\n\\mathbb P \\left(\\bigcup_i A_i \\right) = \\sum_i \\mathbb P(A_i)\n$$",
    "kids": {
      "Random_Variable": "",
      "Stochastic_Process": ""
    },
    "name": "Probability_Space",
    "parents": {
      "Measurable_Space": ""
    },
    "properties": [
      "### Large number theorem\n\n$$\n\\begin{align*}\n\\lim\\limits_{n \\to \u221e} \\mathbb P \\left(\\left|\\frac{1}{N} \\sum_{k=1}^n X_k-\u03bc \\right|<\u03b5 \\right) = 1  \\tag{Weak large number theorem}\\\\\n\\lim\\limits_{n \\to \u221e} \\mathbb P\\left(\\left|\\frac{f_A}{n}-p \\right|<\u03b5\\right) = 1  \\tag{Bernoulli large number theorem}\n\\end{align*}\n$$\n\n### Central Limit Theorem\n\n$$\n\\begin{align*}\n  \\lim\\limits_{n \\to \u221e} F_n(x) &= \\lim\\limits_{n \\to \u221e} \\mathbb P \\left(\\frac{\\sum\\limits_{k=1}^n X_k - n \u03bc}{\\sqrt{n} \u03c3} \u2264 x \\right)  \\\\\n  &= \\int_{-\u221e}^x \\frac{1}{\\sqrt{2 \u03c0}} e^{-t^2 / 2} \\mathrm d t  \\\\\n  &= \\Phi(x)\n\\end{align*}\n$$\n\n### Joint Probability\n\n$$\n\\mathbb P(A B)\n$$\nThe probability of A and B occurring together.\n\n### Conditional Probability\n\n$$\n\\mathbb P(B | A)\n$$\nProbability of occurrence of $B$ under the condition that $A$ occurs.\n\n#### Property\n\n- Independence \n  $$\n  Independence \\Leftrightarrow \\mathbb P(A B) = \\mathbb P(A) \\mathbb P(B)\n  $$\n  The occurrence of $A$ and $B$ does not affect each other.\n\n- relationship between Joint \\& Conditional probability\n  $$\n  \\begin{align*}\n    \\mathbb P(B | A) &= \\frac{\\mathbb P(A B)}{\\mathbb P(A)}  \\\\\n    \\mathbb P(A B) &= \\mathbb P(B | A) \\mathbb P(A) = \\mathbb P(A | B) \\mathbb P(B)\n  \\end{align*}\n  $$\n\n- Theorem -- Total Probability Theorem\n  $$\n  \\mathbb P(A) = \\sum_i \\mathbb P(A|B_i) \\mathbb P(B_i) \\quad; \\sum_i A_i = \u03a9\n  $$\n\n- Bayes formula\n  $$\n  \\begin{align*}\n    \\mathbb P(A | B) &= \\frac{\\mathbb P(B | A) \\mathbb P(A)}{\\mathbb P(B)}  \\\\\n    \\mathbb P(A_i | B) &= \\frac{\\mathbb P(B | A_i) \\mathbb P(A_i)}{\\sum\\limits_j \\mathbb P(B|A_j) \\mathbb P(A_j)}; \\sum_j A_j = \u03a9\n  \\end{align*}\n  $$"
    ]
  },
  "Projective_Space": {
    "define": "Given a [vector space](./Linear_Space.md) $V$ over a field $K$, the projective space $\\mathbf P(V)$ is the set of equivalence classes of $V - \\{0\\}$ under the equivalence relation $\\sim$ (equivalence relation is defined by $x \\sim y$ if there is a nonzero element $\\lambda \\in K$ such that $x = \u03bby$).",
    "kids": {},
    "name": "Projective_Space",
    "parents": {
      "Linear_Space": ""
    },
    "properties": [
      "- If $V$ is an $n+1$-dimensional vector space, then the corresponding projective space $\\mathbf P(V)$ is $n$-dimensional"
    ]
  },
  "Quadratic_Function": {
    "define": "$$\n\\begin{align*}\n  f(x) &= a x^2 + b x + c  \\tag{Univariate Quadratic}  \\\\\n  f(\\boldsymbol x) &= \\boldsymbol x^T \\boldsymbol A \\boldsymbol x + \\boldsymbol b \\boldsymbol x + c  \\tag{Multivariate}  \\\\\n    &= \\sum_{i=1}^{\\dim} \\sum_{j=1}^{\\dim} a_{ij} \u00b7 x_i x_j + \\sum_{i=1}^{\\dim} b_i x_i + c\n\\end{align*}\n$$",
    "kids": {},
    "name": "Quadratic_Function",
    "parents": {
      "Polynomial_Function": ""
    },
    "properties": [
      "### Zero Set of Quadratic Function , Quadric Surface\n\n#### Define  \nQuadric Surface is the zero set of a quadratic function,\n$$\n\\begin{align*}\n  &\\{ \\boldsymbol x \\ |\\ \\boldsymbol x^T \\boldsymbol A \\boldsymbol x + \\boldsymbol b \\boldsymbol x + c = 0\\} \\tag{Quadric Surface}\\\\\n\\Leftrightarrow &\\left\\{ \\boldsymbol x' \\ |\\ \\boldsymbol x'^T \\boldsymbol A' \\boldsymbol x' = 0, \\boldsymbol x' = \\left(\\begin{matrix} \\boldsymbol x \\\\ 1 \\end{matrix}\\right)\\right\\}\n\\end{align*}\n$$\n\n#### Solution of Univariate Quadratic Equation  \nFor the given parameters $a, b, c$, and a univariate quadratic equation,\n$$\nf(x) = a x^2 + b x + c = 0\n$$\n\nThe solutions of equation are, \n$$\n\\begin{align*}\n  x &= \\frac{- b \\pm \\sqrt{\u0394}}{2 a}\\\\\n  \u0394 &= b^2 - 4 a c\n\\end{align*}\n$$\nProperties of solutions, \n- $\u0394 > 0$, Two real roots\n- $\u0394 = 0$, A real double root\n- $\u0394 < 0$, Two complex roots\n\n#### Include\n\n##### Sphere & Spherical Surface\n\n- Define  \n  For $\\boldsymbol A = \\boldsymbol I, \\boldsymbol b = \\boldsymbol 0, c = -r^2$ of a Quadratic Function,\n  $$\n  \\begin{align*}\n    &\\{ \\boldsymbol x \\ |\\ \\|\\boldsymbol x - \\boldsymbol x_c\\|_2 \\le r < 0\\}  \\tag{Sphere}\\\\\n  \\Leftrightarrow\\quad &\\{ \\boldsymbol x \\ |\\ (\\boldsymbol x - \\boldsymbol x_c)^T (\\boldsymbol x - \\boldsymbol x_c) \\le r^2 < 0\\}  \\\\\n  \\Leftrightarrow\\quad &\\{ \\boldsymbol x_c + r \\boldsymbol u \\ |\\ \\|\\boldsymbol u\\|_2 \\le r < 0\\}\n  \\end{align*}\n  $$\n\n  $$\n  \\{ \\boldsymbol x \\ |\\ \\|\\boldsymbol x - \\boldsymbol x_c\\|_2 = r \\}  \\tag{Spherical Surface}\\\\\n  $$\n\n  Spherical Surface is a point set with a constant distance value $r$ from the center point $\\boldsymbol x_c$.\n\n<img src=\"./assets/Sphere_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n- Property\n  - Sphere is a convex set\n\n##### Ellipsoid & Ellipsoid Surface\n\n- Define  \n  In a Quadratic Function, if $\\boldsymbol A = \\boldsymbol P^{-1}, \\boldsymbol b = \\boldsymbol 0, c = -1$ is a positive definite matrix, the zero set of the function is an Ellipsoid Surface,\n  $$\n  \\begin{align*}\n    &\\left\\{ \\boldsymbol x \\ |\\ (\\boldsymbol x - \\boldsymbol x_c)^T \\boldsymbol P^{-1} (\\boldsymbol x - \\boldsymbol x_c) \\le 1, \\boldsymbol P = \\boldsymbol P^T \u2ab0 0 \\right\\}  \\tag{Ellipsoid}\\\\\n    \\Leftrightarrow\\quad &\\{ \\boldsymbol x_c + \\boldsymbol A \\boldsymbol u \\ |\\ \\|\\boldsymbol u\\|_2 \\le 1\\}\n  \\end{align*}\n  $$\n\n  $$\n  \\{ \\boldsymbol x \\ |\\ (\\boldsymbol x - \\boldsymbol x_c)^T \\boldsymbol P^{-1} (\\boldsymbol x - \\boldsymbol x_c) = 1, \\boldsymbol P = \\boldsymbol P^T \u2ab0 0\\}  \\tag{Ellipsoid Surface}\n  $$\n\n<img src=\"./assets/Ellipsoid_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n- Property\n  \n  - Ellipsoid is a convex set\n\n##### Hyperboloid\n\n- Define\n  if $\\boldsymbol A$ is a non-positive definite matrix.\n\n  Hyperboloid of one sheet, Hyperboloid of two sheets, Conical surface in between\n  \n\n<img src=\"./assets/Hyperboloid_Of_Two_Sheets_Quadric.png\" alt=\"img\" style=\"zoom: 18%;\" />\n\n<img src=\"./assets/Hyperboloid_Of_One_Sheet_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n##### Paraboloid\n\n- Define \n\n<img src=\"./assets/Paraboloid_Quadric.png\" alt=\"img\" style=\"zoom:20%;\" />\n\n<img src=\"./assets/Hyperbolic_Paraboloid_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n##### Cylinder & Cylinder Surface\n\n- Define\n\n  \n\n<img src=\"./assets/Elliptic_Cylinder_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n<img src=\"./assets/Hyperbolic_Cylinder_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n<img src=\"./assets/Parabolic_Cylinder_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />\n\n##### Cone\n\n- Define\n\n<img src=\"./assets/Circular_Cone_Quadric.png\" alt=\"img\" style=\"zoom:18%;\" />"
    ]
  },
  "Quaternion_Ring": {
    "define": "$$\nq = a + b i + c j + d k\n$$\n\nQuaternion number system extends the complex numbers. Where $a, b, c, d \\in \\mathbb R$ are [real numbers](./Real_Field.md), and $i, j, k$ are symbols that can be interpreted as unit-vectors pointing along the three spatial axes. (Quaternion [Ring](./Ring.md)) The multiplication rules for the basis elements are:\n$$\ni^2 = j^2 = k^2 = ijk = -1\n$$\n<img src=\"assets/image-20231026023813592.png\" alt=\"image-20231026023813592\" style=\"zoom:25%;\" />\n\n<img src=\"assets/Cayley_Q8_quaternion_multiplication_graph.svg\" alt=\"Cayley_Q8_quaternion_multiplication_graph\" style=\"width:120px;\" />",
    "kids": {},
    "name": "Quaternion_Ring",
    "parents": {
      "Real_Field": "",
      "Ring": ""
    },
    "properties": [
      "- The conjugate of a quaternion is defined as: $q^* = a - b i - c j - d k$.\n\n- Quaternion & Rotation\n  $$\n  q = \\cos(\\frac{\\theta}{2}) + \\sin(\\frac{\\theta}{2})(xi + yj + zk)\n  $$\n  $\\theta$ is the angle of rotation, $x, y, z$ is the unit vector component of the axis of rotation.\n\n  - Spherical linear interpolation"
    ]
  },
  "Radon_Translation": {
    "define": "For a function $f(\\boldsymbol x)$ that satisfies the three regularity conditions as above, **Radon Translation** $\\mathcal R f$ is is a [function](./Function.md) (integral transform) defined on the space of straight lines $L \\subset \\mathbb R^2$ by the line integral along each such line as, \n\n- $f(x)$ is continuous.\n- the double integral $\\iint \\frac{|f(x)|}{\\sqrt{x^2 + y^2}} \\mathrm{d}x\\mathrm{d}y$, extending over the whole plane, converges.\n- for any arbitrary point $(x, y)$ on the plane it holds that $\\lim\\limits_{r\\to\\infty} \\int\\limits_{0}^{2\\pi} f(x+r\\cos\\varphi, r + \\sin\\varphi) \\mathrm{d}\\varphi = 0$.\n\n$$\n\\begin{align*}\n\\mathcal R f(L) &= \\int_L f(\\boldsymbol x) |\\mathrm{d} \\boldsymbol x| \\\\\n\\mathcal R f(\\theta, r) &= \\int_{-\\infty}^{+\\infty} f(z \\sin \\theta + r \\cos \\theta, -z \\sin \\theta + r \\cos \\theta) \\mathrm{d} z\n\\end{align*}\n$$\n\n<img src=\"assets/894.png\" alt=\"img\" style=\"zoom:33%;\" />\n\n<img src=\"assets/Radon_transform_sinogram.gif\" alt=\"Radon_transform_sinogram\" style=\"zoom:33%;\" />",
    "kids": {},
    "name": "Radon_Translation",
    "parents": {
      "Function": ""
    },
    "properties": [
      "- The two-dimensional Fourier transform of the initial function along a line at the inclination angle is the one variable Fourier transform of the Radon transform (acquired at angle of that function.\n  $$\n  F(s\\theta)=\\int _{\\mathbb {R} }{\\mathcal {R}}f(\\theta ,r)e^{-2\\pi isr}\\,\\mathrm{d}r\n  $$\n  \n\n### Radon inversion formula\n\n$$\n\\begin{align*}\nf(\\mathbf {x} )&=\\int _{0}^{\\pi }(\\mathcal {R}f(\\cdot ,\\theta )*h)(\\left\\langle \\mathbf {x} ,\\mathbf {n} _{\\theta }\\right\\rangle )\\mathrm{d}\\theta\\\\\nf(x, y) &= \\int_0^\\pi (\\mathcal F_r^{-1}(\\mathcal F_r(\\mathcal R f(\\theta, r))(\\omega))\\cdot|\\omega|)(x \\sin \\theta + y \\cos \\theta)\\mathrm{d}\\theta\n\\end{align*}\n$$\n\nwhere $h$ is such that $\\hat h(k) = |k|$. The result obtained by Fourier transforming the Radon transform result $\\mathcal{R}f(\\theta, r)$ is filled into the line passing through the origin at an angle of $\\theta$, and finally the inverse Fourier transform is performed to obtain the original function $f(x, y)$.\n\n- Proof\n\n  Fourier Transform of the Radon Transform:\n  $$\n  \\begin{align*}\n  \\mathcal F_r(\\mathcal R f(\\theta, r))(\\omega) &= \\int_{-\\infty}^{+\\infty} \\mathcal R f(\\theta, r) e^{i\\omega r} \\mathrm{d} r\\\\\n  &= F(\\omega\\cos\\theta, \\omega\\sin\\theta)\\delta(\\omega)\n  \\end{align*}\n  $$\n  \n  $$\n  \\Rightarrow f(x, y) = \\int_0^\\pi (\\mathcal F_r^{-1}(\\mathcal F_r(\\mathcal R f(\\theta, s))(\\omega))\\cdot|\\omega|)(x \\sin \\theta + y \\cos \\theta)\\mathrm{d}\\theta\n  $$"
    ]
  },
  "Random_Variable": {
    "define": "**Random Variable**:\n$$\nX: \u03a9 \\to \\mathbb R  \\tag{Random Variable}\n$$\na random variable $X$ is a function from a sample space $\u03a9$ to the real numbers $\\mathbb R$.\n\nSymbol:\n  - $\u03a9$: sample space\n  - $\\mathbb R$: the field of real numbers\n\n- Note  \n  event set $\\{\u03b6 | X(\u03b6) \u2264 x\\}$, shorthand as $\\{X \u2264 x\\}$.\n\n**Random Vector , Multivariate random variable**:\n$$\n\\boldsymbol X = (X_1, ... , X_n)^T  \\tag{Random Vector}\n$$",
    "kids": {
      "Moment": ""
    },
    "name": "Random_Variable",
    "parents": {
      "Probability_Space": ""
    },
    "properties": [
      "### Probability Mass Function \n\n- Define \n  for a discrete Random Variable $X$\n  $$\n  \\mathbb P(X = x)\n  $$\n\n- Property\n  - Nonnegative\n    $$\n    \\mathbb P(X = x) > 0\n    $$\n\n  - Sums to 1\n    $$\n    \\sum_i \\mathbb P(X = x_i) = 1\n    $$\n\n### Cumulative Distribution Function\n\n- Define  \n  $$\n  \\begin{align*}\n    F_X(x) &= \\mathbb P(X \u2264 x)  \\\\\n    F_{\\boldsymbol X}(x) &= \\mathbb P(X_1 \u2264 x_1, ..., X_n \u2264 x_n) = \\mathbb P(\\boldsymbol X \u2264 \\boldsymbol x)\n  \\end{align*}\n  $$\n\n* Probability Generating Function\n  - Define  \n    For a discrete random variable $X$ taking values in the non-negative integers $x \\in \\mathbb Z$, the Probility Generating Function is  \n    $$\n    G(z) = \\mathbb E(z^x) = \\sum_{i=0}^\\infty z^x \\mathbb P(x)\n    $$\n\n  - Property\n    - $G(1) = 1$\n    - $\\mathbb P(X = x) = \\frac{G^{(k)}(0)}{x!}$\n    - $\\mathbb E(X) = G'(1)$\n    - $Var(X) = G''(1) + G'(1)(1 - G'(1))$ \n    - $\\mathbb E(X^k) = \\left(z \\frac{\\partial }{\\partial z}\\right) G(z)|_{z = 1}$\n\n\n### Probability Density Function\n\n- Define  \n  $$\n  \\begin{align*}\n    f_X(x) &= \\frac{\\mathrm d F_X(x)}{\\mathrm d x}  \\\\\n    f_{\\boldsymbol X}(\\boldsymbol x) &= \\frac{\u2202^n F_{\\boldsymbol X}(x)}{\u2202 x_1 ... \u2202 x_n}  \\\\\n    f_{X_i}(x_i) &= \\int_{-\\infty}^\\infty ... \\int_{-\\infty}^\\infty f_{\\boldsymbol X}(\\boldsymbol x) \\mathrm d x_1 ... \\mathrm d x_j ... \\mathrm d x_n |_{j \u2260 i}  \\tag{Marginal Probability Density}\n  \\end{align*}\n  $$\n\n### [Moment](./Moment.md)\n\n### Transformation Between Distributions\n\nFor one-to-one mapping of random variables $g: x \\to y$ and random vectors $g: \\boldsymbol  x \\to \\boldsymbol  y$, the transformation between distributions is like,\n$$\nf_Y(y) = \\frac{1}{|\\frac{\\mathrm d y}{\\mathrm d x}|} f_X(g^{-1}(y))\n$$\n\n$$\nf_{\\boldsymbol Y}(\\boldsymbol y) = \\frac{1}{|\\det(J_g)|} f_{\\boldsymbol X}(g^{-1}(\\boldsymbol y))\n$$\n\n\n\n- Problem: generation of random number\n* Mersenne Twister\n\n### Probability Distribution \n### Discrete Probability Distribution \n\n#### 0-1 distribution ; Bernoulli distribution\n\n- Define  \n  It is the discrete probability distribution of a random variable which \n  $$\n  \\begin{align*}\n  \\mathbb P(X = 1) &= p  \\\\\n  \\mathbb P(X = 0) &= 1 - p\n  \\end{align*}\n  $$\n\n- Property\n  | property | value |\n  |---|---|\n  | Support | $k\\in \\{0,1\\}$ |\n  | Probability mass function | $\\begin{array}{ll} \\mathbb P(X = 1) = p\\\\ \\mathbb P(X = 0) = 1 - p\\end{array}$ |\n  | Cumulative distribution function | $\\mathbb P(X \\le x) = \\left\\{\\begin{array}{ll} 0 & \\text { if } x<0 \\\\ 1-p & \\text { if } 0 \\leq x<1 \\\\ 1 & \\text { if } x \\geq 1 \\end{array}\\right.$ |\n  | Mean | $\\mathbb E(x) = p$ |\n  | Variance | $D(x) = p (1 - p)$ |\n  | Skewness | $\\frac{1 - 2 p}{\\sqrt{p (1 - p)}}$ |\n  | Kurtosis | $\\frac{1 - 6 p (1 - p)}{p (1 - p)}$ |\n  | Entropy | $-p \\ln p - (1-p) \\ln (1-p)$ |\n\n\n#### Binomial distribution \n\n- Define  \n  When n independent Bernoulli trials are performed with the same success probability $p$, the Binomial distribution with parameters $n$ and $p$ is the distribution of $X$, which is the number $n$ of successes.\n  $$\\mathbb P(X = k) = C^k_n p^k (1-p)^{n-k}$$\n\n- Property  \n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = n p$ |\n  | Variance | $D(x) = n p(1 - p)$ |\n  |||\n\n#### Geometric distribution \n\n- Define  \n  $$\\mathbb P(X = k) = p (1-p)^{n-1}$$\n  \u63cf\u8ff0\u8fde\u7eed\u72ec\u7acb\u91cd\u590d\u5b9e\u9a8c\u4e2d, \u9996\u6b21\u6210\u529f\u6240\u8fdb\u884c\u7684\u5b9e\u9a8c\u6b21\u6570.\n\n- Property\n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \\frac{1}{p}$ |\n  | Variance | $D(x) = \\frac{1 - p}{p^2}$ |\n  |||\n\n#### Hypergeometric distribution \n\n- Define  \n  $$\\mathbb P(X = k) = \\frac{C_M^k C_{N_M}^{n-k}}{C_N^n}$$\n\n- Property  \n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \\frac{n M}{N}$ |\n  | Variance | $D(x) = \\frac{n M}{N} (1 - \\frac{M}{N}) \\frac{N - M}{N - 1}$ |\n  |||\n\n#### Poisson distribution \n\n- Define  \n  Poisson process\uff1a \n  $$\\mathbb P(X = k) = \\frac{\u03bb^k}{k!} e^{-\u03bb}$$\n\n  2D & n-D Poisson process\uff1a\n  - the number of events in a region A is distributed $Pois(\\lambda \u00b7 area(A))\n  - the numbers of events in disjoint regions are independent of each other.\n\n- Property  \n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \u03bb$ |\n  | Variance | $D(x) = \u03bb$ |\n  |||\n\n- Theorem{Poisson\u5b9a\u7406}  \n  $$\\lim_{n \\to \\infty, p \\to 0, \u03bb = n p} \\frac{C_M^k C_{N_M}^{n-k}}{C_N^n} = \\frac{\u03bb^k}{k!} e^{-\u03bb}$$\n\n### Continuity Probability Distribution \n\n#### Uniformity distribution \n\n- Define  \n  $$\n  \\begin{align*}\n    f(x) = \\left\\{\\begin{matrix} \\frac{1}{b-a} &\\quad a < x < b \\\\ 0 &\\quad other \\end{matrix}\\right.  \\\\\n    F(x) = \\left\\{\\begin{matrix} 0 &\\quad x < a \\\\ \\frac{1}{b-a} &\\quad a \u2264 x < b \\\\ 1 &\\quad b \u2264 x \\end{matrix}\\right.\n  \\end{align*}\n  $$\n\n- Property  \n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \\frac{a + b}{2}$ |\n  | Variance | $D(x) = \\frac{(b - a)^2}{12}$ |\n  |||\n\n#### Normal distribution \n\n- Define\n  $$\n  \\begin{align*}\n    f_X(x) &= \\frac{1}{\\sqrt{2 \u03c0} \\sigma} e^{-\\frac{(x - \u03bc)^2}{2 \\sigma^2}} \\quad; x \\in (-\\infty, +\\infty)  \\\\\n    f_{\\boldsymbol X}(\\boldsymbol x) &= \\frac{1}{(2 \u03c0)^{\\frac{n}{2}} |\\boldsymbol \u03a3|^{\\frac{1}{2}}} e^{-\\frac{(\\boldsymbol x - \\boldsymbol \u03bc)\\boldsymbol \u03a3^{-1}(\\boldsymbol x - \\boldsymbol \u03bc)^T}{2}} \\tag{Multivariate Normal distribution }\n  \\end{align*}\n  $$\n\n  * Standard Normal distribution \n    $$f_X(x) = \\frac{1}{\\sqrt{2 \u03c0}} e^{-\\frac{x^2}{2}} \\quad; x \\in (-\\infty, +\\infty)$$\n    $$\u03bc = 0, \\sigma^2 = 1$$\n\n- Property  \n  - basic parameters \n    | property | value |\n    |---|---|\n    | Mean | $\\mathbb E(x) = \u03bc$ |\n    | Variance | $\\begin{array}{ll} D(x) = \\sigma^2 \\\\ D(\\boldsymbol x) = \\boldsymbol \u03a3 \\end{array}$ |\n    |||\n\n    - Proof  \n      $$\n      \\begin{align*}\n        D(x) &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}} \\sum_{i=1}^D \\sum_{j=1}^D \\boldsymbol u_i \\boldsymbol u_j^T \\int e^{-\\sum\\limits_{k=1}^D \\frac{\\boldsymbol y_k^2}{2 \u03bb_k}} y_i y_j \\mathrm d \\boldsymbol y   \\\\\n          &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}} \\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \\int e^{-\\sum\\limits_{k=1}^D \\frac{y_k^2}{2 \u03bb_k}} y_i^2 \\mathrm d \\boldsymbol y  \\tag{$i \u2260 j, \\boldsymbol u_i \\boldsymbol u_j^T=0, \\boldsymbol u_i \\boldsymbol u_j$ \u6b63\u4ea4}  \\\\\n          &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}} \\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \\int \\prod_{k=1}^D e^{-\\frac{y_k^2}{2 \u03bb_k}} y_i^2 \\mathrm d \\boldsymbol y   \\\\\n          &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}} \\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \\left(\\int_{-\\infty}^{+\\infty} e^{-\\frac{y_i^2}{2 \u03bb_i}} y_i^2 \\mathrm d y_i \u00d7 \\prod_{k=1, k \u2260 i}^D \\int_{-\\infty}^{+\\infty} e^{-\\frac{y_X^2}{2 \u03bb_k}} \\mathrm d y_k \\right)  \\tag{\u79ef\u5206\u4e58\u6cd5\u7ed3\u5408\u5f8b}  \\\\\n          &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}} \\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \\left((2 \u03c0 \u03bb_i)^{\\frac{1}{2}} \u00b7 \u03bb_i \u00d7 \\prod_{k=1, k \u2260 i}^D(2 \u03c0 \u03bb_k)^{\\frac{1}{2}} \\right)  \\tag{\u89c1\u4e0b\u9762\u63a8\u5bfc}  \\\\\n          &= \\frac{1}{(2 \u03c0)^{\\frac{D}{2}}} \\frac{1}{|\\boldsymbol \u03a3|^{\\frac{1}{2}}}  \u00b7 \\left((2 \u03c0)^{\\frac{D}{2}} \\prod_{k=1}^D \u03bb_k \\right) \u00b7 \\left(\\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \u03bb_i\\right)   \\\\\n          &= \\sum_{i=1}^D \\boldsymbol u_i \\boldsymbol u_i^T \u03bb_i  \\tag{$\\prod_{k=1}^D \u03bb_k=|\\boldsymbol \u03a3|^{\\frac{1}{2}}$}  \\\\\n          &= \\boldsymbol \u03a3\n      \\end{align*}\n      $$\n\n      when $k = i$,\n      $$\n      \\begin{align*}\n        \\int_{-\\infty}^{+\\infty} e^{-\\frac{y_\u03bb^2}{2 \u03bb_i}} y_i^2 \\mathrm d y_i &=(\u03bb_i \\sqrt{2 \u03bb_i}) \u00b7 \\int_{-\\infty}^{+\\infty} \\left(\\frac{y_i^2}{2 \u03bb_i} \\right)^{\\frac{1}{2}} e^{-\\frac{y_\u03bb^2}{2 \u03bb_i}} \\mathrm d \\frac{y_i^2}{2 \u03bb_i}   \\\\\n        &= (\u03bb_i \\sqrt{2 \u03bb_i}) \u00b7 2 \u0393(3/2)  \\tag{$\u0393(z) = \\int_0^{+\\infty} x^{z-1} e^{-x} \\mathrm d x$}  \\\\\n        &= \\sqrt{2 \u03c0 \u03bb_i} \u00b7 \u03bb_i  \\tag{$\u0393(3/2) = \\frac{\\sqrt{\u03c0}}{2}$}\n      \\end{align*}\n      $$\n\n      when $k \u2260 i$,\n      $$\n      \\begin{align*}\n        \\int_{-\\infty}^{+\\infty} e^{-\\frac{y_\u03bb^2}{2 \u03bb_k}} \\mathrm d y_k &=(\\sqrt{\\frac{\u03bb_k}{2}}) \u00b7 \\int_{-\\infty}^{+\\infty} \\left(\\frac{y_k^2}{2 \u03bb_k} \\right)^{-\\frac{1}{2}} e^{-\\frac{y_\u03bb^2}{2 \u03bb_k}} \\mathrm d \\frac{y_k^2}{2 \u03bb_k}   \\\\\n        &= \\left(\\sqrt{\\frac{\u03bb_k}{2}}\\right) \u00b7 2 \u0393(\\frac{1}{2})  \\tag{$\u0393(z) = \\int_0^{+\\infty} x^{z-1} e^{-x} \\mathrm d x$}  \\\\\n        &= \\sqrt{2 \u03c0 \u03bb_k}  \\tag{$\u0393(\\frac{1}{2}) = \\sqrt{\u03c0}$}\n      \\end{align*}\n      $$\n\n  - Conditional Distributions  \n    A multivariable $\\boldsymbol x$ is partitioned as follows\n    $$\\boldsymbol x = \\left(\\begin{matrix}\\boldsymbol x_1 \\\\ \\boldsymbol x_2\\end{matrix}\\right) \\sim \\mathcal N \\left(\\left(\\begin{matrix}\\boldsymbol \\mu_1 \\\\ \\boldsymbol \\mu_2\\end{matrix}\\right), \\left(\\begin{matrix} \\boldsymbol \\Sigma_{11} & \\boldsymbol \\Sigma_{12}\\\\ \\boldsymbol \\Sigma_{21} & \\boldsymbol \\Sigma_{22}\\end{matrix}\\right)\\right)$$\n\n    Then the distribution of $\\boldsymbol x_1$ conditional on $\\boldsymbol x_2 = a$ is still a multivariate normal \n    $$(\\boldsymbol x_1\\ |\\ \\boldsymbol x_2 = \\boldsymbol a) \\sim \\mathcal N\\left(\\boldsymbol \\mu_1 + \\boldsymbol \\Sigma_{12} \\boldsymbol \\Sigma_{22}^{-1} (\\boldsymbol a - \\boldsymbol \\mu_2), \\boldsymbol \\Sigma_{11} - \\boldsymbol \\Sigma_{12} \\boldsymbol \\Sigma_{22}^{-1} \\boldsymbol \\Sigma_{21} \\right)$$\n\n#### Rayleigh  distribution\n\n- Define  \n  $$\n    f_X(x) = \\frac{x}{\u03c3^2} e^{\\frac{-x^2}{2 \u03c3^2}}\n  $$\n\n#### $\u0393$ distribution \n\n- Define\n  $$\n    f(x) = \\left\\{\\begin{matrix} \\frac{1}{\u03b2^\u03b1 \u0393(\u03b1)} x^{a^{-1}} e^{-x / \u03b2} &\\quad x \\in (0, +\\infty) \\\\ 0 &\\quad x \\in (-\\infty, 0] \\end{matrix}\\right.\n  $$\n- Property  \n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \u03b1 \u03b2$ |\n  | Variance | $D(x) = \u03b1 \u03b2^2$ |\n  |||\n\n  when $\u03b1=1$, $\u0393$ distribution \u9000\u5316\u4e3aExponential distribution;  \n  when $\u03b1=\\frac{n}{2}, \u03b2=\\frac{1}{2}$, $\u0393$ distribution \u9000\u5316\u4e3a$\\chi^2$ distribution.\n\n#### Exponential distribution \n\n- Define  \n  $$f(x) = \\left\\{\\begin{matrix} \u03bb e^{-\u03bb x} &\\quad x \\in (0, +\\infty) \\\\ 0 &\\quad x \\in (-\\infty, 0] \\end{matrix}\\right.$$\n  $$F(x) = \\left\\{\\begin{matrix} \u03bb 1 - e^{-\u03bb x} &\\quad x \\in (0, +\\infty) \\\\ 0 &\\quad x \\in (-\\infty, 0] \\end{matrix}\\right.$$\n\n- Property\n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = \u03b8$ |\n  | Variance | $D(x) = \u03b8^2$ |\n  |||\n\n#### $\\chi^2$ distribution \n\n- Define\n  $$\\frac{1}{2^{\\frac{n}{2}} \u0393(\\frac{n}{2})} x^{\\frac{n}{2} - 1} e^{-x / 2}$$\n\n- Property\n  | property | value |\n  |---|---|\n  | Mean | $\\mathbb E(x) = n$ |\n  | Variance | $D(x) = 2 n$ |\n  |||"
    ]
  },
  "Rational_Number_Field": {
    "define": "$$\n\\mathbb{Q} = \\left\\{ \\frac{a}{b} \\mid a, b \\in \\mathbb{Z} \\text{ and } b \\neq 0 \\right\\}\n$$\n\nRational number field is a [field](./Field.md) of rational numbers is the set of all numbers that can be expressed as the quotient of two [integers](./Integer_Ring.md), where the denominator is not zero. \n\n- Addition and Multiplication are Closed\n  $$\n  \\frac{p}{q} + \\frac{r}{s} = \\frac{ps + qr}{qs}\\\\\n  \\frac{p}{q} \\times \\frac{r}{s} = \\frac{pr}{qs}\n  $$\n\n- Additive and Multiplicative Identity: $0$ is the additive identity, $1$ is the multiplicative identity.\n\n- Additive and Multiplicative Inverses: Every rational number $p/q$ has an additive inverse $-p/q$, and a multiplicative inverse $q/p$.\n\n- Additive and Multiplicative Commutativity\n  $$\n  \\frac{p}{q} + \\frac{r}{s} = \\frac{r}{s} + \\frac{p}{q}  \\\\\n  \\frac{p}{q} \\times \\frac{r}{s} = \\frac{r}{s} \\times \\frac{p}{q}\n  $$\n\n- Additive and Multiplicative Associativity\n  $$\n  \\left( \\frac{p}{q} + \\frac{r}{s} \\right) + \\frac{t}{u} = \\frac{p}{q} + \\left( \\frac{r}{s} + \\frac{t}{u} \\right)  \\\\\n  \\left( \\frac{p}{q} \\times \\frac{r}{s} \\right) \\times \\frac{t}{u} = \\frac{p}{q} \\times \\left( \\frac{r}{s} \\times \\frac{t}{u} \\right)\n  $$\n\n- Distributivity\n  $$\n  \\frac{p}{q} \\times \\left( \\frac{r}{s} + \\frac{t}{u} \\right) = \\frac{p}{q} \\times \\frac{r}{s} + \\frac{p}{q} \\times \\frac{t}{u}\n  $$",
    "kids": {
      "Real_Field": ""
    },
    "name": "Rational_Number_Field",
    "parents": {
      "Field": "",
      "Integer_Ring": ""
    },
    "properties": [
      ""
    ]
  },
  "Real_Field": {
    "define": "$$\n\\mathbb R\n$$\n\nReal numbers is defined through the Dedekind cut of rational number sets $\\mathbb Q$. The Dedekind cut is a pair of sets A and B that divide the [rational number](./Rational_Number_Field.md) set $\\mathbb Q$ into two parts, satisfying:\n\n- $A \\neq \\empty, A \\neq \\mathbb Q$\n- if $p, q \\in \\mathbb Q, p < q, q \\in A$, then $p \\in A$. \n- No maximum element in $A$, if $q \\in A$, then there must be $p \\in \\mathbb Q, p > q$, let $p \\in A$.\n\n\nEach Dedekind cut defines a real number: if the cut represents a rational number, it is that rational number, otherwise it is an irrational number.\n\n\n\nThe set of real numbers, denoted $\\mathbb{R}$, together with the operations of addition and multiplication, is called the [field](./Field.md) of real numbers if the following axioms are satisfied:\n\n**Field Axioms**:\n- (A1) $a + b = b + a$ for all $a, b \\in \\mathbb{R}$ (Commutativity of Addition).\n- (A2) $a + (b + c) = (a + b) + c$ for all $a, b, c \\in \\mathbb{R}$ (Associativity of Addition).\n- (A3) There exists an element $0 \\in \\mathbb{R}$ such that $a + 0 = a$ for all $a \\in \\mathbb{R}$ (Existence of Additive Identity).\n- (A4) For every $a \\in \\mathbb{R}$, there exists an element $-a \\in \\mathbb{R}$ such that $a + (-a) = 0$ (Existence of Additive Inverse).\n- (M1) $a \\cdot b = b \\cdot a$ for all $a, b \\in \\mathbb{R}$ (Commutativity of Multiplication).\n- (M2) $a \\cdot (b \\cdot c) = (a \\cdot b) \\cdot c$ for all $a, b, c \\in \\mathbb{R}$ (Associativity of Multiplication).\n- (M3) There exists an element $1 \\in \\mathbb{R}$, $1 \\neq 0$, such that $a \\cdot 1 = a$ for all $a \\in \\mathbb{R}$ (Existence of Multiplicative Identity).\n- (M4) For every $a \\in \\mathbb{R}$ with $a \\neq 0$, there exists an element $a^{-1} \\in \\mathbb{R}$ such that $a \\cdot a^{-1} = 1$ (Existence of Multiplicative Inverse).\n- (D) $a \\cdot (b + c) = (a \\cdot b) + (a \\cdot c)$ for all $a, b, c \\in \\mathbb{R}$ (Distributive Law).\n\n**Order Axioms**:\n- (O1) For every $a, b \\in \\mathbb{R}$, exactly one of the following holds: $a < b$, $a = b$, $a > b$.\n- (O2) If $a < b$ and $b < c$, then $a < c$.\n- (O3) If $a < b$ and $c > 0$, then $a \\cdot c < b \\cdot c$.\n- (O4) If $a < b$ and $c < 0$, then $a \\cdot c > b \\cdot c$.",
    "kids": {
      "Complex_Field": "",
      "Euclidean_Space": "",
      "Quaternion_Ring": "",
      "Real_Value_Function": ""
    },
    "name": "Real_Field",
    "parents": {
      "Field": "",
      "Rational_Number_Field": ""
    },
    "properties": [
      ""
    ]
  },
  "Real_Value_Function": {
    "define": "$$\nf: \\mathbb R \\to \\mathbb R\n$$\n\nA real function $f: \\mathbb R \\to \\mathbb R$ is a [function](./Function.md) from [real numbers](./Real_Field.md) to real numbers.\n\nFor multi-variate real functions:\n$$\nf: \\mathbb R^n \\to \\mathbb R\n$$",
    "kids": {},
    "name": "Real_Value_Function",
    "parents": {
      "Function": "",
      "Real_Field": ""
    },
    "properties": [
      "### Basic properties\n\n- Boundedness\n- Differentiability: A function is said to be differentiable at a point $x = a$ if the following limit exists:\n\n$$\nf'(a) = \\lim_{{h \\to 0}} \\frac{f(a + h) - f(a)}{h}\n$$\n- Periodicity: $f(x + T) = f(x)$.  The number $T$ is referred to as its period.\n- Odd and Even Properties\n  - Odd function: $f(-x) = -f(x)$\n  - Even function: $f(-x) = f(x)$\n\n### Limitation\n\n$$\n\\lim_{x\\rightarrow a}f(x)=L\\Leftrightarrow\\forall\\epsilon > 0,\\exists\\delta > 0,\\text{ s.t. }0 < |x - a|<\\delta\\Rightarrow|f(x)-L|<\\epsilon\n$$\n\nFor a function $f: \\mathbb R \\to \\mathbb R$ defined on some open interval that contains the number $a$, except possibly at $a$ itself. We say that the limit of $f(x)$ as $x$ approaches $a$ is equal to $L$: If and only if for any given positive number $\\epsilon > 0$ there exists a number $\\delta > 0$ such that whenever $0 < |x- a|< \\delta$ (which means $x$ is within $\\delta$ units of $a$ but not equal to a), it follows that $| f(a) - L|< \\epsilon$.\n\n#### Property\n\n- **Uniqueness**: If $\\lim\\limits_{x\\rightarrow a}f(x)$ exists, then this limit value is unique. \n\n- **Local Boundedness**: If $\\lim\\limits_{x\\rightarrow a}f(x)=L$, then there exist constants $M>0$, $\\delta>0$ and a deleted neighborhood of $a$ such that when $0 < |x - a|<\\delta$, $f(x)$ is bounded in this neighborhood $|f(x)|\\leq M$.\n\n- **Local Sign Preservation**: If $\\lim\\limits_{x\\rightarrow a}f(x)=L>0$ (or $L < 0$), then there exists a constant $\\delta>0$ and a deleted neighborhood of $a$ such that in this neighborhood $0 < |x - a|<\\delta$, $f(x)>0$ (or $f(x)<0$). If the function limit is greater than $0$, the function value is also greater than $0$ near the limit point; vice versa. \n\n- **Squeeze theorem**: Let $I$ be an interval containing the point $a$. Let $g, f, h$ be functions defined on $I$, except possibly at a itself. Suppose that for every $x$ in $I$ not equal to $a$, we have $g(x) \\le f(x) \\le h(x)$, and also suppose that\n  $$\n  \\lim\\limits_{x\\to a} g(x) = \\lim\\limits_{x\\to a} h(x) = L \\quad \\Rightarrow\\quad \\lim\\limits_{x\\to a} f(x) = L\n  $$\n\n- **Heine's Theorem (Resolution Principle)**: The necessary and sufficient condition for the existence of the limit of the function $f(x)$ as $x\\to x_0$ is that for any sequence $\\{x_n\\}$ with $x_0$ as the limit ($x_n\\neq x_0$), $\\lim_{n\\to\\infty}f(x_n)$ exists and is equal.\n\n**Equivalent Infinitesimal Formulas**: When $x \\to 0$\n\n$$\n\\begin{align*}\n\\sin x &\\sim x\\\\\n\\tan x &\\sim x\\\\\n1 - \\cos x &\\sim\\frac{1}{2}x^2\\\\\ne^x - 1 &\\sim x\\\\\n\\ln(1 + x) &\\sim x\n\\end{align*}\n$$\n\n\n#### Limit Operation Rules\n\n**Arithmetic rules of limits**: \n\n- Addition & Subtraction: $\\lim\\limits_{x\\rightarrow a}(f(x)\\pm g(x))=\\lim\\limits_{x\\rightarrow a}f(x)\\pm \\lim\\limits_{x\\rightarrow a}g(x)$\n- Multiplication: $\\lim\\limits_{x\\rightarrow a}(f(x)\\cdot g(x))=\\lim\\limits_{x\\rightarrow a}f(x)\\cdot\\lim\\limits_{x\\rightarrow a}g(x)$\n- Division: $\\lim\\limits_{x\\rightarrow a}\\frac{f(x)}{g(x)}=\\frac{\\lim\\limits_{x\\rightarrow a}f(x)}{\\lim\\limits_{x\\rightarrow a}g(x)},B\\neq0$\n\n**Infinitesimal Operation Rules**: The sum of two infinitesimals is an infinitesimal; the product of a bounded function and an infinitesimal is an infinitesimal. The corollaries include that the product of a constant and an infinitesimal is an infinitesimal, and the product of a finite number of infinitesimals is an infinitesimal.\n\n**Limit Operation Rules of Composite Functions**: Let the function $y = f(g(x))$ be composed of the function $u = g(x)$ and $y = f(u)$. $f(g(x))$ is defined in a deleted neighborhood of the point $x_0$. If $\\lim\\limits_{x \\to x_0}g(x)=u_0$ and there exists $\\delta_0>0$ such that when $x\\in U^{\\circ}(x_0,\\delta_0)$, $g(x)\\neq u_0$. If $\\lim\\limits_{u \\to u_0}f(u)=A$, then $\\lim\\limits_{x \\to x_0}f(g(x))=\\lim\\limits_{u \\to u_0}f(u)=A$.\n\n### Differential: Derivative & Partial derivative\n\n$$\n\\begin{align*}\n  \\frac{\\mathrm df}{\\mathrm dx} &= \\lim_{\u0394x \\to 0}  \\frac{ f(x + \u0394x) - f(x - \u0394x) }{ 2 \u0394x }  \\tag{First derivative}\\\\\n  \\frac{\\mathrm d^n f}{\\mathrm dx^n} &= \\lim_{\u0394x \\to 0} \\frac{ f^{(n - 1)}(x + \u0394x) - f^{(n - 1)}(x - \u0394x)} { 2 \u0394x }  \\tag{$n$-order derivative}\n\\end{align*}\n$$\n\n**Derivative**: Let $f: \\mathbb{R} \\to \\mathbb{R}$ be a function. The derivative of $f$ at a point $x$ in its domain, if it exists, is given by the limit as mentioned above . If this limit exists, we say that $f$ is differentiable at $x$. The function $f'$ that assigns to each $x$ the value $f'(x)$ (where it exists) is called the derivative of $f$.\n$$\n\\begin{align*}\n\\frac{\u2202f}{\u2202x_i} &= \\lim\\limits_{\\Delta x_i\\to0}\\frac{f(...,x_{i, 0} + \\Delta x_i,...) -  f(..., x_{i, 0} - \\Delta x_i, ...)}{2 \u0394x_i}  \\\\\n\\frac{\u2202^2 f}{\u2202x_i^2}  \n&= \\lim\\limits_{\\Delta x_i\\to0} \\frac{f'(..,x_{i, 0}+\\Delta x_i,..) -  f'(..,x_{i, 0}-\\Delta x_i,..)}{\\Delta x_i}   \\\\\n&= \\lim\\limits_{\\Delta x_i\\to0}\\frac{f(..,x_{i, 0}+\\Delta x_i) - 2\u00b7f(..,x_{i, 0}) + f(..,x_{i, 0}-\u0394x_i)}{\\Delta x_i^2}  \\\\\n\\frac{\u2202^2 f}{\u2202x_j \u2202x_i} &= \\frac{\\partial}{\\partial x_j} \\left(\\frac{\\partial f}{\\partial x_i} \\right)\n\\end{align*}\n$$\n\n**Partial derivative**: For multi-variate functions, let the function $z = f(x_{1}, \\cdots,x_{n})$ be defined in a certain neighborhood of the point $(x_{1, 0}, \\cdots,x_{n, 0})$. The partial derivative of $f$ with respect to $x$ at the point $(x_{1, 0}, \\cdots,x_{n, 0})$ is list as above.\n\n#### Property\n\n- **Necessary Condition for Differentiability**: If the function $z = f(x,y)$ is differentiable at the point $(x_0,y_0)$, then the partial derivatives $f_x(x_0,y_0)$ and $f_y(x_0,y_0)$ must exist.\n- **Sufficient Condition for Differentiability**: If the partial derivatives $f_x(x,y)$ and $f_y(x,y)$ of the function $z = f(x,y)$ are continuous in a certain neighborhood of the point $(x_0,y_0)$, then the function $z = f(x,y)$ is differentiable at the point $(x_0,y_0)$.\n\n- **Arithmetic rules**: Let $u = u(x)$ and $v = v(x)$ be differentiable at point $x$. \n\n$$\n\\begin{align*}\n(u\\pm v)'&=u'\\pm v'\\\\\n(uv)' &= u'v + uv'\\\\\n(cu)'&=cu'\\\\\n\\left(\\frac{u}{v}\\right)'&=\\frac{u'v - uv'}{v^{2}} \\quad (v\\neq0)\n\\end{align*}\n$$\n\n- **Chain Rule**: for the function $z(x) = z(y(x))$, then \n$$\n\\frac{\\mathrm d z}{\\mathrm d x} = \\frac{\\mathrm d z}{\\mathrm d y} \\cdot \\frac{\\mathrm d y}{\\mathrm d x}\n$$\n\n- **Chain Rule for Partial Derivatives**: If $z = f(u,v)$, $u = u(x,y)$, $v = v(x,y)$, then \n\n$$\n\\begin{align*}\n\\frac{\\partial z}{\\partial x}&=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial x}\\\\\n\\frac{\\partial z}{\\partial y}&=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial y}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial y}\n\\end{align*}\n$$\n\n- **Derivative Rule of Inverse Functions**: If the function $x = f(y)$ is monotonic, differentiable in the interval $I_y$ and $f'(y)\\neq0$, then its inverse function $y = f^{-1}(x)$ is also differentiable in the interval $I_x=\\{x|x = f(y),y\\in I_y\\}$, and \n\n$$\n(f^{-1})'(x)=\\frac{1}{f'(y)}\n$$\n\n- **Derivative Rule of Composite Functions**: If $u = g(x)$ is differentiable at point $x$, and $y = f(u)$ is differentiable at point $u = g(x)$, then the composite function $y = f(g(x))$ is differentiable at point $x$, and its derivative is \n$$\ny'=f'(u)\\cdot g'(x)\n$$\n\n- **L'H\u00f4pital's Rule**: if $\\lim\\limits_{x \\to a} f(x) =  \\lim\\limits_{x \\to a} g(x) = 0  \\text{ or } \\infty$ and $g'(x) \\neq 0, \\forall x \\in I \\text{ with } x \\neq a$, and $\\lim\\limits_{x \\to a} \\frac{f'(x)}{g'(x)}$ exists, then\n$$\n\\lim\\limits_{x \\to a} \\frac{f(x)}{g(x)} = \\lim\\limits_{x \\to a} \\frac{f'(x)}{g'(x)}\n$$\n\n#### Taylor's theorem\nIf a real-valued function $f(x)$ is differentiable at the point $x = a$, then \n$$\n\\begin{align*}\nf(x) &= f(a) + \\sum_{i=1}^k \\frac{f^{(i)}(a)}{i!}(x-a)^i + o(|x-a|^k)  \\\\\nf(a_1 + h_1,a_2 + h_2,\\cdots,a_n + h_n)&=f(a_1,a_2,\\cdots,a_n)+\\sum_{i = 1}^{n}\\frac{\\partial f(a_1,a_2,\\cdots,a_n)}{\\partial x_i}h_i\\\\\n&+\\frac{1}{2!}\\sum_{i = 1}^{n}\\sum_{j = 1}^{n}\\frac{\\partial^2 f(a_1,a_2,\\cdots,a_n)}{\\partial x_i\\partial x_j}h_ih_j+\\cdots\\\\\n&+\\frac{1}{m!}\\sum_{i_1 = 1}^{n}\\sum_{i_2 = 1}^{n}\\cdots\\sum_{i_m = 1}^{n}\\frac{\\partial^m f(a_1,a_2,\\cdots,a_n)}{\\partial x_{i_1}\\partial x_{i_2}\\cdots\\partial x_{i_m}}h_{i_1}h_{i_2}\\cdots h_{i_m}\\\\\n&+R_m\n\\end{align*}\n$$\n\n- $R_m$ is the remainder, which usually has the form of Lagrange remainder and Peano remainder.\n\n- **Lagrangian remainder**: where $\\theta\\in(0,1)$.\n$$\nR_m=\\frac{1}{(m + 1)!}\\sum_{i_1 = 1}^{n}\\sum_{i_2 = 1}^{n}\\cdots\\sum_{i_{m + 1}= 1}^{n}\\frac{\\partial^{m + 1} f(a_1+\\theta h_1,a_2+\\theta h_2,\\cdots,a_n+\\theta h_n)}{\\partial x_{i_1}\\partial x_{i_2}\\cdots\\partial x_{i_{m + 1}}}h_{i_1}h_{i_2}\\cdots h_{i_{m + 1}}\n$$\n\n- **Peano-type remainder**: which holds when $\\rho\\to0$, indicating that the remainder is an infinitesimal of higher order than $\\rho^m$.\n\n$$\nR_m = o(\\rho^m)$, where $\\rho=\\sqrt{h_1^2 + h_2^2+\\cdots+h_n^2}\n$$\n\n#### Mean Value Theorem\n**Lagrange's Mean Value Theorem**: If the function $y = f(x)$ satisfies: (1) continuous on the closed interval $[a,b]$; (2) differentiable on the open interval $(a,b)$, then there exists at least one point $\\xi\\in(a,b)$ such that \n$$\nf(b)-f(a)=f'(\\xi)(b - a)\n$$\n\n- **Rolle's Theorem**: If the function $y = f(x)$ satisfies: (1) continuous on the closed interval $[a,b]$; (2) differentiable on the open interval $(a,b)$; (3) $f(a)=f(b)$, then there exists at least one point $\\xi\\in(a,b)$ such that $f'(\\xi)=0$.\n\n- **Fermat's Theorem**: If the function $y = f(x)$ has a local extremum at the point $x_0$ and is differentiable at this point, then $f'(x_0)=0$.\n\n- **Cauchy's Mean Value Theorem**: If the functions $f(x)$ and $g(x)$ satisfy: (1) continuous on the closed interval $[a,b]$; (2) differentiable on the open interval $(a,b)$; (3) $g'(x)\\neq0$ for any $x\\in(a,b)$, then there exists at least one point $\\xi\\in(a,b)$ such that \n\n$$\n\\frac{f(b)-f(a)}{g(b)-g(a)}=\\frac{f'(\\xi)}{g'(\\xi)}\n$$\n\n### Gradient & Divergence & Curl\n\n$$\n\\nabla f = \\sum_{i=1}^{\\dim} \\frac{\u2202f}{\u2202x_i} \\hat{\\boldsymbol x_i} = \\left(\\begin{matrix}\\frac{\u2202f}{\u2202x_1} \\\\ \\vdots \\\\ \\frac{\u2202f}{\u2202x_{\\dim}}\\end{matrix}\\right)  \\tag{Gradient}\n$$\n\n**Gradient** $\\nabla (\\cdot): (f: \\mathbb R^{\\dim} \\to \\mathbb R) \\to (f: \\mathbb R^{\\dim} \\to \\mathbb R^{\\dim})$, reflects the direction of the maximum rate of change for function $f$ at point $\\boldsymbol x_0$.\n\n$$\n\\nabla \u00b7 \\boldsymbol f = \\lim_{|V| \\to 0} \\frac{1}{|V|} \\oint_{S(V)} \\boldsymbol f \\cdot \\hat {\\boldsymbol n} \\mathrm d S \\tag{Divergence}\n$$\n$$\n\\nabla \u00b7 \\boldsymbol f = \\sum_{i=1}^{\\dim} \\frac{\u2202f_{i}}{\u2202x_i}  \\tag{Cartesian coordinates}\n$$\n\n**Divergence** $\\nabla \\cdot (\\cdot): (f: \\mathbb R^{\\dim} \\to \\mathbb R^{\\dim}) \\to (f: \\mathbb R^{\\dim} \\to \\mathbb R)$. For a vector field $\\boldsymbol f(\\boldsymbol x)$, the divergence is defined as the limit of the redio of the surface integral of $\\boldsymbol f$ out of the closed surface $S$ of a valume $V$ enclosing point $\\boldsymbol x_0$, as $V$ shrinks to $0$. The divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point.\n\n$$\n\\nabla \\times \\boldsymbol f = \\lim_{A \\to 0} \\frac{1}{|A|} \\oint_{C} \\boldsymbol f \\cdot \\mathrm d \\boldsymbol r \\tag{Curl}\n$$\n$$\n\\begin{align*}\n  \\nabla \\times \\boldsymbol f =& \\left(\\frac{\u2202f_z}{\u2202y} - \\frac{\u2202f_y}{\u2202z} \\right) \\hat{\\boldsymbol x} + \\\\\n  & \\left(\\frac{\u2202f_x}{\u2202z} - \\frac{\u2202f_z}{\u2202x} \\right) \\hat{\\boldsymbol y}  +\\\\\n  & \\left(\\frac{\u2202f_y}{\u2202x} - \\frac{\u2202f_x}{\u2202y} \\right) \\hat{\\boldsymbol z}  \\tag{3D Cartesian coordinates}\n\\end{align*}\n$$\n\n\n**Curl** $\\nabla \\times (\\cdot): (f: \\mathbb R^{3} \\to \\mathbb R^{3}) \\to (f: \\mathbb R^{3} \\to \\mathbb R)$. For a vector field in three-dimensional $\\boldsymbol f(\\boldsymbol x)$, the curl is defined as the limit of the redio of the line integral of $\\boldsymbol f$ along the boundary $C$ of a area $A$ enclosing point $\\boldsymbol x_0$, as $A$ shrinks to $0$. The curl represents the circulation density at each point of the field. \u65b9\u5411\u662f\u65cb\u8f6c\u5ea6\u6700\u5927\u7684\u73af\u91cf\u7684\u65cb\u8f6c\u8f74, \u65cb\u8f6c\u7684\u65b9\u5411\u6ee1\u8db3\u53f3\u624b\u5b9a\u5219, \u5927\u5c0f\u662f\u7ed5\u8be5\u65cb\u8f6c\u8f74\u65cb\u8f6c\u7684\u73af\u91cf\u4e0e\u65cb\u8f6c\u8def\u5f84\u56f4\u6210\u7684\u9762\u5143\u9762\u79ef\u4e4b\u6bd4.\n\n#### Property\n\n- $\\nabla \\times (\\nabla \\phi) = 0$, for any scalar field $\\phi$.\n- $\\nabla \\cdot (\\nabla \\times \\boldsymbol F) = 0$, for any vector field (in three dimensions) $\\boldsymbol F$. \n- $\\nabla \\cdot (\\phi \\boldsymbol F) = (\\nabla \\phi) \\cdot \\boldsymbol F + \\phi (\\nabla \\cdot \\boldsymbol F)$\n- $\\nabla \\times (\\phi \\boldsymbol F) = (\\nabla \\phi) \\times \\boldsymbol F + \\phi (\\nabla \\times \\boldsymbol F)$\n\n### Integral\n\n$$\n\\int f(x) \\mathrm d x  = F(x)  + const. \\tag{Integral}\n$$\nIntegral $f: (f: \\mathbb R \\to \\mathbb R) \\to (f: \\mathbb R \\to \\mathbb R)$ represents the anti-derivative of a function $f(x)$. The indefinite integral of a function $f$ is a family of functions $F$ such that for all $x$ in the domain of $f$, $F'(x) = f(x)$. Where $const.$ is an arbitrary constant, reflecting the fact that the process of differentiation loses constant information.\n\n#### Integral of multivariate functions\n\n$$\n\\int\\cdots\\int f(x_1,x_2,\\cdots,x_n)dx_1dx_2\\cdots dx_n=H(x_1,x_2,\\cdots,x_n)+C\n$$\n\nFor an $n -$variable function $y = f(x_1,x_2,\\cdots,x_n)$, if there exists a function $H(x_1,x_2,\\cdots,x_n)$ such that $\\frac{\\partial H(x_1,x_2,\\cdots,x_n)}{\\partial x_i}=f(x_1,x_2,\\cdots,x_n)$ for $i = 1,2,\\cdots,n$, then $H(x_1,x_2,\\cdots,x_n)$ is a primitive function of $f(x_1,x_2,\\cdots,x_n)$. The indefinite integral of $f(x_1,x_2,\\cdots,x_n)$ is defined as above.\n\n#### Property\n\n- Integration by part: for two continuously differentiable functions $u, v$, \n  $$\n  \\int u \\mathrm d v = uv - \\int v \\mathrm d u\n  $$\n  \n\n**Substitution Integration Formula**:\n\n- **First Substitution**: If $x=\\varphi(t)$ is differentiable, and $\\varphi^\\prime(t)$ is continuous, and $f(x)$ is continuous on the corresponding interval, then \n\n$$\n\\int f(x)dx=\\int f[\\varphi(t)]\\varphi^\\prime(t)dt\n$$\n\n- **Second Substitution**: If $x=\\varphi(t)$ has an inverse function $t=\\varphi^{-1}(x)$, and $\\varphi^\\prime(t)$ is continuous and $\\varphi^\\prime(t)\\neq0$, and $f[\\varphi(t)]\\varphi^\\prime(t)$ has an antiderivative $F(t)$, then \n\n$$\n\\int f(x)dx = F[\\varphi^{-1}(x)]+C\n$$\n\n\n### Riemann Integra\n\n$$\n\\int_a^b f(x) \\mathrm d x = F(b) - F(a) \\tag{Definite Integral}\n$$\n\nDefinite Integral $f: (\\mathbb R, \\mathbb R, f: \\mathbb R \\to \\mathbb R) \\to \\mathbb R$ of a function f(x) over an interval $[a, b]$ is the limit of a sum of rectangular areas as the width of the rectangles approaches zero. \n\n\n#### Riemann Integral of multivariate functions\n\n$$\n\\int\\cdots\\int_{D}f(\\mathbf{x})dV=\\lim\\limits_{\\lambda\\rightarrow0}\\sum_{i = 1}^{N}f(\\mathbf{\\xi}_i)\\Delta V_i\n$$\n\nLet $f(\\mathbf{x})$ be a bounded function defined on a closed region $D$ in $n$-dimensional space $\\mathbb{R}^{n}$, where $\\mathbf{x}=(x_1,x_2,\\cdots,x_n)$. We divide the region $D$ into $N$ small subregions $\\Delta V_i$ ($i = 1,2,\\cdots,N$) and let $\\lambda$ be the maximum diameter of these small subregions. Arbitrarily choose a point $\\mathbf{\\xi}_i=(\\xi_{i1},\\xi_{i2},\\cdots,\\xi_{in})$ in each small subregion $\\Delta V_i$. The $n$-dimensional integral of $f(\\mathbf{x})$ over the region $D$ is then defined as above. If this limit exists, the function $f(\\mathbf{x})$ is said to be integrable over the region $D$.\n\nIn the context of measure theory, if $\\mu$ is a measure on $\\mathbb{R}^{n}$, the integral of $f$ over $D$ can also be written as $\\int_{D}f(\\mathbf{x})d\\mu(\\mathbf{x})$, where $d\\mu$ represents the measure element. When $\\mu$ is the Lebesgue measure, it corresponds to the usual volume measure in $\\mathbb{R}^{n}$ and the above definition in terms of $\\Delta V_i$ is consistent with the Lebesgue integral.\n\n#### Property\n\n- **Riemann Integral Existence Theorem**: If a function $f(x)$ is continuous on the interval $[a, b]$, or has only a finite number of first-kind discontinuities on $[a, b]$, then $f(x)$ is Riemann integrable on $[a, b]$.\n\n- **Linearity**: $\\int_{a}^{b}[k_1f(x)+k_2g(x)]dx = k_1\\int_{a}^{b}f(x)dx + k_2\\int_{a}^{b}g(x)dx$, where $k_1,k_2$ are constants.\n- **Additivity of Intervals**: $\\int_{a}^{b}f(x)dx=\\int_{a}^{c}f(x)dx+\\int_{c}^{b}f(x)dx$, where $a < c < b$.\n- **Comparison Theorem**: If $f(x)\\leq g(x)$ on $[a, b]$, then $\\int_{a}^{b}f(x)dx\\leq\\int_{a}^{b}g(x)dx$.\n- **Estimation Theorem**: If $m\\leq f(x)\\leq M$ on $[a, b]$, then $m(b - a)\\leq\\int_{a}^{b}f(x)dx\\leq M(b - a)$.\n- **Integral Mean Value Theorem**: If $f(x)$ is continuous on $[a, b]$, then there exists $\\xi\\in[a, b]$ such that \n$$\n\\int_{a}^{b}f(x)dx = f(\\xi)(b - a)\n$$\n\n- **Green's Theorem**: Let $D$ be a closed region in the plane bounded by a piecewise smooth simple closed curve $L$, and $P(x,y)$ and $Q(x,y)$ have continuous partial derivatives on $D$. \n$$\n\\underset{D}{\\iint}\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)dxdy=\\oint_{L}Pdx + Qdy\n$$\n\n- **Gauss's Theorem**: Let $\\varOmega$ be a closed region in space bounded by a piecewise smooth closed surface $\\varSigma$, and $P(x,y,z)$, $Q(x,y,z)$, $R(x,y,z)$ have continuous partial derivatives on $\\varOmega$. \n$$\n\\underset{\\varOmega}{\\iiint}\\left(\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z}\\right)dxdydz=\\underset{\\varSigma}{\u222f}Pdydz + Qdzdx+Rdxdy\n$$\n\n- **Stokes' Theorem**: Let $\\varSigma$ be a piecewise smooth oriented surface in space bounded by a piecewise smooth simple closed curve $L$, and $P(x,y,z)$, $Q(x,y,z)$, $R(x,y,z)$ have continuous partial derivatives on an open region containing $\\varSigma$.\n$$\nunderset{\\varSigma}{\\iint}\\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right)dydz+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right)dzdx+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)dxdy=\\oint_{L}Pdx + Qdy+Rdz\n$$\n\n- **\u79ef\u5206\u4e2d\u503c\u5b9a\u7406**\uff1a\u5982\u679c\u51fd\u6570$f(x)$\u5728\u95ed\u533a\u95f4$[a,b]$\u4e0a\u8fde\u7eed\uff0c\u5219\u5728\u79ef\u5206\u533a\u95f4$[a,b]$\u4e0a\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u70b9$\\xi$\uff0c\n$$\n\\int_{a}^{b}f(x)dx = f(\\xi)(b - a)$\uff0c$a\\leq\\xi\\leq b\n$$\n\n**Double & Triple Integral Conversion Formula**: \n\n- Double Integral Conversion Formula\n$$\n\\begin{align*}\n\\iint\\limits_{D}f(x,y)d\\sigma&=\\int_{a}^{b}dx\\int_{c}^{d}f(x,y)dy=\\int_{c}^{d}dy\\int_{a}^{b}f(x,y)dx\\\\\n&=\\iint\\limits_{D}f(r\\cos\\theta,r\\sin\\theta)rdrd\\theta=\\int_{\\alpha}^{\\beta}d\\theta\\int_{r_1(\\theta)}^{r_2(\\theta)}f(r\\cos\\theta,r\\sin\\theta)rdr\n\\end{align*}\n$$\n\n- Triple Integral Conversion Formula\n\n$$\n\\begin{align*}\n\\iiint\\limits_{\\Omega}f(x,y,z)dV&=\\int_{a}^{b}dx\\int_{c}^{d}dy\\int_{e}^{f}f(x,y,z)dz\\\\\n&=\\iiint\\limits_{\\Omega}f(r\\cos\\theta,r\\sin\\theta,z)rdrd\\theta dz\\\\\n\\end{align*}\n$$\n\n### Continuity\n\nLet the function $y = f(x)$ be defined in a certain neighborhood of the point $x_0$, if $\\lim\\limits_{x\\rightarrow x_0}f(x)=f(x_0)$, then the function $f(x)$ is said to be continuous at the point $x_0$. Formally, for any positive number $\\epsilon > 0$, if there exists a positive number $\\delta > 0$ such that whenever $|x - a| < \\delta$, $|f(x) - f(a)| < \\epsilon$, the function is said to be continuous at $a$. Intuitively, the continuity of a function at a point means that the graph of the function is unbroken at that point.\n\n#### Discontinuity classification\n\n- **Removable Discontinuity**: If $\\lim\\limits_{x\\rightarrow x_0^{-}}f(x)=\\lim\\limits_{x\\rightarrow x_0^{+}}f(x) = L$, but $f(x_0)$ is either not defined or $f(x_0)\\neq L$, then $x_0$ is a removable discontinuity point.\n- **Jump Discontinuity**: If $\\lim\\limits_{x\\rightarrow x_0^{-}}f(x)=L_1$ and $\\lim\\limits_{x\\rightarrow x_0^{+}}f(x)=L_2$, and $L_1\\neq L_2$, then $x_0$ is a jump discontinuity point.\n\n - **Second-kind Discontinuity Points**: If at least one of the one-sided limits $\\lim\\limits_{x\\rightarrow x_0^{-}}f(x)$ and $\\lim\\limits_{x\\rightarrow x_0^{+}}f(x)$ does not exist (including the cases where the limit is infinite), then $x_0$ is a second - kind discontinuity point. \n\n#### Properties\n\n- **Local Boundedness**: If the function $f(x)$ is continuous at the point $x_0$, then there exists a neighborhood of $x_0$ within which $f(x)$ is bounded.\n- **Local Sign Preserving preservation**: If $f(x)$ is continuous at $x_0$ and $f(x_0)>0$ (or $f(x_0)<0$), then there exists a certain neighborhood of $x_0$ within which $f(x)>0$ (or $f(x)<0$).\n- **Properties of Arithmetic Operations**: If the functions $f(x)$ and $g(x)$ are both continuous at the point $x_0$, then $f(x)\\pm g(x)$, $f(x)g(x)$, and $\\frac{f(x)}{g(x)}(g(x_0)\\neq0)$ are also continuous at the point $x_0$.\n\n### Monotonicity \n\nLet the domain of the function $y = f(x)$ be $I$. For any two values of the independent variable $x_1$, $x_2$ in an interval $D$ within the domain $I$, when $x_1 < x_2$, if $f(x_1)<f(x_2)$ (or $f(x_1)>f(x_2)$), then the function $f(x)$ is said to be an increasing function (or a decreasing function) on the interval $D$.\n\n#### Determination Methods\n\n**Derivative Method**: If the function $y = f(x)$ is differentiable in the interval $(a,b)$, then a necessary and sufficient condition for $f(x)$ to be monotonically increasing in $(a,b)$ is that $f'(x)\\geq0$ holds constantly in $(a,b)$, and $f'(x)$ is not constantly zero in any sub-interval of $(a,b)$. A necessary and sufficient condition for $f(x)$ to be monotonically decreasing in $(a,b)$ is that $f'(x)\\leq0$ holds constantly in $(a,b)$, and $f'(x)$ is not constantly zero in any sub-interval of $(a,b)$.\n\n#### Properties\n\n- **Monotonicity of Composite Functions**: If the function $u = g(x)$ is monotonic on the interval $[a,b]$, the function $y = f(u)$ is monotonic on the interval $[c,d]$, and when $x\\in[a,b]$, $u = g(x)\\in[c,d]$, then the composite function $y = f(g(x))$ is monotonic on the interval $[a,b]$. When the monotonicities of the inner and outer functions are the same, the composite function is an increasing function; when the monotonicities of the inner and outer functions are different, the composite function is a decreasing function.\n\n### Concavity & Convexity\n\n$$\n\\begin{align*}\nf \\left(\\frac{x_1 + x_2}{2} \\right)<\\frac{f(x_1)+f(x_2)}{2}  \\tag{concave}\\\\\nf \\left(\\frac{x_1 + x_2}{2} \\right)>\\frac{f(x_1)+f(x_2)}{2}  \\tag{convex}\\\\\n\\end{align*}\n$$\n\n\nLet the function $f(x)$ be defined on the interval $I$. For any two points $x_1$, $x_2$ in $I$, if $f(\\frac{x_1 + x_2}{2})<\\frac{f(x_1)+f(x_2)}{2}$ always holds, then $f(x)$ is called a concave function on the interval $I$; if $f(\\frac{x_1 + x_2}{2})>\\frac{f(x_1)+f(x_2)}{2}$ always holds, then $f(x)$ is called a convex function on the interval $I$.\n\n#### Determination Methods\n\n**Derivative Method**: Suppose the function $f(x)$ has a second - derivative $f''(x)$ in the interval $(a,b)$. If $f''(x)>0$ in $(a,b)$, then the function $f(x)$ is a concave function in $(a,b)$; if $f''(x)<0$ in $(a,b)$, then the function $f(x)$ is a convex function in $(a,b)$.\n\n#### Properties\n- **Sum**: If $f(x)$ and $g(x)$ are both concave / convex on the interval $I$, then $f(x)+g(x)$ is also concave / convex on the interval $I$.\n\n### Kolmogorov-Arnold Representation Theorem  \n\n$$\nf(\\boldsymbol x) = f(x_1, ..., x_n) = \\sum_{q=0}^{2n} \\Phi_q\\left( \\sum_{p=1}^n \\phi_{q, p}(x_p) \\right)\n$$\nKolmogorov-Arnold representation theorem states that every multivariate continuous function can be represented as a superposition of the two-argument addition of continuous functions of one variable.\n\n\n### Differential Equation\n\n$$\nf \\left(x, y, \\frac{\\mathrm d y}{\\mathrm d x}, \\frac{\\mathrm d^2 y}{\\mathrm dx^2}, ..., \\frac{\\mathrm d^n y}{\\mathrm d x^n} \\right) = 0  \\tag{ODE}\n$$\nOrdinary differential equation (ODE) is an equation that relates an unknown function $y$ to its derivatives with respect to a single independent variable $x$.  \n\n$$\nf \\left(D^k u(x), ... , D^2 u(x), u(x), x \\right) = 0  \\tag{PDE}\n$$\n$$\nf: \\mathbb R^{n^k} \\times \\mathbb R^{n^{k-1}} \\times \\mathbb R^n \\times \\mathbb R \\times \\Omega \\to \\mathbb R \\quad; x \\in \\Omega; u: \\Omega \\to \\mathbb R\n$$\nPartial differential equation (PDE) is an equation that relates an unknown function $u$ of two or more variables to its partial derivatives with respect to those variables.\n\n#### Linear Differential Equation\n\n$$\n\\sum_{k=0}^K a_k(x) u^{(k)}(x) = f(x)  \\tag{Linear ODE}\n$$\n$$\n\\sum_{k=0}^K a_k(x) D^k u(x) = f(x)  \\tag{Linear PDE}\n$$\n\n- Property\n  - The solution set of a linear differential equation constitutes a linear space.\n\n#### Second Order Nonlinear Partial Differential Equation\n\n$$\n\\sum_{ij} a_{ij}(x) \\frac{\u2202^2 u}{\u2202 x_i \u2202 x_j} + \\sum_i b_i(x) \\frac{\u2202 u}{\u2202 x_i} + c(x) u(x) = f(x)\n$$\ncoefficient matrix $A(x) = (a_{ij}(x))_{m \\times m}$\n\nInclude\n* Elliptic Partial Differential Equation\n\n  $A(x)$ is negative definite.\n\n* Include\n  * Poisson's Equations\n    - Define\n      $$\n      -\\nabla^2 \\phi = f\n      $$\n    * Laplace's Equations\n      $$\n      \\nabla^2 \\phi = 0\n      $$\n\n* Hyperbolic Partial Differential Equation\n\n  eigenvalue of $A(x)$ consists of a $0$ and other negative numbers\n\n  - Include\n    * Diffusion equation\n      - Define\n        $$\n        \\frac{\u2202u}{\u2202t} - a \\nabla^2 u = f(x,t)\n        $$\n\n* Parabolic Partial Differential Equation\n\n  eigenvalue of $A(x)$ consists of of a positive number and other negative numbers.\n\n  - Include\n    * Wave equation\n      $$\n      \\frac{\u2202^2 u}{\u2202t^2} - a \\nabla^2 u = f(x,t)\n      $$\n\n#### Semi-linear Partial Differential Equation\n\n#### Quasi-linear Partial Differential Equation\n\n#### Fully Nonlinear Partial Differential Equation"
    ]
  },
  "Relation": {
    "define": "$$\nR(A_1, A_2, \\cdots, A_n) \\subseteq A_1 \\times A_2 \\times \\cdots \\times A_n  \\tag{Relation}\n$$\n\nA $n$-ary **relation** $R$ in sets $A_1, A_2, \\cdots, A_n$ is a [subset](./Set.md) of their Cartesian product $A_1 \\times A_2 \\times \\cdots \\times A_n$. Relation is like a table, consists of a set of tuples (rows) and attributes (columns).\n\n- $n$ Degree: The number of attributes (columns) in a relation.\n- Cardinality: The number of tuples (rows) in a relation.",
    "kids": {
      "Function": ""
    },
    "name": "Relation",
    "parents": {
      "Set": ""
    },
    "properties": [
      "### Operations\n\n#### Set operations\n\nA relation is essentially a set, so it possesses the same operations as a set.\n\n- **Intersection** (\u2229): returns the rows that are common to both relations.\n\n$$\nR\\cap S=\\{t|t\\in R\\land t\\in S\\} \\text{ and } R\\cap S = R-(R - S)\n$$\n\n- **Union** (\u222a): combines the results of two relations. The relations must be union-compatible (i.e., they have the same number of columns with the same domains).\n\n$$\nR\\cup S = \\{t|t\\in R \\lor t\\in S\\}\n$$\n\n- **Set Difference** (\u2212): returns the rows that are in the first relation but not in the second.\n\n$$\nR - S = \\{t|t\\in R \\land t\\notin S\\}\n$$\n\n- **Cartesian Product** (\u00d7): combines each row of the first relation with every row of the second relation.\n\n$$\nR\\times S=\\{(r_1,r_2,\\cdots,r_m,s_1,s_2,\\cdots,s_n)|(r_1,r_2,\\cdots,r_m)\\in R\\land(s_1,s_2,\\cdots,s_n)\\in S\\}\n$$\n\n\n#### Select & Projection\n\n**Select** (\u03c3): filters rows based on a specified condition (predicate).\n$$\n\\sigma_\\text{condition}(R)=\\{t|t\\in R\\land F(t)=\\text{True}\\}\n$$\n\n**Projection** (\u03c0): selects specific columns from a relation.\n$$\n\\pi_{A}(R)=\\{t[A]|t\\in R\\}\n$$\n\n#### Join\n\n$$\nR\\Join_{A\\theta B}S=\\sigma_{A\\theta B}(R\\times S)  \\tag{join}\n$$\n\n**Join** ($\\Join$): combines related tuples from two relations based on a condition, typically a common attribute. Where A and B are groups of attributes of equal and comparable degree on R and S respectively, and $\\theta$ is a comparison operator.\n\n$$\n\\begin{align*}\nR\\Join_{L,\\theta}S &=\\{(r_1,\\cdots,r_m,s_1,\\cdots,s_n)\\mid (r_1,\\cdots,r_m)\\in R\\land((\\exists(s_1,\\cdots,s_n)\\in S: \\theta((r_1,\\cdots,r_m),(s_1,\\cdots,s_n)))\\lor\\forall(s_1,\\cdots,s_n)\\in S:\\neg\\theta((r_1,\\cdots,r_m),(s_1,\\cdots,s_n))\\land(s_1 = \\text{null},\\cdots,s_n=\\text{null}))\\}\\\\\nR\\Join_{R,\\theta}S &=\\{(r_1,\\cdots,r_m,s_1,\\cdots,s_n)\\mid (s_1,\\cdots,s_n)\\in S\\land((\\exists(r_1,\\cdots,r_m)\\in R: \\theta((r_1,\\cdots,r_m),(s_1,\\cdots,s_n)))\\lor\\forall(r_1,\\cdots,r_m)\\in R:\\neg\\theta((r_1,\\cdots,r_m),(s_1,\\cdots,s_n))\\land(r_1 = \\text{null},\\cdots,r_m=\\text{null}))\\}\\\\\nR\\Join_{\\text{full},\\theta}S &=(R\\Join_{L,\\theta}S)\\cup(R\\Join_{R,\\theta}S)\n\\end{align*}    \\tag{outer join}\n$$\n\nOuter Join (Left, Right, Full): Joins relations but retains rows from one or both relations that do not meet the join condition, filling with nulls where necessary.\n\n- **Left Outer Join ($\\Join_L$)**: Keeps all rows from the left relation. For each row $r$ in $R$, if there is a row $s$ in $S$ such that $\\theta(r, s)$ holds, then the pair $(r, s)$ is in $R\\Join_{L,\\theta}S$. If there is no such row $s$ in $S$ that satisfies $\\theta(r, s)$, then the pair $(r, (\\text{null},\\cdots,\\text{null}))$ is in $R\\Join_{L,\\theta}S$.\n- **Right Outer Join ($\\Join_R$)**: Keeps all rows from the right relation. For each row $s$ in $S$, if there is a row $r$ in $R$ such that $\\theta(r, s)$ holds, then the pair $(r, s)$ is in $R\\Join_{R,\\theta}S$. If there is no such row $r$ in $R$ that satisfies $\\theta(r, s)$, then the pair $(( \\text{null},\\cdots,\\text{null}), s)$ is in $R\\Join_{R,\\theta}S$.\n- **Full Outer Join ($\\Join_\\text{full}$)**: Keeps rows from both relations.\n\n$$\nR\\bowtie S=\\left\\{(r_1,\\cdots,r_m,s_1,\\cdots,s_n)\\mid r\\in R\\land s\\in S\\land\\bigwedge_{i = 1}^{k}(r[C_i]=s[C_i])\\right\\}/_{\\sim}  \\tag{natural join}\n$$\n\n\n\nNatural join of relations $R$ and $S$ is an special join where the join condition is defined by common attributes having equal values, combines tuples from $R$ and $S$ where the values of the common attributes are equal. \n\n- $R$: The first relation, $R$ has attributes $A_1, A_2,\\cdots, A_m$.\n- $S$: The second relation, $S$ has attributes $B_1, B_2,\\cdots, B_n$\n- $C$: the set of common attributes between $R$ and $S$. $C = \\{C_1,C_2,\\cdots,C_k\\}\\subseteq\\{A_1,\\cdots,A_m\\}\\cap\\{B_1,\\cdots,B_n\\}$.\n- $\\theta$: the join condition (a boolean valued function on the attributes of $R, S$)\n- $\\sim$: represents an equivalence relation that removes the duplicate columns of the common attributes. That is, we only keep one copy of each common attribute in the final result.\n\n### Binary Relation\n\n\n$$\nX \\ R\\ Y \\subseteq X \\times Y  \\tag{Binary Relation}\n$$\nBinary Relation $R$ over set $X, Y$ is a subset of the Cartesian product $X \\times Y$. The set $X$ is called the domain, and set $Y$ the codomain."
    ]
  },
  "Riemann_Zeta_Function": {
    "define": "$$\n\\zeta(s)=\\sum_{n=1}^{\\infty} \\frac{1}{n^{s}}=\\frac{1}{\\Gamma(s)} \\int_{0}^{\\infty} \\frac{x^{s-1}}{e^{x}-1} \\mathrm{~d} x\n$$\n\nRiemann zeta function for $s$ where $\\Re(s) > 1$ is as described above ([Complex function](./Complex_Value_Function.md)). (This series is absolutely convergent in the above region.) The Riemann function is analytically extended to the complex plane, anywhere except for point $s=1$, achieved through a series of functional relationships and integral representations. At $s = 1$, the Riemannian function has a simple pole.\n\n<img src=\"assets/R.0a748464f04900f38f6f535deb08f1d1\" alt=\"img\" style=\"zoom: 20%;\" />",
    "kids": {},
    "name": "Riemann_Zeta_Function",
    "parents": {
      "Complex_Value_Function": ""
    },
    "properties": [
      "- the relationship with primes\n  $$\n  \\zeta(s) = \\prod_{p \\text{ is prime}} \\frac{1}{1 - p^{-s}}\n  $$\n\n- Riemann Hypothesis: Riemann zeta function has its zeros only at the negative even integers and complex numbers with real part $\\frac{1}{2}$."
    ]
  },
  "Ring": {
    "define": "$$\n(G, +, \\cdot)\n$$\n\nRing is an algebraic structure, where $G$ is a set, $\\cdot$ and $+$ are binary operations, and satisfy:  \n\n- $(G, +)$ is a commutative group\n- $(G, \\cdot)$ is a monoid\n  - $(G, \\cdot)$ satisfies associative law, $a \\cdot (b \\cdot c) = (a \\cdot b) \\cdot c$\n  - $(G, \\cdot)$ exists multiplicative identity, $\\exist 1: 1 \\cdot x = x \\cdot 1 = x, \\forall x \\in G$\n- Distributive law: multiplication is distributive with respect to addition,\n  $$\n  \\begin{align*}\n    a \\cdot (b + c) &= a \\cdot b + a \\cdot c  \\\\\n    (b + c) \\cdot a &= b \\cdot a + c \\cdot a\n  \\end{align*}\n  $$",
    "kids": {
      "Field": "",
      "Integer_Ring": "",
      "Module": "",
      "Quaternion_Ring": ""
    },
    "name": "Ring",
    "parents": {
      "Algebra_Structure": ""
    },
    "properties": [
      "### Ideal\n\n- Define\n\n  Let $R$ be a ring and $I$ be a subring of $R$, if $\\forall i \\in I, \\forall r \\in R$, $i\\cdot r = r \\cdot i \\in I$,  we call $I$ is the ideal subring of $R$.\n\n- Property\n  - Quotient Ring\n\n- Include\n\n  - Prime Ideal\n\n    An ideal $I$ of a commutative ring $R$ is called a prime ideal if, whenever the product of two elements $a, b \\in R$ is an element of $I$, at least one of $a$ or $b$ is in $I$. Symbolically, if $I$ is a prime ideal and $ab \\in I$, then either $a \\in I$ or $b \\in I$.\n\n  - Maximal Ideal\n\n    An ideal $I$ of a ring $R$ is called a maximal ideal if it is a proper ideal (i.e., $I \\neq R$) and there are no other proper ideals properly containing $I$. In other words, there does not exist another ideal $J$ such that $I \\subsetneq J \\subsetneq R$.\n\n### Polynomial Ring\n\nThe polynomial ring $K[x]$ in $x$ over a field (or, more generally, a commutative ring) $K$ defined as the set of all polynomials in the variable $x$ with coefficients $p_i \\in K$ and a non-negative integer $n$ (representing the degree of the polynomial). \n$$\nf(x) = p_{0}+p_{1}x+p_{2}x^{2}+\\cdots +p_{n}x^{n}\n$$\n\n- **Addition**: $g(x) + f(x)$ is the polynomial whose coefficient of $x_i$ is $a_i + b_i$ for each $i$.\n- **Multiplication**: Given two polynomials $f, g$, their product $f \\cdot g$ is computed using the distributive property.\n\n  \n\n### Commutative Ring\n\nA Ring satisfying commutative law.\n$$\na \\cdot b = b \\cdot a \\quad; \\forall a, b \\in G\n$$"
    ]
  },
  "Sequence": {
    "define": "$$\nf: \\mathbb N \\to S  \\tag{Sequence}\n$$\n$$\n\\begin{align*}\n(a_1, a_2, \\cdots, a_n)  \\tag{Finite sequence}\\\\\n(a_1, a_2, \\cdots)  \\tag{Infinite sequence}\n\\end{align*}\n$$\n\nA sequence is a [function](./Function.md) $f: \\mathbb N \\to S$ which mapping the set of positive integers or non-negative integers $\\mathbb N$ (the positions of elements in the sequence) to the elements $S$ at each position.",
    "kids": {},
    "name": "Sequence",
    "parents": {
      "Function": ""
    },
    "properties": [
      "### Limitation\n\n$$\n\\lim_{n \\to \\infty} x_n=L \\Leftrightarrow |x_n-L|<\\epsilon, \\forall epsilon>0, \\exists N \\in Z_+, n > N  \\tag{Limit of Sequence}\n$$\n\nthe limit of the sequence $\\{x_{n}\\}$ as $n$ approaches infinity is $L$, written as $\\lim\\limits_{n\\rightarrow\\infty}x_{n} = L$ if for every positive number $\\epsilon> 0$, there exists a positive integer $N$ such that for all $n > N$, we have $\\vert a_{n}-L\\vert<\\epsilon$. If such a number $L$ exists, we say the sequence converges; otherwise, we say the sequence diverges.\n\n#### Basic Properties\n\n- **Uniqueness**:  If a sequence $\\{a_{n}\\}$ converges, then its limit is unique.\n\n$$\n\\lim_{n\\rightarrow\\infty}a_{n}=L_{1}, \\lim_{n\\rightarrow\\infty}a_{n}=L_{2} \\Rightarrow L_{1} = L_{2}\n$$\n\n- **Boundedness**: If a sequence $\\{a_{n}\\}$ converges, then the sequence is bounded. There exists a positive number $M$ such that $\\vert a_{n}\\vert\\leq M$ for all $n$. However, the converse is not necessarily true. A bounded sequence may not converge. \n- **Sign preservation**: If $\\lim\\limits_{n\\rightarrow\\infty}a_{n}=L$ and $L>0$ (or $L<0$), then there exists a positive integer $N$ such that for all $n > N$, $a_{n}>0$ (or $a_{n}<0$).\n\n- **Comparison Theorem**: If $a_{n}\\leq b_{n}$ for all $n$, then $\\lim\\limits_{n\\rightarrow\\infty}a_{n}\\leq \\lim\\limits_{n\\rightarrow\\infty}b_{n}$.\n- **Squeeze Theorem**: If $a_{n}\\leq c_{n}\\leq b_{n}$ for all $n$ and $\\lim\\limits_{n\\rightarrow\\infty}a_{n}=\\lim\\limits_{n\\rightarrow\\infty}b_{n}=L$, then $\\lim\\limits_{n\\rightarrow\\infty}c_{n}=L$.\n- **Subsequences of a Convergent Sequence**: If $\\lim\\limits_{n\\rightarrow\\infty}a_{n}=L$, the subsequence $\\{a_{n_k}\\}$ is also convergent and converges to the same limit $L$.\n\n#### Algebraic Properties\n- **Sum & DifferenceRule**: $\\lim\\limits_{n\\rightarrow\\infty}(a_{n} \\pm b_{n})=\\lim\\limits_{n\\rightarrow\\infty}a_{n} \\pm \\lim\\limits_{n\\rightarrow\\infty}b_{n}$.\n- **Product Rule**: $\\lim\\limits_{n\\rightarrow\\infty}(a_{n}\\times b_{n})=\\lim\\limits_{n\\rightarrow\\infty}a_{n}\\times\\lim\\limits_{n\\rightarrow\\infty}b_{n}$.\n- **Quotient Rule**: If $\\lim\\limits_{n\\rightarrow\\infty}b_{n}\\neq0$, then $\\lim\\limits_{n\\rightarrow\\infty}\\frac{a_{n}}{b_{n}}=\\frac{\\lim\\limits_{n\\rightarrow\\infty}a_{n}}{\\lim\\limits_{n\\rightarrow\\infty}b_{n}}$.\n\n### Classic Sequence\n\n#### Arithmetic Sequence\n\n$$\na_{n}-a_{n - 1}=d  \\quad (n\\geq2, n\\in \\mathbb N^+) \\\\\na_{n}=a_{1}+(n - 1)d\n$$\n\nIf starting from the second term of a sequence, the difference between each term and its preceding term is equal to the same constant, then this sequence is called an arithmetic sequence.\n\n- $d$: the common difference of the arithmetic sequence.\n\n##### Properties\n- **Arithmetic Mean**: If $a$, $b$, $c$ are in arithmetic sequence, then $2b = a + c$, and $b$ is called the arithmetic mean of $a$ and $c$.\n- **Sum Formula of the First $n$ Terms**: \n$$\nS_{n}=\\frac{n(a_{1}+a_{n})}{2}=na_{1}+\\frac{n(n - 1)}{2}d\n$$\n- $m + n = p + q \\Rightarrow a_{m}+a_{n}=a_{p}+a_{q}$\n- **Monotonicity**: When $d>0$, the sequence is an increasing sequence; when $d<0$, the sequence is a decreasing sequence; when $d = 0$, the sequence is a constant sequence.\n\n#### Geometric Sequence\n\n$$\n\\frac{a_{n}}{a_{n - 1}}=q  \\quad (n\\geq2, n\\in \\mathbb N^+, q \\neq 0)\\\\\na_{n}=a_{1}q^{n - 1}\n$$\n\nIf starting from the second term of a sequence, the ratio of each term to its preceding term is equal to the same constant, then this sequence is called a geometric sequence.\n\n- $q$: the common ratio of the geometric sequence\n\n##### Properties\n\n- **Geometric Mean**: If $a$, $b$, $c$ are in geometric sequence, then $b^{2}=ac$, and $b$ is called the geometric mean of $a$ and $c$, and $a$, $b$, $c$ are all non-zero.\n- **Sum Formula of the First $n$ Terms**: When $q = 1$, $S_{n}=na_{1}$; when $q\\neq1$, $S_{n}=\\frac{a_{1}(1 - q^{n})}{1 - q}=\\frac{a_{1}-a_{n}q}{1 - q}$.\n- $m + n = p + q \\Rightarrow a_{m}\\cdot a_{n}=a_{p}\\cdot a_{q}$\n- **Monotonicity**: When $a_{1}>0$, $q>1$ or $a_{1}<0$, $0<q<1$, the sequence is an increasing sequence; when $a_{1}>0$, $0<q<1$ or $a_{1}<0$, $q>1$, the sequence is a decreasing sequence; when $q = 1$, the sequence is a constant sequence; when $q<0$, the sequence is an oscillating sequence.\n\n### Series\n\nA series refers to the sum of the terms of a sequence. Given a sequence $a_n$, the series $S$ is given by:\n$$\nS = \\sum_{i=0}^\\infty a_i  \\\\\nS_n = \\sum_{i=0}^n a_i\n$$\n\n### Subsequence\n\nSubsequence of a sequence $(a_n)$ is $(a_{g(n)})$ where $g : \\mathbb N \\to \\mathbb N$ is strictly increasing.  \n\nProblem:\n* Sort\n\n* Maximum Subarray Sum\n  - Purpose  \n    For a given sequence $a$, we aim to find the maximum sum of a contiguous subarray.\n    $$\n    \\begin{align*}\n      \\max_{x \\subseteq a} \\sum x\n    \\end{align*}\n    $$\n\n  - Algorithm  \n    Dynamic Program,\n    $$\n    f_i = \\max(f_{i-1}, 0) + a_i\n    $$\n    $$\n    s^* = \\max_{i=1}^n(f_i)\n    $$\n    where $f_i$ refer to the maximum sum of a contiguous subarray ending at $a_i$. \n\n* Longest Subsequence Problem\n* Sequence Palindrome\n  - Include\n    * Longest Palindrome Subsequence \n      - Purpose \n        $$\n        \\begin{align*}\n          \\max_{x \\subseteq a} \\quad & n_x = \\text{number}(x)  \\\\\n          s.t. \\quad & x_i = x_{n_x - i + 1}  \\quad ; i = 1:n_x  \\tag{Palindrome}\n        \\end{align*}\n        $$\n\n      - Algorithm  \n        Dynamic programming,\n        $$\n        \\begin{align*}\n          f(s,e) &= \\left\\{\\begin{matrix}\n            f(s-1,e+1) + 2 \\quad & f(s,e) > 0 \\ \\text{and}\\  a_{s-1} = a_{e+1}  \\\\\n            0 \\quad & other.\n            \\end{matrix}\\right.  \\\\\n          f(s,s) &= 1  \\tag{initial}  \\\\\n          f(s,s+1) &= 2 \\quad ;a_s = a_{s+1}  \\\\\n        \\end{align*}\n        $$\n        $f()$: $a_{s:e}$\u7684\u56de\u6587\u5b57\u6570, \u4e0d\u662f\u56de\u6587\u5e8f\u5217\u5219\u4e3a0.\n\n    * Maximum Palindrome Prefix\n      - Purpose  \n        $$\n        \\begin{align*}\n          \\max_{x \\in 1:n_a} \\quad & x  \\\\\n          s.t. \\quad & a_i = x_{x - i + 1}  \\quad ; i = 1:x  \\tag{Palindrome}\n        \\end{align*}\n        $$\n\n* Sequence Matching\n  - Purpose  \n    For two given sequences $a, b$, where $\\text{number}(b) \\le \\text{number}(a)$, and we aim to find the first place where $b$ matching the successive subsequence of $a$.\n    $$\n    \\begin{align*}\n      \\min\\quad& k \\\\\n      s.t.\\quad& b = a_{k:k+n_b-1}\n    \\end{align*}\n    $$\n\n  - Property  \n    - The next place possible matched is $k+i-l_i$, from the place $k$ in $a$ and $b_{1:i} = a_{k:k+i-1}$.\n\n      $$\n      l_i = \\text{length}_\\text{Longest Prefix-Suffix}(b_{1:i})\n      $$\n      $$\n      \\begin{align*}\n        b_{1:i} = a_{k:k+i-1} \\Rightarrow\n        b_{1:l_i} &= a_{k+i-l_i:k+i-1}  \\tag{match}\\\\\n        b_{1:l'} &\u2260 a_{k+i-l':k+i-1}  \\quad ; l' > l_i  \\tag{mismatch}\n      \\end{align*}\n      $$\n\n  - Algorithm\n    * Knuth-Morris-Pratt Algorithm  \n      For a place $k$ in sequence $a$ and $b_{1:i} = a_{k:k+i-1}$, we judge whether is the matched place. If not, we use the property above to arrive the place $k'$ possible matched and do the same thing, untill find the answer.\n      $$\n      \\begin{matrix}\n        k \\gets& k+i-l_i \\quad; b_{i+1} \\neq a_{k+i}\\\\\n        i \\gets& i+1 \\quad; b_{i+1} = a_{k+i}\\\\\n      \\end{matrix}\n      $$\n\n* Dynamic Time Warping , DTW"
    ]
  },
  "Set": {
    "define": "$$\n\\{\\cdot\\}\n$$\n\n\n\nA set $S$ is a collection of distinct objects. \n\nIf an object $x$ is a member of a set $S$, we write $x \\in S$. Otherwise, we write $x \\notin S$. The most commonly used axiomatic system for set theory is Zermelo-Fraenkel set theory with the Axiom of Choice (ZFC axiomatic system):\n\n1. **Axiom of Extensionality**: Two sets are equal if they have the same elements.\n   $$\n   \\forall A \\forall B (\\forall x (x \\in A \\leftrightarrow x \\in B) \\rightarrow A = B)\n   $$\n\n2. **Axiom of Regularity (also known as the Axiom of Foundation)**: Every non-empty set has a member that is disjoint from it. \n   $$\n   \\forall x(x \\neq \\varnothing \\rightarrow \\exists y(y \\in x \\wedge y \\cap x=\\varnothing))\n   $$\n\n3. **Axiom of Pairing**: For any two sets, there is a set that contains exactly those two sets.\n   $$\n   \\forall x \\forall y \\exists B \\forall z (z \\in B \\leftrightarrow (z = x \u2228 z = y))\n   $$\n\n4. **Axiom of Union**: For any set of sets, there is a set that contains all the elements of those sets.\n   $$\n   \\forall A \\exists B \\forall x (x \\in B \\leftrightarrow \\exists C (x \\in C \u2227 C \\in A))\n   $$\n\n5. **Axiom of Infinity**: There exists a set that contains the empty set and is closed under the operation of \"successor\" which is defined for any set $x$ as $x \\cup \\{x\\}$.\n   $$\n   \\exists A (\u2205 \\in A \u2227 \\forall x (x \\in A \\rightarrow x \u222a {x} \\in A))\n   $$\n\n6. **Axiom Schema of Separation (also known as the Axiom Schema of Comprehension)**: For any set and any property that can be defined without reference to the whole set, there is a subset containing exactly those elements of the original set that have the property.\n   $$\n   \\forall w_{1},\\ldots ,w_{n}\\,\\forall A\\,\\exists B\\,\\forall x\\,(x\\in B\\Leftrightarrow [x\\in A\\land \\varphi (x,w_{1},\\ldots ,w_{n},A)])\n   $$\n\n7. **Axiom of Power Set**: For any set, there is a set of all its subsets.\n   $$\n   \\forall A \\exists B \\forall C (C \\in B \\leftrightarrow \\forall x (x \\in C \\rightarrow x \\in A))\n   $$\n\n8. **Axiom Schema of Replacement**: If a property defines a function on a set, then the image of the set under that function is also a set.\n   $$\n   \\forall A (\\forall x \\in A \\exists !y \u03c6(x, y, p1, ..., pn) \\rightarrow \\exists B \\forall x \\in A \\exists y (y \\in B \u2227 \u03c6(x, y, p1, ..., pn)))\n   $$\n\n9. **Axiom of Choice**: For any set of non-empty sets, there exists a choice function that selects one element from each set.\n   $$\n   \\forall A (\\exists B \\forall x (x \\in B \\leftrightarrow (\\exists y (y \\in A \u2227 \\forall z (z \\in A \\rightarrow (z = y \u2228 \u00acS(z, y)))))))\n   $$",
    "kids": {
      "Algebra_Structure": "",
      "Fractal": "",
      "Graph": "",
      "Natural_Number": "",
      "Ordered_Set": "",
      "Power_Set": "",
      "Relation": ""
    },
    "name": "Set",
    "parents": {
      "root": ""
    },
    "properties": [
      "### Cardinality & Counting\n\n$$\n|S| = \\text{number}(S)  \\tag{Cardinality}\n$$\nCardinality $|S|$ is the number of elements in a set $S$.\n\n#### Property\n\n* Addition theorem  \n  for $S = \\cap_{i=1}^n S_i, S_i \\cap S_j = \\emptyset (i \u2260 j)$\n  $$\n  \\Rightarrow |S| = \\sum_{i=1}^n |S_i|\n  $$\n\n* Multiplication theorem  \n  for sets $S_A, S_B$, and\n  $$\n  \\begin{align*}\n    S &= \\{(a, b) | a \\in S_A, b \\in S_B\\}  \\\\\n      &= S_A \u00d7 S_B  \\tag{Cartesian\u79ef}  \\\\\n  \\end{align*}\n  $$\n  $$\n  \\Rightarrow |S| = |S_A| \u00d7 |S_B|\n  $$\n\n  - Proof\n    $$\n    \\begin{align*}\n      S \n      &= \\{(a, b) | a \\in S_A, b \\in S_B\\}  \\\\\n      &= \\bigcap_{a_i \\in S_A} \\{(a_i, b) | b \\in S_B\\}  \\\\\n      \\Rightarrow |S| &= \\sum_{i=1}^{|S_A|} |S_B|  \\tag{Addition theorem}  \\\\\n      &= |S_A| \u00d7 |S_B|  \\\\\n    \\end{align*}\n    $$\n\n* Principle of Inclusion-Exclusion  \n  for $A_1,...,A_n \\subseteq S$\n  $$\n  \\begin{align*}\n    \\left|\\bigcup_{i=1}^n A_i\\right| &= \\sum_{k=1}^n \\left((-1)^{k-1} \\sum_{\\substack{i_1,...,i_k \\in 1:n \\\\ i_1\u2260...\u2260i_k}} \\left|\\bigcup_{i\\in\\{i_1,...,i_k\\}} A_i\\right|\\right)\n  \\end{align*}\n  $$\n\n- Special Counting Sequence\n  * Catalan Numbers \n    $$\n    \\begin{align*}\n      f_n \n      &= \\frac{C(2n, n)}{n+1}\\quad, n \\ge 0  \\\\\n      &= C(2n, n) - C(2n, n - 1)  \\\\\n      &= C(2n, n) - C(2n, n + 1)  \\\\\n      &= \\frac{(2n)!}{(n+1)! n!}\\\\\n      &= \\left\\{\\begin{matrix}\n        \\sum\\limits_{i=1}^n f_{i-1}f_{n-i}  & n \\ge 2\\\\\n        1 & n = 0, 1\n      \\end{matrix}\\right. \\tag{recurrence form}\\\\\n      &= \\frac{4n-2}{n+1} f_{n-1}\n    \\end{align*}\n    $$\n    Catalan Numbers are a sequence of natural numbers.\n* Pigeonhole Principle  \n  for $A_1, ..., A_n \\subseteq A, |A| = n + 1$, $\\Rightarrow \\exists A_i, |A_i| \u2265 2$.\n\n### Relationship between sets\n\n* Subset & Proper Subset \n  $$\n  A \\subseteq B \\quad\\Leftrightarrow\\quad x \\in B, \\forall x \\in A \\tag{Subset}\n  $$\n  If all the elements of set $A$ are contained in a set $B$, then we say $A$ is a subset of $B$.\n\n  $$\n  A \\subset B \\Leftrightarrow x \\in B, \\forall x \\in A \\text{ and } \\exist x \\notin A, x \\in B \\tag{Proper Subset}\n  $$\n\n  A set $A$ is a proper subset of $B$, if $A \\subseteq B$, but not $A = B$.\n\n* Equal  \n  $$\n  \\begin{align*}\n    A = B &\\quad\\Leftrightarrow\\quad x \\in B, \\forall x \\in A \\text{ and } x \\in A, \\forall x \\in B  \\tag{equal}\\\\\n    &\\quad\\Leftrightarrow\\quad A \\subseteq B, B \\subseteq A\n  \\end{align*}\n  $$\n  Two sets are equal, if they contain the same elements.\n\n* Disjoint\n  $$\n  A, B \\text{ is Disjoint } \\quad\\Leftrightarrow\\quad A \\cap B = \\emptyset\n  $$\n\n### Operations\n\n#### Intersection\n\n$$\nA \\cap B = \\{x \\ |\\ x \\in A, x \\in B\\}  \\tag{Intersection}\n$$\n\n- Property\n  - idempotency law: $A \\cap A = A$\n  - commutative law: $A \\cap B = B \\cap A$  \n  - associative law: $A \\cap (B \\cap C) = (A \\cap B) \\cap C$\n\n#### Union\n\n$$\nA \\cup B = \\{x \\ |\\ x \\in A \\text{ or } x \\in B \\}  \\tag{Union}\n$$\n\n- Property\n  - idempotency law: $A \\cup A = A$\n  - commutative law: $A \\cup B = B \\cup A$  \n  - associative law: $A \\cup (B \\cup C) = (A \\cup B) \\cup C$\n\n#### Difference\n\n$$\nA - B = \\{x \\ |\\ x \\in A \\text{ and } x \\notin B\\}  \\tag{Difference}\n$$\n\n#### Complement of A Set\n\n$$\n\\bar A = U - A = \\{x \\ |\\ x \\in U, x \\notin A\\}  \\tag{Complement of A Set}\n$$\n\nFor a universal set $U$, the complement of a set $A$ is $U - A$.\n\n- Property\n  - $\\bar{\\bar A} = A$ \n\n  - distributive laws \n    $$\n    A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\n    $$\n    $$\n    A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\n    $$\n  - absorption laws\n    $$\n    A \\cap (A \\cup B) = A\n    $$\n    $$\n    A \\cup (A \\cap B) = A\n    $$\n  - DeMorgan's laws\n    $$\n    A - (B \\cap C) = (A - B) \\cup (A - C)\n    $$\n    $$\n    A - (B \\cup C) = (A - B) \\cap (A - C)\n    $$\n    $$\n    \\overline{A \\cap B} = \\bar A \\cup \\bar B\n    $$\n    $$\n    \\overline{A \\cup B} = \\bar A \\cap \\bar B\n    $$\n\n### Cartesian Product\n\n$$\nA \\times B = \\{(a, b) \\ | a \\in A \\text{ and } b \\in B\\}\n$$\nFor two sets $A, B$, cartesian product is the set of all ordered pairs such that the first element of the pair is an element of $A$ and the second one is from $B$.\n\n- Property\n  - $\\text{number}(A \\times B) = \\text{number}(A) \\cdot \\text{number}(B)$\n\n### [Power Set](./Power_Set.md)\n\n### Ordered Pair\n\n$$\n(a, b) = \\{\\{a\\}, \\{a, b\\}\\}\n$$\nOrdered pair $(a, b)$ is a pair of two elements $a, b$ in which order matters.\n\n### Empty Set\n$$\n\\emptyset = \\{\\}  \\tag{Empty Set}\n$$\nEmpty Set is a set without any element. \n\n  - Property \n    - $\\emptyset \\in S, \\forall \\text{ set } S$\n    - $A \\cap \\emptyset = \\emptyset$\n    - $A \\cup \\emptyset = A$"
    ]
  },
  "Sigma_Algebra": {
    "define": "$$\n  \\Sigma \\subseteq P(S)  \\tag{$\\sigma$-algebra}\n$$\nFor a set $S$ and its power set $P(S)$, a $\\sigma$-algebra $\\Sigma$ is a subset of power set such that\n- $S \\in \\Sigma$, and $S$ is considered to be the universal set in the following context.\n- $\\Sigma$ closed under complementation, i.e. $A \\in \\Sigma$ implies that $A^C = S - A \\in \\Sigma$. Meanwhile, base on the $S \\in \\Sigma$ (1) we have $\\emptyset \\in \\Sigma$. \n- $\\Sigma$ is closed under countable unions, i.e. for any sequence $(A_1, ..., A_n), A_i \\in \\Sigma$, we have that \n$$\n\\bigcup_i A_i \\in \\Sigma\n$$",
    "kids": {},
    "name": "Sigma_Algebra",
    "parents": {
      "Power_Set": ""
    },
    "properties": [
      "- The maximum $\\sigma$-algebra is Power Set of $S$,  \nThe minimum $\\sigma$-algebra is $\\{\\emptyset, S\\}$\n\n- Countable intersection set closure, if $A_1, ... , A_n \\in \u03a3$, then $\\bigcap_i A_i  \\in \u03a3$\n- Proof  \n  De Morgan's law\n\n- Include: Borel $\\sigma$-algebra\n\n$$\n\\mathcal B(X) = \\sigma(\\mathcal O)  \\tag{Borel $\\sigma$-algebra}\n$$\nThe Borel $\\sigma$-algebra on a topological space $X$ is the smallest $\\sigma$-algebra containing all the open subsets of $X$. Where $\\mathcal O$ denote the collection of all open subsets of $X$."
    ]
  },
  "Simplex": {
    "define": "$$\nC = \\text{conv} (\\{v_1, ..., v_k\\}) = \\left\\{\\sum_{i=1}^k \\theta_i v_i \\ |\\ \\theta \u2ab0 0, \\boldsymbol 1^T \\theta=1 \\right\\}\n$$\n\nSimplex represents the simplest possible polytope in any given dimension. Specifically, a $k$-simplex is a $k$-dimensional polytope which is the convex hull of its $k + 1$ vertices. ([polyhedron](./Polyhedron.md))",
    "kids": {},
    "name": "Simplex",
    "parents": {
      "Polyhedron": ""
    },
    "properties": [
      "* Point\n* Line Segment\n* Triangle\n  - Define \n  - Property\n    - judge whether a point is inside the triangle\n\n      We assume that the order of input vertices of the triangle $(\\boldsymbol a, \\boldsymbol b, \\boldsymbol c)$ is counter clockwise.\n\n      $$\n      \\left.\\begin{matrix}\n      (\\boldsymbol b-\\boldsymbol a) \\times (\\boldsymbol p-\\boldsymbol b) > 0\\\\\n      (\\boldsymbol c-\\boldsymbol b) \\times (\\boldsymbol p-\\boldsymbol c) > 0\\\\\n      (\\boldsymbol a-\\boldsymbol c) \\times (\\boldsymbol p-\\boldsymbol a) > 0\\\\\n      \\end{matrix} \\right\\} \\Leftrightarrow \\boldsymbol p \\text{ is in Triangle}(\\boldsymbol a, \\boldsymbol b, \\boldsymbol c)\n      $$\n\n  - Helen's formula\n      $$\n      S = \\sqrt{q(q-a)(q-b)(q-c)}\n      $$\n      $$\n      q = \\frac{a + b + c}{2}\n      $$\n\n* Tetrahedron\n\n- 5-cell"
    ]
  },
  "Stochastic_Process": {
    "define": "A Stochastic Process $X(t, \\omega), \\omega \\in \\Omega, t \\in T$ is defined as a collection of random variables defined on a [Probability Space](./Probability_Space.md) $(\u03a9, \\mathcal F, P)$, and these random variables indexed by set $T$.\n\nNote\n- When the time $t$ is fixed, the random process degenerates into a random variable.\n- When the random sample $\u03b6$ is determined, the random process degenerates into a continuous time function",
    "kids": {
      "Markov_Process": "",
      "Martingale": ""
    },
    "name": "Stochastic_Process",
    "parents": {
      "Probability_Space": ""
    },
    "properties": [
      "### Correlation Function & Covariance Function\n\n$$\n\\begin{align*} \n  Corr(X(t_1), Y(t_2)) \n  &= \\mathbb E(X(t_1) Y(t_2))  \\tag{Correlation function}\\\\\n\n  Corr(X(t_1), X(t_2)) \n  &= \\mathbb E(X(t_1) X(t_2))  \\tag{AutoCorrelation function}\\\\\n\n  Cov(X(t_1), Y(t_2)) \n  &= \\mathbb E((X(t_1) - \\mu_X(t_1)) (Y(t_2) - \\mu_Y(t_2)))  \\tag{Covariance function}\\\\\n  &= \\mathbb E(X(t_1) X(t_2)) - \\mu_X(t_1) \\mu_Y(t_2)  \\\\\n  &= Corr(X(t_1), Y(t_2)) - \\mu_X(t_1) \\mu_Y(t_2)  \\\\\n\n  Cov(X(t_1), X(t_2)) \n  &= \\mathbb E((X(t_1) - \\mu(t_1)) (X(t_2) - \\mu(t_2)))  \\tag{AutoCovariance function}\\\\\n  &= \\mathbb E(X(t_1) X(t_2)) - \\mu(t_1) \\mu(t_2)  \\\\\n  &= Corr(X(t_1), X(t_2)) - \\mu(t_1) \\mu(t_2) \n\\end{align*} \n$$\n\n#### Property  \n\n- $X, Y \\ \\text{Uncorrelated} \\Leftrightarrow Cov(X(t_1), Y(t_2)) = 0, \\quad \\forall t_1, t_2$\n\n- $X, Y \\ \\text{Orthogonality} \\Leftrightarrow Corr(X(t_1), Y(t_2)) = 0, \\quad \\forall t_1, t_2$\n\n\n\nIndependence\n\n\n\nExample: \n\n- Simple process\n  $$\n  X(t, \u03b6) = X(\u03b6) f(t)\n  $$\n\n- Random Sine Wave\n  $$\n  X(t, \u03b6) = A(\u03b6) \\sin(\\omega_0 t + \\Theta(\u03b6))\n  $$\n\n\n\n### Stationary Process & Weakly Stationary Process\n\n\n$$\n\\mathbb P (x(t_1), ... , x(t_n)) = \\mathbb P (x(t_1+\\tau), ..., x(t_n+\\tau)) \\quad ;\\forall \\tau, t_1, ..., t_n \\in \\mathbb R, n \\in \\mathbb N  \\tag{Stationary}\n$$\nStationary process is a stochastic process in which the joint distribution of any set of time-indexed random variables is invariant to shifts in time (the statistical properties of the process are constant over time).\n\n$$\nR_{XX}(t_1 - t_2 ,0) = R_{XX}(t_1, t_2) \\quad; \\forall t_1, t_2 \\in \\mathbb R  \\tag{Weakly Stationary}\n$$\nWeakly stationary process is a stochastic process in which the mean, variance and autocovariance (or autocorrelation) of the process are constant over time, but the joint distribution of the variables may depend on the time index.\n\n#### Property\n\n- Power Spectral Density: Power Spectral Density is the Fourier transform of autocorrelation function of Weak-sense stationary process.  Power Spectral Density consists of real numbers greater than 0.\n\n#### Problem: Test the Stationary\n* Unit Root Test \n\n### Gaussian Process\n\n$$\n\\{X_t \\ |\\ t \\in T, (X_{t_1},...,X_{t_k}) \\sim \\mathcal N(\\cdot, \\cdot), \\forall t_1,...,t_k \\in T\\}\n$$\nGaussian Process is a time continuous stochastic process $\\{X_t \\ |\\ t \\in T\\}$ such that the random vector $(X_{t_1},...,X_{t_k})$ obeys multivariate Gaussian distribution for any finite set of indices $t_1,...,t_k \\in T$.\n\n### Autoregressive Process\n\n$$\nX_t = \\epsilon_t + \\alpha_0 + \\sum\\limits_{i=1}^p \\alpha_i X_{t-i}  \\tag{Autoregressive}\n$$\n\nAutoregressive Process is a discrete-time stochastic process in which the current value of a time series variable depends linearly on its past values. Where $p$ is the order of autoregressive process, which means the length of the associated historical value.\n\n### Stochastic Point Process\n\nStochastic Point Process is a collection of random variables $\\{X(t) : t \\ge 0\\}$, where $X(t)$ represents the location or time of occurrence of a point at time $t$. \n\n#### Poisson Point Process\n\nPoisson point process is a stochastic process that models the random spatial distribution of events in a continuous space, which satisfies,\n* Spatial homogeneity. For any region $A$, the value of the number of events occurring in the region $N(A)$ depends only on the size of the Lebesgue measure  (such as area, volume) of $A$ and is independent of the position and shape of $A$. \n* Independent. For any disjoint measurable regions $A_1, A_2, \\ldots, A_n$, the random variables $N(A_1), N(A_2), \\ldots, N(A_n)$ are independent of each other.\n* The average rate of occurrence of events is constant throughout the space. And, $N(A)$ follows a Poisson distribution with constant intensity $\\lambda> 0$. Where $\\mu_A$ is the Lebesgue measure of $A$,\n    $$\n    \\mathbb P(N(A) = n) = \\frac{\\lambda \\cdot \\mu_A}{n!} e^{\\lambda \\cdot \\mu_A}\n    $$\n    $$\n    \\mathbb E(N(A)) = \\lambda \\cdot \\mu_A\n    $$"
    ]
  },
  "Symmetric_Group": {
    "define": "$$\n  S_n = (\\{f: X \\to X\\}, \\circ)\n$$\n\nSymmetric group on a finite set $X$ is the group whose elements are all bijective functions $f: X \\to X$ and whose group operation is that of function composition $f_1 \\circ f_2 = f_1(f_2(\\cdot))$. Where $n$ is the degree of symmetric group, that is, the number of elements in set $X$.",
    "kids": {},
    "name": "Symmetric_Group",
    "parents": {
      "Group": ""
    },
    "properties": [
      "- Cayley's theorem: every group $G$ is isomorphic to a subgroup of a symmetric group.\n\n* Permutation Group\n    - Define\n      Permutation group is a group $G$ whose elements are permutations of a given set $M$ and whose group operation is the composition of permutations in $G$ (which are thought of as bijective functions from the set $M$ to itself).  \n\n    - Property\n      - every group is isomorphic to some permutation group."
    ]
  },
  "Tensor": {
    "define": "$$\nT:\\underbrace{V^*\\times\\cdots\\times V^*}_{k\\text{ times}}\\times\\underbrace{V\\times\\cdots\\times V}_{l\\text{ times}}\\to\\mathbb{R}\n$$\n\nA $(k,l)$-type tensor $T$ is a multilinear map on an $n$-dimensional [vector space](./Linear_Space.md) $V$ and its dual space $V^*$.\n\nIn abstract index notation, tensors $T_{a_1,\\cdots, a_l}^{a_{l+1}, \\cdot, a_{l+k}}$ are denoted by letters with indices, but the indices do not refer to specific components in a particular basis as in the traditional component-based index notation. Instead, they represent the abstract algebraic and geometric roles that the tensors play in a given context.",
    "kids": {},
    "name": "Tensor",
    "parents": {
      "Linear_Space": ""
    },
    "properties": [
      "### Basic Operations\n\n- Addition: \n\n$$\n(T + S)(\\alpha_1,\\cdots,\\alpha_k,v_1,\\cdots,v_l)=T(\\alpha_1,\\cdots,\\alpha_k,v_1,\\cdots,v_l)+S(\\alpha_1,\\cdots,\\alpha_k,v_1,\\cdots,v_l)\n$$\n\n- Tensor Product\n\n$$\n(T S)(\\alpha_1,\\cdots,\\alpha_{k_1 + k_2},v_1,\\cdots,v_{l_1 + l_2})=T(\\alpha_1,\\cdots,\\alpha_{k_1},v_1,\\cdots,v_{l_1})S(\\alpha_{k_1+1},\\cdots,\\alpha_{k_1 + k_2},v_{l_1 + 1},\\cdots,v_{l_1 + l_2})\n$$\n\n\n- $\\alpha_1,\\cdots,\\alpha_k\\in V^*$\n- $v_1,\\cdots,v_l\\in V$.\n\n### Contraction\n\n$$\nC(T)^{i_1\\cdots i_{k - 1}i_{k + 1}\\cdots i_m}_{j_1\\cdots j_{l - 1}j_{l + 1}\\cdots j_n}=\\sum_{r = 1}^{N}T^{i_1\\cdots r\\cdots i_m}_{j_1\\cdots r\\cdots j_n}\n$$\n\nThe contraction of a tensor is an operation that reduces the rank of a tensor by summing over a pair of indices. For a tensor $T^{i_1i_2\\cdots i_m}_{j_1j_2\\cdots j_n}$, if we contract over the indices $i_k$ and $j_l$, we sum over the values of these indices.\n\n- $N$ is the dimension of the vector space on which the tensor is defined."
    ]
  },
  "Topological_Space": {
    "define": "$$\n(S, \\tau)\n$$\n\nA **Topological space** is a pair $(S, \\tau)$,  where $S$ is a set and $\\tau$ is a **topology** on $S$. A topology $\\tau$ is a collection of subsets of a set $S$ (a subset of [power set](./Power_Set.md) $P(S)$) that satisfies the following axioms.\n\n- The empty set and the whole set $S$ itself belong to $\\tau$.\n$$\n\\{\\emptyset, S\\} \\subseteq \\tau\n$$\n\n- The intersection of any finite members of $\\tau$ belongs to $\\tau$. If $U_{1},U_{2},\\cdots,U_{n}$ are sets in $\\tau$, then \n$$\n\\bigcap_{i = 1}^{n}U_{i}\\in\\tau\n$$\n\n- Any arbitrary (finite or infinite) union of members of $\\tau$ belongs to $\\tau$. If $\\{U_{\\alpha}\\}_{\\alpha\\in I}$ is an arbitrary collection of sets in $\\tau$, where $I$ is an index set, then \n$$\n\\bigcup_{\\alpha\\in I}U_{\\alpha}\\in\\tau\n$$\n\n### Open Set\n\nThe elements of $\\tau$ are called **open sets** in the topological space $(S,\\tau)$, and the selection of open sets determines the topological structure of the space.",
    "kids": {
      "Hausdorff_Space": "",
      "Metric_Space": ""
    },
    "name": "Topological_Space",
    "parents": {
      "Power_Set": ""
    },
    "properties": [
      "### Closed Set\n\nClosed Set is the complementary set of Open Set. A set can be both closed and open at the same time.\n\n### Compact\n\nA topological space $X$ is compact if every open cover of $X$ has a finite subcover.\n\n- Open cover: A collection of open sets $\\{U_\\alpha\\}$ such that $X \\subseteq \\bigcup\\limits_\\alpha U_\\alpha$.\n- Finite subcover: A finite subset $\\{U_1, U_2, \\cdots, U_n\\}$ of the open cover that still satisfies $X \\subseteq \\bigcup\\limits_{i=1}^n U_i$\n\n\n\nProperties:\n\n- Compact space is is still a compact space under a continuous mapping.\n\n### Borel $\\sigma$-algebra \n\n### Genus\nGenus of a non-empty connected surface is defined as the maximum number of non-intersecting simple closed curves that can be drawn on the surface without dividing it into two disconnected pieces. The genus is a topological invariant that characterizes its \"number of holes\". \n\nGenus $g$ can be defined in terms of the Euler characteristic $\\chi$, where $b$ is the number of boundary components.\n\n$$\ng = \\frac{2 - \\chi - b}{2}  \\tag{Genus}\n$$\n\n### Euler Characteristic\n\n$$\n\\chi = V - E + F  \\tag{Euler Characteristic}\n$$\n\nEuler Characteristic is a topological invariant and defined as an alternating sum of the ranks of the homology groups of the space.\n\nEuler Characteristic of sphere, in a polyhedra, the Euler characteristic was classically defined for surfaces of polyhedra with the numbers of vertices $V$ (corners), edges $E$ and faces $F$. Any convex polyhedron's surface has Euler characteristic $\\chi = 2$.\n\n### Relationship between multiple topological spaces\n\n#### Continuity\n\nA function $f: X\\rightarrow Y$ between two topological spaces $(X, \\tau_X)$ and $(Y, \\tau_Y)$ is said to be continuous if the pre-image of every open set in $Y$ is an open set in $X$.\n$$\nf^{- 1}(U)\\in\\tau_X \\quad (\\forall U\\subseteq \\tau_Y)\n$$\n\n- $f^{-1}(U)=\\{x\\in X:f(x)\\in U\\}$ represents the pre-image of the set $U\\subseteq \\tau_Y$ under the function $f$.\n\n#### Homeomorphism\n\nA function $f: X \\to Y$ between two topological spaces is a homeomorphism if it has the following properties,\n- $f$ is a bijection \n- $f$ is continuous\n- the inverse function $f^{-1}$ is continuous ($f$ is an open mapping)."
    ]
  },
  "Tree": {
    "define": "Tree is a class of connected undirected graphs without loops.\n\n### Rooted Tree\n\nWhen the root node is set to a certain node of the tree, the hierarchical relationship of the entire tree and the parent-child relationship among each node will be uniquely determined.\n\n- **root node**: A node without forward nodes, and a tree has only one root node.\n- **leaf node:** A node that has no children.\n- depth: Number of edges in the simple path from node to root node. The depth of the tree is the maximum node depth in the tree.\n\n<img src=\"./assets/rooted tree.svg\" style=\"zoom:50%;\" />",
    "kids": {
      "Binary_Tree": ""
    },
    "name": "Tree",
    "parents": {
      "Graph": "undirected, connected, acyclic"
    },
    "properties": [
      "- There exists and only exists one single simple path between any two points of the tree.\n- $number(E) = number(V) - 1$\n- Delete an edge, the Tree will become disconnected;  \n  Add an edge, the Tree will have a loop."
    ]
  },
  "root": {
    "define": "",
    "kids": {
      "Logic": "",
      "Set": ""
    },
    "name": "root",
    "parents": {},
    "properties": []
  }
}